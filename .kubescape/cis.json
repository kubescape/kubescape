{
  "guid": "",
  "name": "CIS",
  "attributes": {
    "armoBuiltin": true,
    "version": "v1.0.1"
  },
  "creationTime": "",
  "description": "Testing CIS for Kubernetes as suggested by CIS in https://workbench.cisecurity.org/benchmarks/8973",
  "controls": [
    {
      "guid": "",
      "name": "Ensure that the API server pod specification file permissions are set to 600 or more restrictive",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.1.1",
      "controlID": "CIS-1.1.1",
      "creationTime": "",
      "description": "Ensure that the API server pod specification file has permissions of `600` or more restrictive.",
      "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchmod 600 /etc/kubernetes/manifests/kube-apiserver.yaml\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-API-server-pod-specification-file-permissions-are-set-to-600-or-more-restrictive",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_control_plane_info(obj)\n\t\n\tfile_obj_path := [\"data\", \"APIServerInfo\", \"specsFile\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual permissions test    \n\tallowed_perms := 384 # == 0o600\n\tnot cautils.unix_permissions_allow(allowed_perms, file.permissions)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t]) \n\n\talert := sprintf(\"the permissions of %s are too permissive. maximum allowed: %o. actual: %o\", [file.path, allowed_perms, file.permissions])\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chmod %o %s\", [allowed_perms, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_control_plane_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "ControlPlaneInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the API server pod specification file has permissions of `600` or more restrictive.",
          "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchmod 600 /etc/kubernetes/manifests/kube-apiserver.yaml\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Ensure that the controller manager pod specification file permissions are set to 600 or more restrictive",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.1.3",
      "controlID": "CIS-1.1.3",
      "creationTime": "",
      "description": "Ensure that the controller manager pod specification file has permissions of `600` or more restrictive.",
      "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchmod 600 /etc/kubernetes/manifests/kube-controller-manager.yaml\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-controller-manager-pod-specification-file-permissions-are-set-to-600-or-more-restrictive",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_control_plane_info(obj)\n\n\tfile_obj_path := [\"data\", \"controllerManagerInfo\", \"specsFile\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual permissions test    \n\tallowed_perms := 384 # == 0o600\n\tnot cautils.unix_permissions_allow(allowed_perms, file.permissions)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t]) \n\n\talert := sprintf(\"the permissions of %s are too permissive. maximum allowed: %o. actual: %o\", [file.path, allowed_perms, file.permissions])\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chmod %o %s\", [allowed_perms, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_control_plane_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "ControlPlaneInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the controller manager pod specification file has permissions of `600` or more restrictive.",
          "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchmod 600 /etc/kubernetes/manifests/kube-controller-manager.yaml\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Ensure that the controller manager pod specification file ownership is set to root:root",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.1.4",
      "controlID": "CIS-1.1.4",
      "creationTime": "",
      "description": "Ensure that the controller manager pod specification file ownership is set to `root:root`.",
      "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchown root:root /etc/kubernetes/manifests/kube-controller-manager.yaml\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-controller-manager-pod-specification-file-ownership-is-set-to-root-root",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_control_plane_info(obj)\n\n\tfile_obj_path := [\"data\", \"controllerManagerInfo\", \"specsFile\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual ownership check\n\tallowed_user := \"root\"\n\tallowed_group := \"root\"\n\tnot allowed_ownership(file.ownership, allowed_user, allowed_group)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"%s is not owned by %s:%s (actual owners are %s:%s)\", [\n\t\tfile.path,\n\t\tallowed_user,\n\t\tallowed_group,\n\t\tfile.ownership.username,\n\t\tfile.ownership.groupname,\n\t])\n\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chown %s:%s %s\", [allowed_user, allowed_group, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_control_plane_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.error # Do not fail if ownership is not found\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.username == user\n\townership.groupname == group\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "ControlPlaneInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the controller manager pod specification file ownership is set to `root:root`.",
          "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchown root:root /etc/kubernetes/manifests/kube-controller-manager.yaml\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Ensure that the scheduler pod specification file permissions are set to 600 or more restrictive",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.1.5",
      "controlID": "CIS-1.1.5",
      "creationTime": "",
      "description": "Ensure that the scheduler pod specification file has permissions of `600` or more restrictive.",
      "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchmod 600 /etc/kubernetes/manifests/kube-scheduler.yaml\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-scheduler-pod-specification-file-permissions-are-set-to-600-or-more-restrictive",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_control_plane_info(obj)\n\n\tfile_obj_path := [\"data\", \"schedulerInfo\", \"specsFile\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual permissions test    \n\tallowed_perms := 384 # == 0o600\n\tnot cautils.unix_permissions_allow(allowed_perms, file.permissions)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"the permissions of %s are too permissive. maximum allowed: %o. actual: %o\", [file.path, allowed_perms, file.permissions])\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chmod %o %s\", [allowed_perms, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_control_plane_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "ControlPlaneInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the scheduler pod specification file has permissions of `600` or more restrictive.",
          "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchmod 600 /etc/kubernetes/manifests/kube-scheduler.yaml\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Ensure that the scheduler pod specification file ownership is set to root:root",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.1.6",
      "controlID": "CIS-1.1.6",
      "creationTime": "",
      "description": "Ensure that the scheduler pod specification file ownership is set to `root:root`.",
      "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchown root:root /etc/kubernetes/manifests/kube-scheduler.yaml\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-scheduler-pod-specification-file-ownership-is-set-to-root-root",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_control_plane_info(obj)\n\n\tfile_obj_path := [\"data\", \"schedulerInfo\", \"specsFile\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual ownership check\n\tallowed_user := \"root\"\n\tallowed_group := \"root\"\n\tnot allowed_ownership(file.ownership, allowed_user, allowed_group)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"%s is not owned by %s:%s (actual owners are %s:%s)\", [\n\t\tfile.path,\n\t\tallowed_user,\n\t\tallowed_group,\n\t\tfile.ownership.username,\n\t\tfile.ownership.groupname,\n\t])\n\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chown %s:%s %s\", [allowed_user, allowed_group, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_control_plane_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.error # Do not fail if ownership is not found\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.username == user\n\townership.groupname == group\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "ControlPlaneInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the scheduler pod specification file ownership is set to `root:root`.",
          "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchown root:root /etc/kubernetes/manifests/kube-scheduler.yaml\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Ensure that the etcd pod specification file permissions are set to 600 or more restrictive",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.1.7",
      "controlID": "CIS-1.1.7",
      "creationTime": "",
      "description": "Ensure that the `/etc/kubernetes/manifests/etcd.yaml` file has permissions of `600` or more restrictive.",
      "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchmod 600 /etc/kubernetes/manifests/etcd.yaml\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-etcd-pod-specification-file-permissions-are-set-to-600-or-more-restrictive",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_control_plane_info(obj)\n\n\tfile_obj_path := [\"data\", \"etcdConfigFile\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual permissions test    \n\tallowed_perms := 384 # == 0o600\n\tnot cautils.unix_permissions_allow(allowed_perms, file.permissions)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"the permissions of %s are too permissive. maximum allowed: %o. actual: %o\", [file.path, allowed_perms, file.permissions])\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chmod %o %s\", [allowed_perms, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_control_plane_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "ControlPlaneInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the `/etc/kubernetes/manifests/etcd.yaml` file has permissions of `600` or more restrictive.",
          "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchmod 600 /etc/kubernetes/manifests/etcd.yaml\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Ensure that the etcd pod specification file ownership is set to root:root",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.1.8",
      "controlID": "CIS-1.1.8",
      "creationTime": "",
      "description": "Ensure that the `/etc/kubernetes/manifests/etcd.yaml` file ownership is set to `root:root`.",
      "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchown root:root /etc/kubernetes/manifests/etcd.yaml\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-etcd-pod-specification-file-ownership-is-set-to-root-root",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_control_plane_info(obj)\n\n\tfile_obj_path := [\"data\", \"etcdConfigFile\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual ownership check\n\tallowed_user := \"root\"\n\tallowed_group := \"root\"\n\tnot allowed_ownership(file.ownership, allowed_user, allowed_group)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"%s is not owned by %s:%s (actual owners are %s:%s)\", [\n\t\tfile.path,\n\t\tallowed_user,\n\t\tallowed_group,\n\t\tfile.ownership.username,\n\t\tfile.ownership.groupname,\n\t])\n\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chown %s:%s %s\", [allowed_user, allowed_group, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_control_plane_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.error # Do not fail if ownership is not found\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.username == user\n\townership.groupname == group\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "ControlPlaneInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the `/etc/kubernetes/manifests/etcd.yaml` file ownership is set to `root:root`.",
          "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchown root:root /etc/kubernetes/manifests/etcd.yaml\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Ensure that the etcd data directory permissions are set to 700 or more restrictive",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.1.11",
      "controlID": "CIS-1.1.11",
      "creationTime": "",
      "description": "Ensure that the etcd data directory has permissions of `700` or more restrictive.",
      "remediation": "On the etcd server node, get the etcd data directory, passed as an argument `--data-dir`, from the below command:\n\n \n```\nps -ef | grep etcd\n\n```\n Run the below command (based on the etcd data directory found above). For example,\n\n \n```\nchmod 700 /var/lib/etcd\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-etcd-data-directory-permissions-are-set-to-700-or-more-restrictive",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_control_plane_info(obj)\n\n\tfile_obj_path := [\"data\", \"etcdDataDir\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual permissions test    \n\tallowed_perms := 448 # == 0o700\n\tnot cautils.unix_permissions_allow(allowed_perms, file.permissions)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"the permissions of %s are too permissive. maximum allowed: %o. actual: %o\", [file.path, allowed_perms, file.permissions])\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chmod %o %s\", [allowed_perms, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_control_plane_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "ControlPlaneInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the etcd data directory has permissions of `700` or more restrictive.",
          "remediation": "On the etcd server node, get the etcd data directory, passed as an argument `--data-dir`, from the below command:\n\n \n```\nps -ef | grep etcd\n\n```\n Run the below command (based on the etcd data directory found above). For example,\n\n \n```\nchmod 700 /var/lib/etcd\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 7
    },
    {
      "guid": "",
      "name": "Ensure that the Container Network Interface file permissions are set to 600 or more restrictive",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.1.9",
      "controlID": "CIS-1.1.9",
      "creationTime": "",
      "description": "Ensure that the Container Network Interface files have permissions of `600` or more restrictive.",
      "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchmod 600 \u003cpath/to/cni/files\u003e\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-Container-Network-Interface-file-permissions-are-set-to-600-or-more-restrictive",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_control_plane_info(obj)\n\n\tfile_obj_path := [\"data\", \"CNIConfigFiles\"]\n\tfiles := object.get(obj, file_obj_path, false)\n\tfile := files[file_index]\n\n\t# Actual permissions test    \n\tallowed_perms := 384 # == 0o600\n\tnot cautils.unix_permissions_allow(allowed_perms, file.permissions)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tsprintf(\"%s/%d\", [concat(\"/\", file_obj_path), file_index]),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"the permissions of %s are too permissive. maximum allowed: %o. actual: %o\", [file.path, allowed_perms, file.permissions])\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chmod %o %s\", [allowed_perms, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_control_plane_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "ControlPlaneInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the Container Network Interface files have permissions of `600` or more restrictive.",
          "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchmod 600 \u003cpath/to/cni/files\u003e\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Ensure that the Container Network Interface file ownership is set to root:root",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.1.10",
      "controlID": "CIS-1.1.10",
      "creationTime": "",
      "description": "Ensure that the Container Network Interface files have ownership set to `root:root`.",
      "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchown root:root \u003cpath/to/cni/files\u003e\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-Container-Network-Interface-file-ownership-is-set-to-root-root",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_control_plane_info(obj)\n\n\tfile_obj_path := [\"data\", \"CNIConfigFiles\"]\n\tfiles := object.get(obj, file_obj_path, false)\n\tfile := files[file_index]\n\n\t# Actual ownership check\n\tallowed_user := \"root\"\n\tallowed_group := \"root\"\n\tnot allowed_ownership(file.ownership, allowed_user, allowed_group)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tsprintf(\"%s/%d\", [concat(\"/\", file_obj_path), file_index]), \"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"%s is not owned by %s:%s (actual owners are %s:%s)\", [\n\t\tfile.path,\n\t\tallowed_user,\n\t\tallowed_group,\n\t\tfile.ownership.username,\n\t\tfile.ownership.groupname,\n\t])\n\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chown %s:%s %s\", [allowed_user, allowed_group, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_control_plane_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.error # Do not fail if ownership is not found\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.username == user\n\townership.groupname == group\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "ControlPlaneInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the Container Network Interface files have ownership set to `root:root`.",
          "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchown root:root \u003cpath/to/cni/files\u003e\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Ensure that the admin.conf file permissions are set to 600",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.1.13",
      "controlID": "CIS-1.1.13",
      "creationTime": "",
      "description": "Ensure that the `admin.conf` file has permissions of `600`.",
      "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchmod 600 /etc/kubernetes/admin.conf\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-admin.conf-file-permissions-are-set-to-600",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_control_plane_info(obj)\n\n\tfile_obj_path := [\"data\", \"adminConfigFile\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual permissions test    \n\tallowed_perms := 384 # == 0o600\n\tnot cautils.unix_permissions_allow(allowed_perms, file.permissions)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"the permissions of %s are too permissive. maximum allowed: %o. actual: %o\", [file.path, allowed_perms, file.permissions])\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chmod %o %s\", [allowed_perms, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_control_plane_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "ControlPlaneInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the `admin.conf` file has permissions of `600`.",
          "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchmod 600 /etc/kubernetes/admin.conf\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 7
    },
    {
      "guid": "",
      "name": "Ensure that the etcd data directory ownership is set to etcd:etcd",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.1.12",
      "controlID": "CIS-1.1.12",
      "creationTime": "",
      "description": "Ensure that the etcd data directory ownership is set to `etcd:etcd`.",
      "remediation": "On the etcd server node, get the etcd data directory, passed as an argument `--data-dir`, from the below command:\n\n \n```\nps -ef | grep etcd\n\n```\n Run the below command (based on the etcd data directory found above). For example,\n\n \n```\nchown etcd:etcd /var/lib/etcd\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-etcd-data-directory-ownership-is-set-to-etcd-etcd",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_control_plane_info(obj)\n\n\tfile_obj_path := [\"data\", \"etcdDataDir\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual ownership check\n\tallowed_user := \"root\"\n\tallowed_group := \"root\"\n\tnot allowed_ownership(file.ownership, allowed_user, allowed_group)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"%s is not owned by %s:%s (actual owners are %s:%s)\", [\n\t\tfile.path,\n\t\tallowed_user,\n\t\tallowed_group,\n\t\tfile.ownership.username,\n\t\tfile.ownership.groupname,\n\t])\n\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chown %s:%s %s\", [allowed_user, allowed_group, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_control_plane_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.error # Do not fail if ownership is not found\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.username == user\n\townership.groupname == group\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "ControlPlaneInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the etcd data directory ownership is set to `etcd:etcd`.",
          "remediation": "On the etcd server node, get the etcd data directory, passed as an argument `--data-dir`, from the below command:\n\n \n```\nps -ef | grep etcd\n\n```\n Run the below command (based on the etcd data directory found above). For example,\n\n \n```\nchown etcd:etcd /var/lib/etcd\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 7
    },
    {
      "guid": "",
      "name": "Ensure that the admin.conf file ownership is set to root:root",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.1.14",
      "controlID": "CIS-1.1.14",
      "creationTime": "",
      "description": "Ensure that the `admin.conf` file ownership is set to `root:root`.",
      "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchown root:root /etc/kubernetes/admin.conf\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-admin.conf-file-ownership-is-set-to-root-root",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_control_plane_info(obj)\n\n\tfile_obj_path := [\"data\", \"adminConfigFile\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual ownership check\n\tallowed_user := \"root\"\n\tallowed_group := \"root\"\n\tnot allowed_ownership(file.ownership, allowed_user, allowed_group)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"%s is not owned by %s:%s (actual owners are %s:%s)\", [\n\t\tfile.path,\n\t\tallowed_user,\n\t\tallowed_group,\n\t\tfile.ownership.username,\n\t\tfile.ownership.groupname,\n\t])\n\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chown %s:%s %s\", [allowed_user, allowed_group, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_control_plane_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.error # Do not fail if ownership is not found\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.username == user\n\townership.groupname == group\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "ControlPlaneInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the `admin.conf` file ownership is set to `root:root`.",
          "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchown root:root /etc/kubernetes/admin.conf\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 7
    },
    {
      "guid": "",
      "name": "Ensure that the scheduler.conf file permissions are set to 600 or more restrictive",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.1.15",
      "controlID": "CIS-1.1.15",
      "creationTime": "",
      "description": "Ensure that the `scheduler.conf` file has permissions of `600` or more restrictive.",
      "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchmod 600 /etc/kubernetes/scheduler.conf\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-scheduler.conf-file-permissions-are-set-to-600-or-more-restrictive",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_control_plane_info(obj)\n\n\tfile_obj_path := [\"data\", \"schedulerInfo\", \"configFile\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual permissions test    \n\tallowed_perms := 384 # == 0o600\n\tnot cautils.unix_permissions_allow(allowed_perms, file.permissions)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"the permissions of %s are too permissive. maximum allowed: %o. actual: %o\", [file.path, allowed_perms, file.permissions])\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chmod %o %s\", [allowed_perms, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_control_plane_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "ControlPlaneInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the `scheduler.conf` file has permissions of `600` or more restrictive.",
          "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchmod 600 /etc/kubernetes/scheduler.conf\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Ensure that the scheduler.conf file ownership is set to root:root",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.1.16",
      "controlID": "CIS-1.1.16",
      "creationTime": "",
      "description": "Ensure that the `scheduler.conf` file ownership is set to `root:root`.",
      "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchown root:root /etc/kubernetes/scheduler.conf\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-scheduler.conf-file-ownership-is-set-to-root-root",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_control_plane_info(obj)\n\n\tfile_obj_path := [\"data\", \"schedulerInfo\", \"configFile\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual ownership check\n\tallowed_user := \"root\"\n\tallowed_group := \"root\"\n\tnot allowed_ownership(file.ownership, allowed_user, allowed_group)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"%s is not owned by %s:%s (actual owners are %s:%s)\", [\n\t\tfile.path,\n\t\tallowed_user,\n\t\tallowed_group,\n\t\tfile.ownership.username,\n\t\tfile.ownership.groupname,\n\t])\n\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chown %s:%s %s\", [allowed_user, allowed_group, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_control_plane_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.error # Do not fail if ownership is not found\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.username == user\n\townership.groupname == group\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "ControlPlaneInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the `scheduler.conf` file ownership is set to `root:root`.",
          "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchown root:root /etc/kubernetes/scheduler.conf\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Ensure that the controller-manager.conf file permissions are set to 600 or more restrictive",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.1.17",
      "controlID": "CIS-1.1.17",
      "creationTime": "",
      "description": "Ensure that the `controller-manager.conf` file has permissions of 600 or more restrictive.",
      "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchmod 600 /etc/kubernetes/controller-manager.conf\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-controller-manager.conf-file-permissions-are-set-to-600-or-more-restrictive",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_control_plane_info(obj)\n\n\tfile_obj_path := [\"data\", \"controllerManagerInfo\", \"configFile\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual permissions test    \n\tallowed_perms := 384 # == 0o600\n\tnot cautils.unix_permissions_allow(allowed_perms, file.permissions)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"the permissions of %s are too permissive. maximum allowed: %o. actual: %o\", [file.path, allowed_perms, file.permissions])\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chmod %o %s\", [allowed_perms, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_control_plane_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "ControlPlaneInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the `controller-manager.conf` file has permissions of 600 or more restrictive.",
          "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchmod 600 /etc/kubernetes/controller-manager.conf\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Ensure that the controller-manager.conf file ownership is set to root:root",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.1.18",
      "controlID": "CIS-1.1.18",
      "creationTime": "",
      "description": "Ensure that the `controller-manager.conf` file ownership is set to `root:root`.",
      "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchown root:root /etc/kubernetes/controller-manager.conf\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-controller-manager.conf-file-ownership-is-set-to-root-root",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_control_plane_info(obj)\n\n\tfile_obj_path := [\"data\", \"controllerManagerInfo\", \"configFile\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual ownership check\n\tallowed_user := \"root\"\n\tallowed_group := \"root\"\n\tnot allowed_ownership(file.ownership, allowed_user, allowed_group)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"%s is not owned by %s:%s (actual owners are %s:%s)\", [\n\t\tfile.path,\n\t\tallowed_user,\n\t\tallowed_group,\n\t\tfile.ownership.username,\n\t\tfile.ownership.groupname,\n\t])\n\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chown %s:%s %s\", [allowed_user, allowed_group, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_control_plane_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.error # Do not fail if ownership is not found\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.username == user\n\townership.groupname == group\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "ControlPlaneInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the `controller-manager.conf` file ownership is set to `root:root`.",
          "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchown root:root /etc/kubernetes/controller-manager.conf\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Ensure that the Kubernetes PKI directory and file ownership is set to root:root",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.1.19",
      "controlID": "CIS-1.1.19",
      "creationTime": "",
      "description": "Ensure that the Kubernetes PKI directory and file ownership is set to `root:root`.",
      "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchown -R root:root /etc/kubernetes/pki/\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-Kubernetes-PKI-directory-and-file-ownership-is-set-to-root-root",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_control_plane_info(obj)\n\n\tfile_obj_path := [\"data\", \"PKIFiles\"]\n\tfiles := object.get(obj, file_obj_path, false)\n\tfile := files[file_index]\n\n\t# Actual ownership check\n\tallowed_user := \"root\"\n\tallowed_group := \"root\"\n\tnot allowed_ownership(file.ownership, allowed_user, allowed_group)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tsprintf(\"%s/%d\", [concat(\"/\", file_obj_path), file_index]), \"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"%s is not owned by %s:%s (actual owners are %s:%s)\", [\n\t\tfile.path,\n\t\tallowed_user,\n\t\tallowed_group,\n\t\tfile.ownership.username,\n\t\tfile.ownership.groupname,\n\t])\n\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chown %s:%s %s\", [allowed_user, allowed_group, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_control_plane_info(obj)\n\n\tfile_obj_path := [\"data\", \"PKIDir\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual ownership check\n\tallowed_user := \"root\"\n\tallowed_group := \"root\"\n\tnot allowed_ownership(file.ownership, allowed_user, allowed_group)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"%s is not owned by %s:%s (actual owners are %s:%s)\", [\n\t\tfile.path,\n\t\tallowed_user,\n\t\tallowed_group,\n\t\tfile.ownership.username,\n\t\tfile.ownership.groupname,\n\t])\n\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chown %s:%s %s\", [allowed_user, allowed_group, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_control_plane_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.error # Do not fail if ownership is not found\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.username == user\n\townership.groupname == group\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "ControlPlaneInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the Kubernetes PKI directory and file ownership is set to `root:root`.",
          "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchown -R root:root /etc/kubernetes/pki/\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 8
    },
    {
      "guid": "",
      "name": "Ensure that the API server pod specification file ownership is set to root:root",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.1.2",
      "controlID": "CIS-1.1.2",
      "creationTime": "",
      "description": "Ensure that the API server pod specification file ownership is set to `root:root`.",
      "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchown root:root /etc/kubernetes/manifests/kube-apiserver.yaml\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-API-server-pod-specification-file-ownership-is-set-to-root-root",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_control_plane_info(obj)\n\n\tfile_obj_path := [\"data\", \"APIServerInfo\", \"specsFile\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual ownership check\n\tallowed_user := \"root\"\n\tallowed_group := \"root\"\n\tnot allowed_ownership(file.ownership, allowed_user, allowed_group)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"%s is not owned by %s:%s (actual owners are %s:%s)\", [\n\t\tfile.path,\n\t\tallowed_user,\n\t\tallowed_group,\n\t\tfile.ownership.username,\n\t\tfile.ownership.groupname,\n\t])\n\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chown %s:%s %s\", [allowed_user, allowed_group, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_control_plane_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.error # Do not fail if ownership is not found\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.username == user\n\townership.groupname == group\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "ControlPlaneInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the API server pod specification file ownership is set to `root:root`.",
          "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchown root:root /etc/kubernetes/manifests/kube-apiserver.yaml\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Ensure that the Kubernetes PKI certificate file permissions are set to 600 or more restrictive",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.1.20",
      "controlID": "CIS-1.1.20",
      "creationTime": "",
      "description": "Ensure that Kubernetes PKI certificate files have permissions of `600` or more restrictive.",
      "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchmod -R 600 /etc/kubernetes/pki/*.crt\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-Kubernetes-PKI-certificate-file-permissions-are-set-to-600-or-more-restrictive",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_control_plane_info(obj)\n\n\tfile_obj_path := [\"data\", \"PKIFiles\"]\n\tfiles := object.get(obj, file_obj_path, false)\n\tfile := files[file_index]\n\tendswith(file.path, \".crt\")\n\n\t# Actual permissions test    \n\tallowed_perms := 384 # == 0o600\n\tnot cautils.unix_permissions_allow(allowed_perms, file.permissions)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tsprintf(\"%s/%d\", [concat(\"/\", file_obj_path), file_index]), \"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"the permissions of %s are too permissive. maximum allowed: %o. actual: %o\", [file.path, allowed_perms, file.permissions])\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chmod %o %s\", [allowed_perms, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_control_plane_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "ControlPlaneInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that Kubernetes PKI certificate files have permissions of `600` or more restrictive.",
          "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchmod -R 600 /etc/kubernetes/pki/*.crt\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 8
    },
    {
      "guid": "",
      "name": "Ensure that the Kubernetes PKI key file permissions are set to 600",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.1.21",
      "controlID": "CIS-1.1.21",
      "creationTime": "",
      "description": "Ensure that Kubernetes PKI key files have permissions of `600`.",
      "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchmod -R 600 /etc/kubernetes/pki/*.key\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-Kubernetes-PKI-key-file-permissions-are-set-to-600",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_control_plane_info(obj)\n\n\tfile_obj_path := [\"data\", \"PKIFiles\"]\n\tfiles := object.get(obj, file_obj_path, false)\n\tfile := files[file_index]\n\tendswith(file.path, \".key\")\n\n\t# Actual permissions test    \n\tallowed_perms := 384 # == 0o600\n\tnot cautils.unix_permissions_allow(allowed_perms, file.permissions)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tsprintf(\"%s/%d\", [concat(\"/\", file_obj_path), file_index]), \"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"the permissions of %s are too permissive. maximum allowed: %o. actual: %o\", [file.path, allowed_perms, file.permissions])\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chmod %o %s\", [allowed_perms, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_control_plane_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "ControlPlaneInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that Kubernetes PKI key files have permissions of `600`.",
          "remediation": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\n \n```\nchmod -R 600 /etc/kubernetes/pki/*.key\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 8
    },
    {
      "guid": "",
      "name": "Ensure that the API Server --service-account-key-file argument is set as appropriate",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.24",
      "controlID": "CIS-1.2.24",
      "creationTime": "",
      "description": "Explicitly set a service account public key file for service accounts on the apiserver.",
      "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the `--service-account-key-file` parameter to the public key file for service accounts:\n\n \n```\n--service-account-key-file=\u003cfilename\u003e\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-api-server-service-account-key-file-argument-is-set-as-appropriate",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true",
            "useFromKubescapeVersion": "v2.0.159"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": \"TLS certificate authority\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tfull_cmd = concat(\" \", cmd)\n\tnot contains(full_cmd, \"--service-account-key-file\")\n\tresult := {\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": sprintf(\"spec.containers[0].command[%d]\", [count(cmd)]),\n\t\t\t\"value\": \"--service-account-key-file=\u003cpath/to/key.pub\u003e\",\n\t\t}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Explicitly set a service account public key file for service accounts on the apiserver.",
          "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the `--service-account-key-file` parameter to the public key file for service accounts:\n\n \n```\n--service-account-key-file=\u003cfilename\u003e\n\n```\n\n#### Impact Statement\nThe corresponding private key must be provided to the controller manager. You would need to securely maintain the key file and rotate the keys based on your organization's key rotation policy.\n\n#### Default Value\nBy default, `--service-account-key-file` argument is not set.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 5
    },
    {
      "guid": "",
      "name": "Ensure that the API Server --request-timeout argument is set as appropriate",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.22",
      "controlID": "CIS-1.2.22",
      "creationTime": "",
      "description": "Set global request timeout for API server requests as appropriate.",
      "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` and set the below parameter as appropriate and if needed. For example,\n\n \n```\n--request-timeout=300s\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-api-server-request-timeout-argument-is-set-as-appropriate",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": result.alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tcontains(cmd[i], \"--request-timeout\")\n\tresult = {\n\t\t\"alert\": \"Please validate the request timeout flag is set to an appropriate value\",\n\t\t\"failed_paths\": [sprintf(\"spec.containers[0].command[%v]\", [i])],\n\t\t\"fix_paths\": [],\n\t}\n}",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Set global request timeout for API server requests as appropriate.",
          "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` and set the below parameter as appropriate and if needed. For example,\n\n \n```\n--request-timeout=300s\n\n```\n\n#### Impact Statement\nNone\n\n#### Default Value\nBy default, `--request-timeout` is set to 60 seconds.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 4
    },
    {
      "guid": "",
      "name": "Ensure that the API Server --DenyServiceExternalIPs is not set",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.3",
      "controlID": "CIS-1.2.3",
      "creationTime": "",
      "description": "This admission controller rejects all net-new usage of the Service field externalIPs.",
      "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the master node and remove the `--DenyServiceExternalIPs'parameter\n\n or\n\n The Kubernetes API server flag disable-admission-plugins takes a comma-delimited list of admission control plugins to be disabled, even if they are in the list of plugins enabled by default.\n\n `kube-apiserver --disable-admission-plugins=DenyServiceExternalIPs,AlwaysDeny ...`",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-api-server-DenyServiceExternalIPs-is-not-set",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": \"admission control plugin DenyServiceExternalIPs is enabled. This is equal to turning off all admission controllers\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\nget_flag_values(cmd) = {\"origin\": origin, \"values\": values} {\n\tre := \" ?--enable-admission-plugins=(.+?)(?: |$)\"\n\tmatchs := regex.find_all_string_submatch_n(re, cmd, -1)\n\tcount(matchs) == 1\n\tvalues := [val | val := split(matchs[0][1], \",\")[j]; val != \"\"]\n\torigin := matchs[0][0]\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tflag := get_flag_values(cmd[i])\n\n\t# value check\n\t\"DenyServiceExternalIPs\" in flag.values\n\n\t# get fixed and failed paths\n\tfixed_values := [val | val := flag.values[j]; val != \"DenyServiceExternalIPs\"]\n\tresult = get_retsult(fixed_values, i)\n}\n\nget_retsult(fixed_values, i) = result {\n\tcount(fixed_values) == 0\n\tresult = {\n\t\t\"failed_paths\": [sprintf(\"spec.containers[0].command[%v]\", [i])],\n\t\t\"fix_paths\": [],\n\t}\n}\n\nget_retsult(fixed_values, i) = result {\n\tcount(fixed_values) \u003e 0\n\tpath = sprintf(\"spec.containers[0].command[%v]\", [i])\n\tresult = {\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": path,\n\t\t\t\"value\": sprintf(\"--enable-admission-plugins=%v\", [concat(\",\", fixed_values)]),\n\t\t}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "This admission controller rejects all net-new usage of the Service field externalIPs.",
          "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the master node and remove the `--DenyServiceExternalIPs'parameter\n\n or\n\n The Kubernetes API server flag disable-admission-plugins takes a comma-delimited list of admission control plugins to be disabled, even if they are in the list of plugins enabled by default.\n\n `kube-apiserver --disable-admission-plugins=DenyServiceExternalIPs,AlwaysDeny ...`\n\n#### Impact Statement\nWhen enabled, users of the cluster may not create new Services which use externalIPs and may not add new values to externalIPs on existing Service objects.\n\n#### Default Value\nBy default, `--token-auth-file` argument is not set.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 4
    },
    {
      "guid": "",
      "name": "Ensure that the API Server --authorization-mode argument is not set to AlwaysAllow",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.6",
      "controlID": "CIS-1.2.6",
      "creationTime": "",
      "description": "Do not always authorize all requests.",
      "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the `--authorization-mode` parameter to values other than `AlwaysAllow`. One such example could be as below.\n\n \n```\n--authorization-mode=RBAC\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-api-server-authorization-mode-argument-is-not-set-to-AlwaysAllow",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": \"AlwaysAllow authorization mode is enabled\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\nget_flag_values(cmd) = {\"origin\": origin, \"values\": values} {\n\tre := \" ?--authorization-mode=(.+?)(?: |$)\"\n\tmatchs := regex.find_all_string_submatch_n(re, cmd, -1)\n\tcount(matchs) == 1\n\tvalues := [val | val := split(matchs[0][1], \",\")[j]; val != \"\"]\n\torigin := matchs[0][0]\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tflag := get_flag_values(cmd[i])\n\n\t# Check if include AlwaysAllow\n\t\"AlwaysAllow\" in flag.values\n\n\t# get fixed and failed paths\n\tfixed_values := [val | val = flag.values[_]; val != \"AlwaysAllow\"]\n\tfixed_flag = get_fixed_flag(fixed_values)\n\tfixed_cmd = replace(cmd[i], flag.origin, fixed_flag)\n\tpath := sprintf(\"spec.containers[0].command[%d]\", [i])\n\n\tresult := {\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": path,\n\t\t\t\"value\": fixed_cmd,\n\t\t}],\n\t}\n}\n\n\nget_fixed_flag(values) = fixed {\n\tcount(values) == 0\n\tfixed = \"--authorization-mode=RBAC\" # If no authorization-mode, set it to RBAC, as recommended by CIS\n}\nget_fixed_flag(values) = fixed {\n\tcount(values) \u003e 0\n\tfixed = sprintf(\"--authorization-mode=%s\", [concat(\",\", values)])\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Do not always authorize all requests.",
          "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the `--authorization-mode` parameter to values other than `AlwaysAllow`. One such example could be as below.\n\n \n```\n--authorization-mode=RBAC\n\n```\n\n#### Impact Statement\nOnly authorized requests will be served.\n\n#### Default Value\nBy default, `AlwaysAllow` is not enabled.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 7
    },
    {
      "guid": "",
      "name": "Ensure that the API Server --kubelet-client-certificate and --kubelet-client-key arguments are set as appropriate",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.4",
      "controlID": "CIS-1.2.4",
      "creationTime": "",
      "description": "Enable certificate based kubelet authentication.",
      "remediation": "Follow the Kubernetes documentation and set up the TLS connection between the apiserver and kubelets. Then, edit API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the kubelet client certificate and key parameters as below.\n\n \n```\n--kubelet-client-certificate=\u003cpath/to/client-certificate-file\u003e\n--kubelet-client-key=\u003cpath/to/client-key-file\u003e\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-api-server-kubelet-client-certificate-and-kubelet-client-key-arguments-are-set-as-appropriate",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": \"certificate based kubelet authentication is not enabled\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tfull_cmd = concat(\" \", cmd)\n\twanted = [\n\t\t\"--kubelet-client-certificate\",\n\t\t\"--kubelet-client-key\",\n\t]\n\n\tfix_paths = [{\n\t\t\"path\": sprintf(\"spec.containers[0].command[%d]\", [count(cmd) + i]),\n\t\t\"value\": sprintf(\"%s=\u003cpath/to/appropriate/file\u003e\", [wanted[i]]),\n\t} |\n\t\twanted[i]\n\t\tnot contains(full_cmd, wanted[i])\n\t]\n\n\tcount(fix_paths) \u003e 0\n\n\tresult = {\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": fix_paths,\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Enable certificate based kubelet authentication.",
          "remediation": "Follow the Kubernetes documentation and set up the TLS connection between the apiserver and kubelets. Then, edit API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the kubelet client certificate and key parameters as below.\n\n \n```\n--kubelet-client-certificate=\u003cpath/to/client-certificate-file\u003e\n--kubelet-client-key=\u003cpath/to/client-key-file\u003e\n\n```\n\n#### Impact Statement\nYou require TLS to be configured on apiserver as well as kubelets.\n\n#### Default Value\nBy default, certificate-based kubelet authentication is not set.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 7
    },
    {
      "guid": "",
      "name": "Ensure that the API Server --etcd-certfile and --etcd-keyfile arguments are set as appropriate",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.25",
      "controlID": "CIS-1.2.25",
      "creationTime": "",
      "description": "etcd should be configured to make use of TLS encryption for client connections.",
      "remediation": "Follow the Kubernetes documentation and set up the TLS connection between the apiserver and etcd. Then, edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the master node and set the etcd certificate and key file parameters.\n\n \n```\n--etcd-certfile=\u003cpath/to/client-certificate-file\u003e \n--etcd-keyfile=\u003cpath/to/client-key-file\u003e\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-api-server-etcd-certfile-and-etcd-keyfile-arguments-are-set-as-appropriate",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": \"etcd is not configured to use TLS properly\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tfull_cmd = concat(\" \", cmd)\n\twanted = [\n\t\t[\"--etcd-certfile\", \"\u003cpath/to/client-certificate-file.crt\u003e\"],\n\t\t[\"--etcd-keyfile\", \"\u003cpath/to/client-key-file.key\u003e\"],\n\t]\n\n\tfix_paths = [{\n\t\t\"path\": sprintf(\"spec.containers[0].command[%d]\", [count(cmd) + i]),\n\t\t\"value\": sprintf(\"%s=%s\", wanted[i]),\n\t} |\n\t\tnot contains(full_cmd, wanted[i][0])\n\t]\n\n\tcount(fix_paths) \u003e 0\n\n\tresult = {\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": fix_paths,\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "etcd should be configured to make use of TLS encryption for client connections.",
          "remediation": "Follow the Kubernetes documentation and set up the TLS connection between the apiserver and etcd. Then, edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the master node and set the etcd certificate and key file parameters.\n\n \n```\n--etcd-certfile=\u003cpath/to/client-certificate-file\u003e \n--etcd-keyfile=\u003cpath/to/client-key-file\u003e\n\n```\n\n#### Impact Statement\nTLS and client certificate authentication must be configured for etcd.\n\n#### Default Value\nBy default, `--etcd-certfile` and `--etcd-keyfile` arguments are not set",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 8
    },
    {
      "guid": "",
      "name": "Ensure that the API Server --authorization-mode argument includes RBAC",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.8",
      "controlID": "CIS-1.2.8",
      "creationTime": "",
      "description": "Turn on Role Based Access Control.",
      "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the `--authorization-mode` parameter to a value that includes `RBAC`, for example:\n\n \n```\n--authorization-mode=Node,RBAC\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-api-server-authorization-mode-argument-includes-RBAC",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": \"RBAC is not enabled\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\nget_flag_values(cmd) = {\"origin\": origin, \"values\": values} {\n\tre := \" ?--authorization-mode=(.+?)(?: |$)\"\n\tmatchs := regex.find_all_string_submatch_n(re, cmd, -1)\n\tcount(matchs) == 1\n\tvalues := [val | val := split(matchs[0][1], \",\")[j]; val != \"\"]\n\torigin := matchs[0][0]\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tflag := get_flag_values(cmd[i])\n\n\t# value check\n\tnot \"RBAC\" in flag.values\n\n\t# get fixed and failed paths\n\tfixed_values := array.concat(flag.values, [\"RBAC\"])\n\tfixed_flag = sprintf(\"%s=%s\", [\"--authorization-mode\", concat(\",\", fixed_values)])\n\tfixed_cmd = replace(cmd[i], flag.origin, fixed_flag)\n\tpath := sprintf(\"spec.containers[0].command[%d]\", [i])\n\n\tresult := {\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": path,\n\t\t\t\"value\": fixed_cmd,\n\t\t}],\n\t}\n}\n\ninvalid_flag(cmd) = result {\n\tfull_cmd := concat(\" \", cmd)\n\tnot contains(full_cmd, \"--authorization-mode\")\n\n\tpath = sprintf(\"spec.containers[0].command[%d]\", [count(cmd)])\n\tresult = {\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": path,\n\t\t\t\"value\": \"--authorization-mode=RBAC\",\n\t\t}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Turn on Role Based Access Control.",
          "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the `--authorization-mode` parameter to a value that includes `RBAC`, for example:\n\n \n```\n--authorization-mode=Node,RBAC\n\n```\n\n#### Impact Statement\nWhen RBAC is enabled you will need to ensure that appropriate RBAC settings (including Roles, RoleBindings and ClusterRoleBindings) are configured to allow appropriate access.\n\n#### Default Value\nBy default, `RBAC` authorization is not enabled.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 8
    },
    {
      "guid": "",
      "name": "Ensure that the API Server --audit-log-maxage argument is set to 30 or as appropriate",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.19",
      "controlID": "CIS-1.2.19",
      "creationTime": "",
      "description": "Retain the logs for at least 30 days or as appropriate.",
      "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the `--audit-log-maxage` parameter to 30 or as an appropriate number of days:\n\n \n```\n--audit-log-maxage=30\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-api-server-audit-log-maxage-argument-is-set-to-30-or-as-appropriate",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": result.alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\nget_flag_value(cmd) = {\"origin\": origin, \"value\": value} {\n\tre := \" ?--audit-log-maxage=(.+?)(?: |$)\"\n\tmatchs := regex.find_all_string_submatch_n(re, cmd, -1)\n\tcount(matchs) == 1\n\tvalue = to_number(matchs[0][1])\n\torigin := matchs[0][0]\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tflag = get_flag_value(cmd[i])\n\tflag.value \u003c 30\n\tfixed = replace(cmd[i], flag.origin, \"--audit-log-maxage=30\")\n\tpath = sprintf(\"spec.containers[0].command[%v]\", [i])\n\tresult = {\n\t\t\"alert\": sprintf(\"Audit log retention period is %v days, which is too small (should be at least 30 days)\", [flag.value]),\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\"path\": path, \"value\": fixed}],\n\t}\n}\n\ninvalid_flag(cmd) = result {\n\tfull_cmd = concat(\" \", cmd)\n\tnot contains(full_cmd, \"--audit-log-maxage\")\n\tresult = {\n\t\t\"alert\": \"Audit log retention period is not set\",\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": sprintf(\"spec.containers[0].command[%v]\", [count(cmd)]),\n\t\t\t\"value\": \"--audit-log-maxage=30\",\n\t\t}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Retain the logs for at least 30 days or as appropriate.",
          "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the `--audit-log-maxage` parameter to 30 or as an appropriate number of days:\n\n \n```\n--audit-log-maxage=30\n\n```\n\n#### Impact Statement\nNone\n\n#### Default Value\nBy default, auditing is not enabled.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 4
    },
    {
      "guid": "",
      "name": "Ensure that the admission control plugin AlwaysAdmit is not set",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.10",
      "controlID": "CIS-1.2.10",
      "creationTime": "",
      "description": "Do not allow all requests.",
      "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and either remove the `--enable-admission-plugins` parameter, or set it to a value that does not include `AlwaysAdmit`.",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-admission-control-plugin-AlwaysAdmit-is-not-set",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": \"admission control plugin AlwaysAdmit is enabled. This is equal to turning off all admission controllers\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\nget_flag_values(cmd) = {\"origin\": origin, \"values\": values} {\n\tre := \" ?--enable-admission-plugins=(.+?)(?: |$)\"\n\tmatchs := regex.find_all_string_submatch_n(re, cmd, -1)\n\tcount(matchs) == 1\n\tvalues := [val | val := split(matchs[0][1], \",\")[j]; val != \"\"]\n\torigin := matchs[0][0]\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\t\n\tflag := get_flag_values(cmd[i])\n\n\t# value check\n\t\"AlwaysAdmit\" in flag.values\n\n\t# get fixed and failed paths\n\tfixed_values := [val | val := flag.values[j]; val != \"AlwaysAdmit\"]\n\tresult = get_retsult(fixed_values, i)\n}\n\nget_retsult(fixed_values, i) = result {\n\tcount(fixed_values) == 0\n\tresult = {\n\t\t\"failed_paths\": [sprintf(\"spec.containers[0].command[%v]\", [i])],\n\t\t\"fix_paths\": [],\n\t}\n}\n\nget_retsult(fixed_values, i) = result {\n\tcount(fixed_values) \u003e 0\n\tpath = sprintf(\"spec.containers[0].command[%v]\", [i])\n\tresult = {\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": path,\n\t\t\t\"value\": sprintf(\"--enable-admission-plugins=%v\", [concat(\",\", fixed_values)]),\n\t\t}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Do not allow all requests.",
          "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and either remove the `--enable-admission-plugins` parameter, or set it to a value that does not include `AlwaysAdmit`.\n\n#### Impact Statement\nOnly requests explicitly allowed by the admissions control plugins would be served.\n\n#### Default Value\n`AlwaysAdmit` is not in the list of default admission plugins.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 8
    },
    {
      "guid": "",
      "name": "Ensure that the API Server --service-account-lookup argument is set to true",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.23",
      "controlID": "CIS-1.2.23",
      "creationTime": "",
      "description": "Validate service account before validating token.",
      "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the below parameter.\n\n \n```\n--service-account-lookup=true\n\n```\n Alternatively, you can delete the `--service-account-lookup` parameter from this file so that the default takes effect.",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-api-server-service-account-lookup-argument-is-set-to-true",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": \"anonymous requests is enabled\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tresult = get_result(cmd[i], i)\n}\n\nget_result(cmd, i) = result {\n\tcmd == \"--service-account-lookup=false\"\n\tresult = {\n\t\t\"failed_paths\": [sprintf(\"spec.containers[0].command[%v]\", [i])],\n\t\t\"fix_paths\": [],\n\t}\n}\n\nget_result(cmd, i) = result {\n\tcmd != \"--service-account-lookup=false\"\n\tcontains(cmd, \"--service-account-lookup=false\")\n\tpath = sprintf(\"spec.containers[0].command[%v]\", [i])\n\tresult = {\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": path,\n\t\t\t\"value\": replace(cmd, \"--service-account-lookup=false\", \"--service-account-lookup=true\"),\n\t\t}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Validate service account before validating token.",
          "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the below parameter.\n\n \n```\n--service-account-lookup=true\n\n```\n Alternatively, you can delete the `--service-account-lookup` parameter from this file so that the default takes effect.\n\n#### Impact Statement\nNone\n\n#### Default Value\nBy default, `--service-account-lookup` argument is set to `true`.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Ensure that the API Server --authorization-mode argument includes Node",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.7",
      "controlID": "CIS-1.2.7",
      "creationTime": "",
      "description": "Restrict kubelet nodes to reading only objects associated with them.",
      "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the `--authorization-mode` parameter to a value that includes `Node`.\n\n \n```\n--authorization-mode=Node,RBAC\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-api-server-authorization-mode-argument-includes-Node",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": \"kubelet nodes can read objects that are not associated with them\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\nget_flag_values(cmd) = {\"origin\": origin, \"values\": values} {\n\tre := \" ?--authorization-mode=(.+?)(?: |$)\"\n\tmatchs := regex.find_all_string_submatch_n(re, cmd, -1)\n\tcount(matchs) == 1\n\tvalues := [val | val := split(matchs[0][1], \",\")[j]; val != \"\"]\n\torigin := matchs[0][0]\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tflag := get_flag_values(cmd[i])\n\n\t# value check\n\tnot \"Node\" in flag.values\n\n\t# get fixed and failed paths\n\tfixed_values := array.concat(flag.values, [\"Node\"])\n\tfixed_flag = sprintf(\"%s=%s\", [\"--authorization-mode\", concat(\",\", fixed_values)])\n\tfixed_cmd = replace(cmd[i], flag.origin, fixed_flag)\n\tpath := sprintf(\"spec.containers[0].command[%d]\", [i])\n\n\tresult := {\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": path,\n\t\t\t\"value\": fixed_cmd,\n\t\t}],\n\t}\n}\n\ninvalid_flag(cmd) = result {\n\tfull_cmd := concat(\" \", cmd)\n\tnot contains(full_cmd, \"--authorization-mode\")\n\n\tpath = sprintf(\"spec.containers[0].command[%d]\", [count(cmd)])\n\tresult = {\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": path,\n\t\t\t\"value\": \"--authorization-mode=Node\",\n\t\t}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Restrict kubelet nodes to reading only objects associated with them.",
          "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the `--authorization-mode` parameter to a value that includes `Node`.\n\n \n```\n--authorization-mode=Node,RBAC\n\n```\n\n#### Impact Statement\nNone\n\n#### Default Value\nBy default, `Node` authorization is not enabled.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 5
    },
    {
      "guid": "",
      "name": "Ensure that the API Server --tls-cert-file and --tls-private-key-file arguments are set as appropriate",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.26",
      "controlID": "CIS-1.2.26",
      "creationTime": "",
      "description": "Setup TLS connection on the API server.",
      "remediation": "Follow the Kubernetes documentation and set up the TLS connection on the apiserver. Then, edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the master node and set the TLS certificate and private key file parameters.\n\n \n```\n--tls-cert-file=\u003cpath/to/tls-certificate-file\u003e \n--tls-private-key-file=\u003cpath/to/tls-key-file\u003e\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-api-server-tls-cert-file-and-tls-private-key-file-arguments-are-set-as-appropriate",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": \"API server is not configured to serve only HTTPS traffic\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tfull_cmd = concat(\" \", cmd)\n\twanted = [\n\t\t[\"--tls-cert-file\", \"\u003cpath/to/tls-certificate-file.crt\u003e\"],\n\t\t[\"--tls-private-key-file\", \"\u003cpath/to/tls-key-file.key\u003e\"],\n\t]\n\n\tfix_paths = [{\n\t\t\"path\": sprintf(\"spec.containers[0].command[%d]\", [count(cmd) + i]),\n\t\t\"value\": sprintf(\"%s=%s\", wanted[i]),\n\t} |\n\t\tnot contains(full_cmd, wanted[i][0])\n\t]\n\n\tcount(fix_paths) \u003e 0\n\n\tresult = {\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": fix_paths,\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Setup TLS connection on the API server.",
          "remediation": "Follow the Kubernetes documentation and set up the TLS connection on the apiserver. Then, edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the master node and set the TLS certificate and private key file parameters.\n\n \n```\n--tls-cert-file=\u003cpath/to/tls-certificate-file\u003e \n--tls-private-key-file=\u003cpath/to/tls-key-file\u003e\n\n```\n\n#### Impact Statement\nTLS and client certificate authentication must be configured for your Kubernetes cluster deployment.\n\n#### Default Value\nBy default, `--tls-cert-file` and `--tls-private-key-file` arguments are not set.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 8
    },
    {
      "guid": "",
      "name": "Ensure that the API Server --profiling argument is set to false",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.17",
      "controlID": "CIS-1.2.17",
      "creationTime": "",
      "description": "Disable profiling, if not needed.",
      "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the below parameter.\n\n \n```\n--profiling=false\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-api-server-profiling-argument-is-set-to-false",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": \"profiling is enabled. This could potentially be exploited to uncover system and program details.\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tcontains(cmd[i], \"--profiling=true\")\n\tfixed = replace(cmd[i], \"--profiling=true\", \"--profiling=false\")\n\tpath := sprintf(\"spec.containers[0].command[%d]\", [i])\n\tresult = {\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\"path\": path, \"value\": fixed}],\n\t}\n}\n\ninvalid_flag(cmd) = result {\n\tfull_cmd = concat(\" \", cmd)\n\tnot contains(full_cmd, \"--profiling\")\n\tpath := sprintf(\"spec.containers[0].command[%d]\", [count(cmd)])\n\tresult = {\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": path,\n\t\t\t\"value\": \"--profiling=false\",\n\t\t}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Disable profiling, if not needed.",
          "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the below parameter.\n\n \n```\n--profiling=false\n\n```\n\n#### Impact Statement\nProfiling information would not be available.\n\n#### Default Value\nBy default, profiling is enabled.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 3
    },
    {
      "guid": "",
      "name": "Ensure that the API Server --audit-log-maxbackup argument is set to 10 or as appropriate",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.20",
      "controlID": "CIS-1.2.20",
      "creationTime": "",
      "description": "Retain 10 or an appropriate number of old log files.",
      "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the `--audit-log-maxbackup` parameter to 10 or to an appropriate value.\n\n \n```\n--audit-log-maxbackup=10\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-api-server-audit-log-maxbackup-argument-is-set-to-10-or-as-appropriate",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": result.alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tcontains(cmd[i], \"--audit-log-maxbackup\")\n\tresult = {\n\t\t\"alert\": \"Please validate that the audit log max backup is set to an appropriate value\",\n\t\t\"failed_paths\": [sprintf(\"spec.containers[0].command[%v]\", [i])],\n\t\t\"fix_paths\": [],\n\t}\n}\n\ninvalid_flag(cmd) = result {\n\tfull_cmd = concat(\" \", cmd)\n\tnot contains(full_cmd, \"--audit-log-maxbackup\")\n\tpath = sprintf(\"spec.containers[0].command[%v]\", [count(cmd)])\n\tresult = {\n\t\t\"alert\": \"Audit log max backup is not set\",\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\"path\": path, \"value\": \"--audit-log-maxbackup=YOUR_VALUE\"}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Retain 10 or an appropriate number of old log files.",
          "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the `--audit-log-maxbackup` parameter to 10 or to an appropriate value.\n\n \n```\n--audit-log-maxbackup=10\n\n```\n\n#### Impact Statement\nNone\n\n#### Default Value\nBy default, auditing is not enabled.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 4
    },
    {
      "guid": "",
      "name": "Ensure that the API Server only makes use of Strong Cryptographic Ciphers",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.31",
      "controlID": "CIS-1.2.31",
      "creationTime": "",
      "description": "Ensure that the API server is configured to only use strong cryptographic ciphers.",
      "remediation": "Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and set the below parameter.\n\n \n```\n--tls-cipher-suites=TLS_AES_128_GCM_SHA256, TLS_AES_256_GCM_SHA384, TLS_CHACHA20_POLY1305_SHA256, TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA, TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA, TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305, TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256, TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305, TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256, TLS_RSA_WITH_3DES_EDE_CBC_SHA, TLS_RSA_WITH_AES_128_CBC_SHA, TLS_RSA_WITH_AES_128_GCM_SHA256, TLS_RSA_WITH_AES_256_CBC_SHA, TLS_RSA_WITH_AES_256_GCM_SHA384.\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-API-Server-only-makes-use-of-Strong-Cryptographic-Ciphers",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\twanted = [\n\t\t\"TLS_AES_128_GCM_SHA256\",\n\t\t\"TLS_AES_256_GCM_SHA384\",\n\t\t\"TLS_CHACHA20_POLY1305_SHA256\",\n\t\t\"TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA\",\n\t\t\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\",\n\t\t\"TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA\",\n\t\t\"TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\",\n\t\t\"TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\",\n\t\t\"TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256\",\n\t\t\"TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA\",\n\t\t\"TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA\",\n\t\t\"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\",\n\t\t\"TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA\",\n\t\t\"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\",\n\t\t\"TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305\",\n\t\t\"TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\",\n\t\t\"TLS_RSA_WITH_3DES_EDE_CBC_SHA\",\n\t\t\"TLS_RSA_WITH_AES_128_CBC_SHA\",\n\t\t\"TLS_RSA_WITH_AES_128_GCM_SHA256\",\n\t\t\"TLS_RSA_WITH_AES_256_CBC_SHA\",\n\t\t\"TLS_RSA_WITH_AES_256_GCM_SHA384\",\n\t]\n\tresult = invalid_flag(obj.spec.containers[0].command, wanted)\n\tmsg := {\n\t\t\"alertMessage\": \"The API server is not configured to use strong cryptographic ciphers\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\nget_flag_values(cmd) = {\"origin\": origin, \"values\": values} {\n\tre := \" ?--tls-cipher-suites=(.+?)(?: |$)\"\n\tmatchs := regex.find_all_string_submatch_n(re, cmd, -1)\n\tcount(matchs) == 1\n\tvalues := [val | val := split(matchs[0][1], \",\")[j]; val != \"\"]\n\torigin := matchs[0][0]\n}\n\n\n# Assume flag set only once\ninvalid_flag(cmd, wanted) = result {\n\tflag := get_flag_values(cmd[i])\n\n\t# value check\n\tmissing = [x | x = wanted[_]; not x in flag.values]\n\tcount(missing) \u003e 0\n\n\t# get fixed and failed paths\n\tfixed_values := array.concat(flag.values, missing)\n\tfixed_flag = sprintf(\"%s=%s\", [\"--tls-cipher-suites\", concat(\",\", fixed_values)])\n\tfixed_cmd = replace(cmd[i], flag.origin, fixed_flag)\n\tpath := sprintf(\"spec.containers[0].command[%d]\", [i])\n\n\tresult := {\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": path,\n\t\t\t\"value\": fixed_cmd,\n\t\t}],\n\t}\n}\n\ninvalid_flag(cmd, wanted) = result {\n\tfull_cmd := concat(\" \", cmd)\n\tnot contains(full_cmd, \"--tls-cipher-suites\")\n\n\tpath = sprintf(\"spec.containers[0].command[%d]\", [count(cmd)])\n\tresult = {\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": path,\n\t\t\t\"value\": sprintf(\"--tls-cipher-suites=%s\", [concat(\",\", wanted)]),\n\t\t}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the API server is configured to only use strong cryptographic ciphers.",
          "remediation": "Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and set the below parameter.\n\n \n```\n--tls-cipher-suites=TLS_AES_128_GCM_SHA256, TLS_AES_256_GCM_SHA384, TLS_CHACHA20_POLY1305_SHA256, TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA, TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA, TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305, TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256, TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305, TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256, TLS_RSA_WITH_3DES_EDE_CBC_SHA, TLS_RSA_WITH_AES_128_CBC_SHA, TLS_RSA_WITH_AES_128_GCM_SHA256, TLS_RSA_WITH_AES_256_CBC_SHA, TLS_RSA_WITH_AES_256_GCM_SHA384.\n\n```\n\n#### Impact Statement\nAPI server clients that cannot support modern cryptographic ciphers will not be able to make connections to the API server.\n\n#### Default Value\nBy default the Kubernetes API server supports a wide range of TLS ciphers",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 5
    },
    {
      "guid": "",
      "name": "Ensure that the API Server --kubelet-certificate-authority argument is set as appropriate",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.5",
      "controlID": "CIS-1.2.5",
      "creationTime": "",
      "description": "Verify kubelet's certificate before establishing connection.",
      "remediation": "Follow the Kubernetes documentation and setup the TLS connection between the apiserver and kubelets. Then, edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the `--kubelet-certificate-authority` parameter to the path to the cert file for the certificate authority.\n\n \n```\n--kubelet-certificate-authority=\u003cca-string\u003e\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-api-server-kubelet-certificate-authority-argument-is-set-as-appropriate",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": \"TLS certificate authority file is not specified\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tfull_cmd = concat(\" \", cmd)\n\tnot contains(full_cmd, \"--kubelet-certificate-authority\")\n\tresult := {\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": sprintf(\"spec.containers[0].command[%d]\", [count(cmd)]),\n\t\t\t\"value\": \"--kubelet-certificate-authority=\u003cpath/to/ca.crt\u003e\",\n\t\t}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Verify kubelet's certificate before establishing connection.",
          "remediation": "Follow the Kubernetes documentation and setup the TLS connection between the apiserver and kubelets. Then, edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the `--kubelet-certificate-authority` parameter to the path to the cert file for the certificate authority.\n\n \n```\n--kubelet-certificate-authority=\u003cca-string\u003e\n\n```\n\n#### Impact Statement\nYou require TLS to be configured on apiserver as well as kubelets.\n\n#### Default Value\nBy default, `--kubelet-certificate-authority` argument is not set.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 8
    },
    {
      "guid": "",
      "name": "Ensure that the API Server --encryption-provider-config argument is set as appropriate",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.29",
      "controlID": "CIS-1.2.29",
      "creationTime": "",
      "description": "Encrypt etcd key-value store.",
      "remediation": "Follow the Kubernetes documentation and configure a `EncryptionConfig` file. Then, edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the master node and set the `--encryption-provider-config` parameter to the path of that file:\n\n \n```\n--encryption-provider-config=\u003c/path/to/EncryptionConfig/File\u003e\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-api-server-encryption-provider-config-argument-is-set-as-appropriate",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n# Encryption config is not set at all \ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\n\tcmd := obj.spec.containers[0].command\n\tnot contains(concat(\" \", cmd), \"--encryption-provider-config\")\n\n\tmsg := {\n\t\t\"alertMessage\": \"Encryption provider config file not set\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [{\n\t\t\t\"path\": sprintf(\"spec.containers[0].command[%d]\", [count(cmd)]),\n\t\t\t\"value\": \"--encryption-provider-config=\u003cpath/to/encryption-config.yaml\u003e\",\n\t\t}],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\n# Encryption config is set but not covering secrets\ndeny[msg] {\n\tobj = input[_]\n\tis_control_plane_info(obj)\n\tconfig_file := obj.data.APIServerInfo.encryptionProviderConfigFile\n\tconfig_file_content = decode_config_file(base64.decode(config_file.content))\n\n\t# Check if the config conver secrets\n\tcount({true | \"secrets\" in config_file_content.resources[_].resources}) == 0\n\t\n\t# Add name to the failed object so that\n\t# it fit the format of the alert object\n\tfailed_obj := json.patch(config_file_content, [{\n\t\t\"op\": \"add\",\n\t\t\"path\": \"name\",\n\t\t\"value\": \"encryption-provider-config\",\n\t}])\n\n\tmsg := {\n\t\t\"alertMessage\": \"Encryption provider config is not covering secrets\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": failed_obj},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\nis_control_plane_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n\ndecode_config_file(content) := data {\n\tdata := yaml.unmarshal(content)\n} else := json.unmarshal(content)\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tfilter_input(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nfilter_input(obj){\n\tis_api_server(obj)\n}\nfilter_input(obj){\n\tis_control_plane_info(obj)\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\nis_control_plane_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "ControlPlaneInfo"
              ]
            }
          ],
          "ruleDependencies": null,
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Encrypt etcd key-value store.",
          "remediation": "Follow the Kubernetes documentation and configure a `EncryptionConfig` file. Then, edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the master node and set the `--encryption-provider-config` parameter to the path of that file:\n\n \n```\n--encryption-provider-config=\u003c/path/to/EncryptionConfig/File\u003e\n\n```\n\n#### Impact Statement\nNone\n\n#### Default Value\nBy default, `--encryption-provider-config` is not set.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 7
    },
    {
      "guid": "",
      "name": "Ensure that encryption providers are appropriately configured",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.30",
      "controlID": "CIS-1.2.30",
      "creationTime": "",
      "description": "Where `etcd` encryption is used, appropriate providers should be configured.",
      "remediation": "Follow the Kubernetes documentation and configure a `EncryptionConfig` file. In this file, choose `aescbc`, `kms` or `secretbox` as the encryption provider.",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-api-server-encryption-providers-are-appropriately-configured",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n# Encryption config is set but not using one of the recommended providers\ndeny[msg] {\n\tobj = input[_]\n\tis_control_plane_info(obj)\n\tconfig_file := obj.data.APIServerInfo.encryptionProviderConfigFile\n\tconfig_file_content = decode_config_file(base64.decode(config_file.content))\n\n\t# For each resource check if it does not have allowed provider\n\tfix_paths := [{\n\t\t\"path\": sprintf(\"resources[%d].providers[%d]\", [i, count(resource.providers)]),\n\t\t\"value\": \"{\\\"aescbc\\\" | \\\"secretbox\\\" | \\\"kms\\\" : \u003cprovider config\u003e}\", # must be string\n\t} |\n\t\tresource := config_file_content.resources[i]\n\t\tcount({true |\n\t\t\tsome provider in resource.providers\n\t\t\thas_one_of_keys(provider, [\"aescbc\", \"secretbox\", \"kms\"])\n\t\t}) == 0\n\t]\n\n\tcount(fix_paths) \u003e 0\n\n\t# Add name to the failed object so that\n\t# it fit the format of the alert object\n\tfailed_obj := json.patch(config_file_content, [{\n\t\t\"op\": \"add\",\n\t\t\"path\": \"name\",\n\t\t\"value\": \"encryption-provider-config\",\n\t}])\n\n\tmsg := {\n\t\t\"alertMessage\": \"Encryption provider config is not using one of the allowed providers (aescbc, secretbox, kms)\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": failed_obj},\n\t}\n}\n\nis_control_plane_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n\ndecode_config_file(content) := data {\n\tdata := yaml.unmarshal(content)\n} else := json.unmarshal(content)\n\nhas_key(x, k) {\n\t_ = x[k]\n}\n\nhas_one_of_keys(x, keys) {\n\thas_key(x, keys[_])\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "ControlPlaneInfo"
              ]
            }
          ],
          "ruleDependencies": null,
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Where `etcd` encryption is used, appropriate providers should be configured.",
          "remediation": "Follow the Kubernetes documentation and configure a `EncryptionConfig` file. In this file, choose `aescbc`, `kms` or `secretbox` as the encryption provider.\n\n#### Impact Statement\nNone\n\n#### Default Value\nBy default, no encryption provider is set.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 7
    },
    {
      "guid": "",
      "name": "Ensure that the API Server --audit-log-maxsize argument is set to 100 or as appropriate",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.21",
      "controlID": "CIS-1.2.21",
      "creationTime": "",
      "description": "Rotate log files on reaching 100 MB or as appropriate.",
      "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the `--audit-log-maxsize` parameter to an appropriate size in MB. For example, to set it as 100 MB:\n\n \n```\n--audit-log-maxsize=100\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-api-server-audit-log-maxsize-argument-is-set-to-100-or-as-appropriate",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true",
            "useFromKubescapeVersion": "v2.0.159"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": result.alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tcontains(cmd[i], \"--audit-log-maxsize\")\n\tresult = {\n\t\t\"alert\": \"Please validate that audit-log-maxsize has an appropriate value\",\n\t\t\"failed_paths\": [sprintf(\"spec.containers[0].command[%v]\", [i])],\n\t\t\"fix_paths\": [],\n\t}\n}\n\ninvalid_flag(cmd) = result {\n\tfull_cmd = concat(\" \", cmd)\n\tnot contains(full_cmd, \"--audit-log-maxsize\")\n\tpath = sprintf(\"spec.containers[0].command[%v]\", [count(cmd)])\n\tresult = {\n\t\t\"alert\": \"Audit log max size not set\",\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\"path\": path, \"value\": \"--audit-log-maxsize=YOUR_VALUE\"}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Rotate log files on reaching 100 MB or as appropriate.",
          "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the `--audit-log-maxsize` parameter to an appropriate size in MB. For example, to set it as 100 MB:\n\n \n```\n--audit-log-maxsize=100\n\n```\n\n#### Impact Statement\nNone\n\n#### Default Value\nBy default, auditing is not enabled.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 4
    },
    {
      "guid": "",
      "name": "Ensure that the admission control plugin NamespaceLifecycle is set",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.14",
      "controlID": "CIS-1.2.14",
      "creationTime": "",
      "description": "Reject creating objects in a namespace that is undergoing termination.",
      "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the `--disable-admission-plugins` parameter to ensure it does not include `NamespaceLifecycle`.",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-admission-control-plugin-NamespaceLifecycle-is-set",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": \"admission control plugin AlwaysAdmit is enabled. This is equal to turning off all admission controllers\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\nget_flag_values(cmd) = {\"origin\": origin, \"values\": values} {\n\tre := \" ?--disable-admission-plugins=(.+?)(?: |$)\"\n\tmatchs := regex.find_all_string_submatch_n(re, cmd, -1)\n\tcount(matchs) == 1\n\tvalues := [val | val := split(matchs[0][1], \",\")[j]; val != \"\"]\n\torigin := matchs[0][0]\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tflag := get_flag_values(cmd[i])\n\n\t# value check\n\t\"NamespaceLifecycle\" in flag.values\n\n\t# get fixed and failed paths\n\tfixed_values := [val | val := flag.values[j]; val != \"NamespaceLifecycle\"]\n\tresult = get_retsult(fixed_values, i)\n}\n\nget_retsult(fixed_values, i) = result {\n\tcount(fixed_values) == 0\n\tresult = {\n\t\t\"failed_paths\": [sprintf(\"spec.containers[0].command[%v]\", [i])],\n\t\t\"fix_paths\": [],\n\t}\n}\n\nget_retsult(fixed_values, i) = result {\n\tcount(fixed_values) \u003e 0\n\tpath = sprintf(\"spec.containers[0].command[%v]\", [i])\n\tresult = {\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": path,\n\t\t\t\"value\": sprintf(\"--disable-admission-plugins=%v\", [concat(\",\", fixed_values)]),\n\t\t}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Reject creating objects in a namespace that is undergoing termination.",
          "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the `--disable-admission-plugins` parameter to ensure it does not include `NamespaceLifecycle`.\n\n#### Impact Statement\nNone\n\n#### Default Value\nBy default, `NamespaceLifecycle` is set.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 3
    },
    {
      "guid": "",
      "name": "Ensure that the admission control plugin SecurityContextDeny is set if PodSecurityPolicy is not used",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.12",
      "controlID": "CIS-1.2.12",
      "creationTime": "",
      "description": "The SecurityContextDeny admission controller can be used to deny pods which make use of some SecurityContext fields which could allow for privilege escalation in the cluster. This should be used where PodSecurityPolicy is not in place within the cluster.",
      "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the `--enable-admission-plugins` parameter to include `SecurityContextDeny`, unless `PodSecurityPolicy` is already in place.\n\n \n```\n--enable-admission-plugins=...,SecurityContextDeny,...\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-admission-control-plugin-SecurityContextDeny-is-set-if-PodSecurityPolicy-is-not-used",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\":\"The SecurityContextDeny addmission controller is not enabled. This could allow for privilege escalation in the cluster\", \n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\nget_flag_values(cmd) = {\"origin\": origin, \"values\": values} {\n\tre := \" ?--enable-admission-plugins=(.+?)(?: |$)\"\n\tmatchs := regex.find_all_string_submatch_n(re, cmd, -1)\n\tcount(matchs) == 1\n\tvalues := [val | val := split(matchs[0][1], \",\")[j]; val != \"\"]\n\torigin := matchs[0][0]\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tflag := get_flag_values(cmd[i])\n\n\t# value check\n\tnot \"SecurityContextDeny\" in flag.values\n\tnot \"PodSecurityPolicy\" in flag.values\n\n\t# get fixed and failed paths\n\tfixed_values := array.concat(flag.values, [\"SecurityContextDeny\"])\n\tfixed_flag = sprintf(\"%s=%s\", [\"--enable-admission-plugins\", concat(\",\", fixed_values)])\n\tfixed_cmd = replace(cmd[i], flag.origin, fixed_flag)\n\tpath := sprintf(\"spec.containers[0].command[%d]\", [i])\n\n\tresult := {\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": path,\n\t\t\t\"value\": fixed_cmd,\n\t\t}],\n\t}\n}\n\ninvalid_flag(cmd) = result {\n\tfull_cmd := concat(\" \", cmd)\n\tnot contains(full_cmd, \"--enable-admission-plugins\")\n\n\tpath = sprintf(\"spec.containers[0].command[%d]\", [count(cmd)])\n\tresult = {\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": path,\n\t\t\t\"value\": \"--enable-admission-plugins=SecurityContextDeny\",\n\t\t}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "The SecurityContextDeny admission controller can be used to deny pods which make use of some SecurityContext fields which could allow for privilege escalation in the cluster. This should be used where PodSecurityPolicy is not in place within the cluster.",
          "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the `--enable-admission-plugins` parameter to include `SecurityContextDeny`, unless `PodSecurityPolicy` is already in place.\n\n \n```\n--enable-admission-plugins=...,SecurityContextDeny,...\n\n```\n\n#### Impact Statement\nThis admission controller should only be used where Pod Security Policies cannot be used on the cluster, as it can interact poorly with certain Pod Security Policies\n\n#### Default Value\nBy default, `SecurityContextDeny` is not set.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 4
    },
    {
      "guid": "",
      "name": "Ensure that the API Server --token-auth-file parameter is not set",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.2",
      "controlID": "CIS-1.2.2",
      "creationTime": "",
      "description": "Do not use token based authentication.",
      "remediation": "Follow the documentation and configure alternate mechanisms for authentication. Then, edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the master node and remove the `--token-auth-file=\u003cfilename\u003e` parameter.",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-api-server-token-auth-file-parameter-is-not-set",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": \"API server TLS is not configured\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tre := \" ?--token-auth-file=(.+?)(?: |$)\"\n\tmatchs := regex.find_all_string_submatch_n(re, cmd[i], -1)\n\tcount(matchs) \u003e 0\n\tfixed = replace(cmd[i], matchs[0][0], \"\")\n\tresult = get_result(sprintf(\"spec.containers[0].command[%d]\", [i]), fixed)\n}\n\n# Get fix and failed paths\nget_result(path, fixed) = result {\n\tfixed == \"\"\n\tresult = {\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [],\n\t}\n}\n\nget_result(path, fixed) = result {\n\tfixed != \"\"\n\tresult = {\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": path,\n\t\t\t\"value\": fixed,\n\t\t}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Do not use token based authentication.",
          "remediation": "Follow the documentation and configure alternate mechanisms for authentication. Then, edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the master node and remove the `--token-auth-file=\u003cfilename\u003e` parameter.\n\n#### Impact Statement\nYou will have to configure and use alternate authentication mechanisms such as certificates. Static token based authentication could not be used.\n\n#### Default Value\nBy default, `--token-auth-file` argument is not set.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 8
    },
    {
      "guid": "",
      "name": "Ensure that the API Server --secure-port argument is not set to 0",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.16",
      "controlID": "CIS-1.2.16",
      "creationTime": "",
      "description": "Do not disable the secure port.",
      "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and either remove the `--secure-port` parameter or set it to a different (non-zero) desired port.",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-api-server-secure-port-argument-is-not-set-to-0",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tcontains(obj.spec.containers[0].command[i], \"--secure-port=0\")\n\tmsg := {\n\t\t\"alertMessage\": \"the secure port is disabled\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [sprintf(\"spec.containers[0].command[%v]\", [i])],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Do not disable the secure port.",
          "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and either remove the `--secure-port` parameter or set it to a different (non-zero) desired port.\n\n#### Impact Statement\nYou need to set the API Server up with the right TLS certificates.\n\n#### Default Value\nBy default, port 6443 is used as the secure port.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 8
    },
    {
      "guid": "",
      "name": "Ensure that the admission control plugin AlwaysPullImages is set",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.11",
      "controlID": "CIS-1.2.11",
      "creationTime": "",
      "description": "Always pull images.",
      "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the `--enable-admission-plugins` parameter to include `AlwaysPullImages`.\n\n \n```\n--enable-admission-plugins=...,AlwaysPullImages,...\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-admission-control-plugin-AlwaysPullImages-is-set",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": \"Admission control policy is not set to AlwaysPullImages\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\nget_flag_values(cmd) = {\"origin\": origin, \"values\": values} {\n\tre := \" ?--enable-admission-plugins=(.+?)(?: |$)\"\n\tmatchs := regex.find_all_string_submatch_n(re, cmd, -1)\n\tcount(matchs) == 1\n\tvalues := [val | val := split(matchs[0][1], \",\")[j]; val != \"\"]\n\torigin := matchs[0][0]\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tflag := get_flag_values(cmd[i])\n\n\t# value check\n\tnot \"AlwaysPullImages\" in flag.values\n\n\t# get fixed and failed paths\n\tfixed_values := array.concat(flag.values, [\"AlwaysPullImages\"])\n\tfixed_flag = sprintf(\"%s=%s\", [\"--enable-admission-plugins\", concat(\",\", fixed_values)])\n\tfixed_cmd = replace(cmd[i], flag.origin, fixed_flag)\n\tpath := sprintf(\"spec.containers[0].command[%d]\", [i])\n\n\tresult := {\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": path,\n\t\t\t\"value\": fixed_cmd,\n\t\t}],\n\t}\n}\n\ninvalid_flag(cmd) = result {\n\tfull_cmd := concat(\" \", cmd)\n\tnot contains(full_cmd, \"--enable-admission-plugins\")\n\n\tpath = sprintf(\"spec.containers[0].command[%d]\", [count(cmd)])\n\tresult = {\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": path,\n\t\t\t\"value\": \"--enable-admission-plugins=AlwaysPullImages\",\n\t\t}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Always pull images.",
          "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the `--enable-admission-plugins` parameter to include `AlwaysPullImages`.\n\n \n```\n--enable-admission-plugins=...,AlwaysPullImages,...\n\n```\n\n#### Impact Statement\nCredentials would be required to pull the private images every time. Also, in trusted environments, this might increases load on network, registry, and decreases speed.\n\n This setting could impact offline or isolated clusters, which have images pre-loaded and do not have access to a registry to pull in-use images. This setting is not appropriate for clusters which use this configuration.\n\n#### Default Value\nBy default, `AlwaysPullImages` is not set.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 4
    },
    {
      "guid": "",
      "name": "Ensure that the API Server --client-ca-file argument is set as appropriate",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.27",
      "controlID": "CIS-1.2.27",
      "creationTime": "",
      "description": "Setup TLS connection on the API server.",
      "remediation": "Follow the Kubernetes documentation and set up the TLS connection on the apiserver. Then, edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the master node and set the client certificate authority file.\n\n \n```\n--client-ca-file=\u003cpath/to/client-ca-file\u003e\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-api-server-client-ca-file-argument-is-set-as-appropriate",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": \"API server communication is not encrypted properly\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tfull_cmd = concat(\" \", cmd)\n\tnot contains(full_cmd, \"--client-ca-file\")\n\tresult := {\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": sprintf(\"spec.containers[0].command[%d]\", [count(cmd)]),\n\t\t\t\"value\": \"--client-ca-file=\u003cpath/to/client-ca.crt\u003e\",\n\t\t}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Setup TLS connection on the API server.",
          "remediation": "Follow the Kubernetes documentation and set up the TLS connection on the apiserver. Then, edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the master node and set the client certificate authority file.\n\n \n```\n--client-ca-file=\u003cpath/to/client-ca-file\u003e\n\n```\n\n#### Impact Statement\nTLS and client certificate authentication must be configured for your Kubernetes cluster deployment.\n\n#### Default Value\nBy default, `--client-ca-file` argument is not set.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 8
    },
    {
      "guid": "",
      "name": "Ensure that the admission control plugin NodeRestriction is set",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.15",
      "controlID": "CIS-1.2.15",
      "creationTime": "",
      "description": "Limit the `Node` and `Pod` objects that a kubelet could modify.",
      "remediation": "Follow the Kubernetes documentation and configure `NodeRestriction` plug-in on kubelets. Then, edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the master node and set the `--enable-admission-plugins` parameter to a value that includes `NodeRestriction`.\n\n \n```\n--enable-admission-plugins=...,NodeRestriction,...\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-admission-control-plugin-NodeRestriction-is-set",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": \"NodeRestriction is not enabled\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\nget_flag_values(cmd) = {\"origin\": origin, \"values\": values} {\n\tre := \" ?--enable-admission-plugins=(.+?)(?: |$)\"\n\tmatchs := regex.find_all_string_submatch_n(re, cmd, -1)\n\tcount(matchs) == 1\n\tvalues := [val | val := split(matchs[0][1], \",\")[j]; val != \"\"]\n\torigin := matchs[0][0]\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tflag := get_flag_values(cmd[i])\n\n\t# value check\n\tnot \"NodeRestriction\" in flag.values\n\n\t# get fixed and failed paths\n\tfixed_values := array.concat(flag.values, [\"NodeRestriction\"])\n\tfixed_flag = sprintf(\"%s=%s\", [\"--enable-admission-plugins\", concat(\",\", fixed_values)])\n\tfixed_cmd = replace(cmd[i], flag.origin, fixed_flag)\n\tpath := sprintf(\"spec.containers[0].command[%d]\", [i])\n\n\tresult := {\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": path,\n\t\t\t\"value\": fixed_cmd,\n\t\t}],\n\t}\n}\n\ninvalid_flag(cmd) = result {\n\tfull_cmd := concat(\" \", cmd)\n\tnot contains(full_cmd, \"--enable-admission-plugins\")\n\n\tpath = sprintf(\"spec.containers[0].command[%d]\", [count(cmd)])\n\tresult = {\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": path,\n\t\t\t\"value\": \"--enable-admission-plugins=NodeRestriction\",\n\t\t}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Limit the `Node` and `Pod` objects that a kubelet could modify.",
          "remediation": "Follow the Kubernetes documentation and configure `NodeRestriction` plug-in on kubelets. Then, edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the master node and set the `--enable-admission-plugins` parameter to a value that includes `NodeRestriction`.\n\n \n```\n--enable-admission-plugins=...,NodeRestriction,...\n\n```\n\n#### Impact Statement\nNone\n\n#### Default Value\nBy default, `NodeRestriction` is not set.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 4
    },
    {
      "guid": "",
      "name": "Ensure that the API Server --audit-log-path argument is set",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.18",
      "controlID": "CIS-1.2.18",
      "creationTime": "",
      "description": "Enable auditing on the Kubernetes API Server and set the desired audit log path.",
      "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the `--audit-log-path` parameter to a suitable path and file where you would like audit logs to be written, for example:\n\n \n```\n--audit-log-path=/var/log/apiserver/audit.log\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-api-server-audit-log-path-argument-is-set",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": \"kubernetes API Server is not audited\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\ninvalid_flag(cmd) = result {\n\tfull_cmd = concat(\" \", cmd)\n\tnot contains(full_cmd, \"--audit-log-path\")\n\tresult := {\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": sprintf(\"spec.containers[0].command[%d]\", [count(cmd)]),\n\t\t\t\"value\": \"--audit-log-path=/var/log/apiserver/audit.log\",\n\t\t}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Enable auditing on the Kubernetes API Server and set the desired audit log path.",
          "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the `--audit-log-path` parameter to a suitable path and file where you would like audit logs to be written, for example:\n\n \n```\n--audit-log-path=/var/log/apiserver/audit.log\n\n```\n\n#### Impact Statement\nNone\n\n#### Default Value\nBy default, auditing is not enabled.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 7
    },
    {
      "guid": "",
      "name": "Ensure that the admission control plugin EventRateLimit is set",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.9",
      "controlID": "CIS-1.2.9",
      "creationTime": "",
      "description": "Limit the rate at which the API server accepts requests.",
      "remediation": "Follow the Kubernetes documentation and set the desired limits in a configuration file.\n\n Then, edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` and set the below parameters.\n\n \n```\n--enable-admission-plugins=...,EventRateLimit,...\n--admission-control-config-file=\u003cpath/to/configuration/file\u003e\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-admission-control-plugin-EventRateLimit-is-set",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\n\tmsg := {\n\t\t\"alertMessage\": \"The API server is not configured to limit the rate at which it accepts requests. This could lead to a denial of service attack\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\nget_flag_values(cmd) = {\"origin\": origin, \"values\": values} {\n\tre := \" ?--enable-admission-plugins=(.+?)(?: |$)\"\n\tmatchs := regex.find_all_string_submatch_n(re, cmd, -1)\n\tcount(matchs) == 1\n\tvalues := [val | val := split(matchs[0][1], \",\")[j]; val != \"\"]\n\torigin := matchs[0][0]\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tflag := get_flag_values(cmd[i])\n\n\t# value check\n\tnot \"EventRateLimit\" in flag.values\n\n\t# get fixed and failed paths\n\tfixed_values := array.concat(flag.values, [\"EventRateLimit\"])\n\tfixed_flag = sprintf(\"%s=%s\", [\"--enable-admission-plugins\", concat(\",\", fixed_values)])\n\tfixed_cmd = replace(cmd[i], flag.origin, fixed_flag)\n\tpath := sprintf(\"spec.containers[0].command[%d]\", [i])\n\n\tresult := {\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": path,\n\t\t\t\"value\": fixed_cmd,\n\t\t}],\n\t}\n}\n\ninvalid_flag(cmd) = result {\n\tfull_cmd := concat(\" \", cmd)\n\tnot contains(full_cmd, \"--enable-admission-plugins\")\n\n\tpath = sprintf(\"spec.containers[0].command[%d]\", [count(cmd)])\n\tresult = {\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": path,\n\t\t\t\"value\": \"--enable-admission-plugins=EventRateLimit\",\n\t\t}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Limit the rate at which the API server accepts requests.",
          "remediation": "Follow the Kubernetes documentation and set the desired limits in a configuration file.\n\n Then, edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` and set the below parameters.\n\n \n```\n--enable-admission-plugins=...,EventRateLimit,...\n--admission-control-config-file=\u003cpath/to/configuration/file\u003e\n\n```\n\n#### Impact Statement\nYou need to carefully tune in limits as per your environment.\n\n#### Default Value\nBy default, `EventRateLimit` is not set.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 4
    },
    {
      "guid": "",
      "name": "Ensure that the API Server --etcd-cafile argument is set as appropriate",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.28",
      "controlID": "CIS-1.2.28",
      "creationTime": "",
      "description": "etcd should be configured to make use of TLS encryption for client connections.",
      "remediation": "Follow the Kubernetes documentation and set up the TLS connection between the apiserver and etcd. Then, edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the master node and set the etcd certificate authority file parameter.\n\n \n```\n--etcd-cafile=\u003cpath/to/ca-file\u003e\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-api-server-etcd-cafile-argument-is-set-as-appropriate",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": \"API server is not configured to use SSL Certificate Authority file for etcd\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tfull_cmd = concat(\" \", cmd)\n\tnot contains(full_cmd, \"--etcd-cafile\")\n\tresult := {\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": sprintf(\"spec.containers[0].command[%d]\", [count(cmd)]),\n\t\t\t\"value\": \"--etcd-cafile=\u003cpath/to/ca-file.crt\u003e\",\n\t\t}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "etcd should be configured to make use of TLS encryption for client connections.",
          "remediation": "Follow the Kubernetes documentation and set up the TLS connection between the apiserver and etcd. Then, edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the master node and set the etcd certificate authority file parameter.\n\n \n```\n--etcd-cafile=\u003cpath/to/ca-file\u003e\n\n```\n\n#### Impact Statement\nTLS and client certificate authentication must be configured for etcd.\n\n#### Default Value\nBy default, `--etcd-cafile` is not set.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 8
    },
    {
      "guid": "",
      "name": "Ensure that the API Server --anonymous-auth argument is set to false",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.1",
      "controlID": "CIS-1.2.1",
      "creationTime": "",
      "description": "Disable anonymous requests to the API server.",
      "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the below parameter.\n\n \n```\n--anonymous-auth=false\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-api-server-anonymous-auth-argument-is-set-to-false",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": \"anonymous requests is enabled\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tcontains(cmd[i], \"--anonymous-auth=true\")\n\tfixed = replace(cmd[i], \"--anonymous-auth=true\", \"--anonymous-auth=false\")\n\tpath := sprintf(\"spec.containers[0].command[%d]\", [i])\n\tresult = {\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\"path\": path, \"value\": fixed}],\n\t}\n}\n\ninvalid_flag(cmd) = result {\n\tfull_cmd = concat(\" \", cmd)\n\tnot contains(full_cmd, \"--anonymous-auth\")\n\tpath := sprintf(\"spec.containers[0].command[%d]\", [count(cmd)])\n\tresult = {\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": path,\n\t\t\t\"value\": \"--anonymous-auth=false\",\n\t\t}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Disable anonymous requests to the API server.",
          "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the below parameter.\n\n \n```\n--anonymous-auth=false\n\n```\n\n#### Impact Statement\nAnonymous requests will be rejected.\n\n#### Default Value\nBy default, anonymous access is enabled.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 8
    },
    {
      "guid": "",
      "name": "Ensure that the admission control plugin ServiceAccount is set",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.2.13",
      "controlID": "CIS-1.2.13",
      "creationTime": "",
      "description": "Automate service accounts management.",
      "remediation": "Follow the documentation and create `ServiceAccount` objects as per your environment. Then, edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the master node and ensure that the `--disable-admission-plugins` parameter is set to a value that does not include `ServiceAccount`.",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-admission-control-plugin-ServiceAccount-is-set",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": \"admission control plugin AlwaysAdmit is enabled. This is equal to turning off all admission controllers\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\nget_flag_values(cmd) = {\"origin\": origin, \"values\": values} {\n\tre := \" ?--disable-admission-plugins=(.+?)(?: |$)\"\n\tmatchs := regex.find_all_string_submatch_n(re, cmd, -1)\n\tcount(matchs) == 1\n\tvalues := [val | val := split(matchs[0][1], \",\")[j]; val != \"\"]\n\torigin := matchs[0][0]\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tflag := get_flag_values(cmd[i])\n\n\t# value check\n\t\"ServiceAccount\" in flag.values\n\n\t# get fixed and failed paths\n\tfixed_values := [val | val := flag.values[j]; val != \"ServiceAccount\"]\n\tresult = get_retsult(fixed_values, i)\n}\n\nget_retsult(fixed_values, i) = result {\n\tcount(fixed_values) == 0\n\tresult = {\n\t\t\"failed_paths\": [sprintf(\"spec.containers[0].command[%v]\", [i])],\n\t\t\"fix_paths\": [],\n\t}\n}\n\nget_retsult(fixed_values, i) = result {\n\tcount(fixed_values) \u003e 0\n\tpath = sprintf(\"spec.containers[0].command[%v]\", [i])\n\tresult = {\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": path,\n\t\t\t\"value\": sprintf(\"--disable-admission-plugins=%v\", [concat(\",\", fixed_values)]),\n\t\t}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Automate service accounts management.",
          "remediation": "Follow the documentation and create `ServiceAccount` objects as per your environment. Then, edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the master node and ensure that the `--disable-admission-plugins` parameter is set to a value that does not include `ServiceAccount`.\n\n#### Impact Statement\nNone.\n\n#### Default Value\nBy default, `ServiceAccount` is set.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 3
    },
    {
      "guid": "",
      "name": "Ensure that the Controller Manager --terminated-pod-gc-threshold argument is set as appropriate",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.3.1",
      "controlID": "CIS-1.3.1",
      "creationTime": "",
      "description": "Activate garbage collector on pod termination, as appropriate.",
      "remediation": "Edit the Controller Manager pod specification file `/etc/kubernetes/manifests/kube-controller-manager.yaml` on the Control Plane node and set the `--terminated-pod-gc-threshold` to an appropriate threshold, for example:\n\n \n```\n--terminated-pod-gc-threshold=10\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-controller-manager-terminated-pod-gc-threshold-argument-is-set-as-appropriate",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_controller_manager(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": result.alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_controller_manager(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-controller-manager\")\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tcontains(cmd[i], \"--terminated-pod-gc-threshold\")\n\tresult = {\n\t\t\"alert\": \"Please validate that --terminated-pod-gc-threshold is set to an appropriate value\",\n\t\t\"failed_paths\": [sprintf(\"spec.containers[0].command[%v]\", [i])],\n\t\t\"fix_paths\": [],\n\t}\n}\n\ninvalid_flag(cmd) = result {\n\tfull_cmd = concat(\" \", cmd)\n\tnot contains(full_cmd, \"--terminated-pod-gc-threshold\")\n\tpath = sprintf(\"spec.containers[0].command[%v]\", [count(cmd)])\n\tresult = {\n\t\t\"alert\": \"--terminated-pod-gc-threshold flag not set to an appropriate value\",\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\"path\": path, \"value\": \"--terminated-pod-gc-threshold=YOUR_VALUE\"}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_controller_manager(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_controller_manager(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-controller-manager\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Activate garbage collector on pod termination, as appropriate.",
          "remediation": "Edit the Controller Manager pod specification file `/etc/kubernetes/manifests/kube-controller-manager.yaml` on the Control Plane node and set the `--terminated-pod-gc-threshold` to an appropriate threshold, for example:\n\n \n```\n--terminated-pod-gc-threshold=10\n\n```\n\n#### Impact Statement\nNone\n\n#### Default Value\nBy default, `--terminated-pod-gc-threshold` is set to `12500`.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 4
    },
    {
      "guid": "",
      "name": "Ensure that the Controller Manager --profiling argument is set to false",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.3.2",
      "controlID": "CIS-1.3.2",
      "creationTime": "",
      "description": "Disable profiling, if not needed.",
      "remediation": "Edit the Controller Manager pod specification file `/etc/kubernetes/manifests/kube-controller-manager.yaml` on the Control Plane node and set the below parameter.\n\n \n```\n--profiling=false\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-controller-manager-profiling-argument-is-set-to-false",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_controller_manager(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": \"profiling is enabled for the kube-controller-manager\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_controller_manager(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-controller-manager\")\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tcmd[i] == \"--profiling=true\"\n\tpath := sprintf(\"spec.containers[0].command[%d]\", [i])\n\tresult = {\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\"path\": path, \"value\": \"--profiling=false\"}],\n\t}\n}\n\ninvalid_flag(cmd) = result {\n\tfull_cmd = concat(\" \", cmd)\n\tnot contains(full_cmd, \"--profiling\")\n\tpath := sprintf(\"spec.containers[0].command[%d]\", [count(cmd)])\n\tresult = {\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": path,\n\t\t\t\"value\": \"--profiling=false\",\n\t\t}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_controller_manager(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_controller_manager(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-controller-manager\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Disable profiling, if not needed.",
          "remediation": "Edit the Controller Manager pod specification file `/etc/kubernetes/manifests/kube-controller-manager.yaml` on the Control Plane node and set the below parameter.\n\n \n```\n--profiling=false\n\n```\n\n#### Impact Statement\nProfiling information would not be available.\n\n#### Default Value\nBy default, profiling is enabled.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 3
    },
    {
      "guid": "",
      "name": "Ensure that the Controller Manager RotateKubeletServerCertificate argument is set to true",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.3.6",
      "controlID": "CIS-1.3.6",
      "creationTime": "",
      "description": "Enable kubelet server certificate rotation on controller-manager.",
      "remediation": "Edit the Controller Manager pod specification file `/etc/kubernetes/manifests/kube-controller-manager.yaml` on the Control Plane node and set the `--feature-gates` parameter to include `RotateKubeletServerCertificate=true`.\n\n \n```\n--feature-gates=RotateKubeletServerCertificate=true\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-controller-manager-RotateKubeletServerCertificate-argument-is-set-to-true",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_controller_manager(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": \"`RotateKubeletServerCertificate` is set to false on the controller manager\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_controller_manager(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-controller-manager\")\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tcontains(cmd[i], \"RotateKubeletServerCertificate=false\")\n\tfixed = replace(cmd[i], \"RotateKubeletServerCertificate=false\", \"RotateKubeletServerCertificate=true\")\n\tpath := sprintf(\"spec.containers[0].command[%d]\", [i])\n\tresult = {\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\"path\": path, \"value\": fixed}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_controller_manager(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_controller_manager(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-controller-manager\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Enable kubelet server certificate rotation on controller-manager.",
          "remediation": "Edit the Controller Manager pod specification file `/etc/kubernetes/manifests/kube-controller-manager.yaml` on the Control Plane node and set the `--feature-gates` parameter to include `RotateKubeletServerCertificate=true`.\n\n \n```\n--feature-gates=RotateKubeletServerCertificate=true\n\n```\n\n#### Impact Statement\nNone\n\n#### Default Value\nBy default, `RotateKubeletServerCertificate` is set to \"true\" this recommendation verifies that it has not been disabled.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Ensure that the Controller Manager --root-ca-file argument is set as appropriate",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.3.5",
      "controlID": "CIS-1.3.5",
      "creationTime": "",
      "description": "Allow pods to verify the API server's serving certificate before establishing connections.",
      "remediation": "Edit the Controller Manager pod specification file `/etc/kubernetes/manifests/kube-controller-manager.yaml` on the Control Plane node and set the `--root-ca-file` parameter to the certificate bundle file`.\n\n \n```\n--root-ca-file=\u003cpath/to/file\u003e\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-controller-manager-root-ca-file-argument-is-set-as-appropriate",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_controller_manager(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": \"the controller manager is not configured to inject the trusted ca.crt file into pods so that they can verify TLS connections to the API server\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_controller_manager(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-controller-manager\")\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tfull_cmd = concat(\" \", cmd)\n\tnot contains(full_cmd, \"--root-ca-file\")\n\tresult := {\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": sprintf(\"spec.containers[0].command[%d]\", [count(cmd)]),\n\t\t\t\"value\": \"--root-ca-file=\u003cpath/to/key/ca.crt\u003e\",\n\t\t}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_controller_manager(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_controller_manager(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-controller-manager\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Allow pods to verify the API server's serving certificate before establishing connections.",
          "remediation": "Edit the Controller Manager pod specification file `/etc/kubernetes/manifests/kube-controller-manager.yaml` on the Control Plane node and set the `--root-ca-file` parameter to the certificate bundle file`.\n\n \n```\n--root-ca-file=\u003cpath/to/file\u003e\n\n```\n\n#### Impact Statement\nYou need to setup and maintain root certificate authority file.\n\n#### Default Value\nBy default, `--root-ca-file` is not set.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 7
    },
    {
      "guid": "",
      "name": "Ensure that the Controller Manager --service-account-private-key-file argument is set as appropriate",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.3.4",
      "controlID": "CIS-1.3.4",
      "creationTime": "",
      "description": "Explicitly set a service account private key file for service accounts on the controller manager.",
      "remediation": "Edit the Controller Manager pod specification file `/etc/kubernetes/manifests/kube-controller-manager.yaml` on the Control Plane node and set the `--service-account-private-key-file` parameter to the private key file for service accounts.\n\n \n```\n--service-account-private-key-file=\u003cfilename\u003e\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-controller-manager-service-account-private-key-file-argument-is-set-as-appropriate",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_controller_manager(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": \"service account token can not be rotated as needed\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_controller_manager(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-controller-manager\")\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tfull_cmd = concat(\" \", cmd)\n\tnot contains(full_cmd, \"--service-account-private-key-file\")\n\tresult := {\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": sprintf(\"spec.containers[0].command[%d]\", [count(cmd)]),\n\t\t\t\"value\": \"--service-account-private-key-file=\u003cpath/to/key/filename.key\u003e\",\n\t\t}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_controller_manager(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_controller_manager(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-controller-manager\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Explicitly set a service account private key file for service accounts on the controller manager.",
          "remediation": "Edit the Controller Manager pod specification file `/etc/kubernetes/manifests/kube-controller-manager.yaml` on the Control Plane node and set the `--service-account-private-key-file` parameter to the private key file for service accounts.\n\n \n```\n--service-account-private-key-file=\u003cfilename\u003e\n\n```\n\n#### Impact Statement\nYou would need to securely maintain the key file and rotate the keys based on your organization's key rotation policy.\n\n#### Default Value\nBy default, `--service-account-private-key-file` it not set.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Ensure that the Controller Manager --use-service-account-credentials argument is set to true",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.3.3",
      "controlID": "CIS-1.3.3",
      "creationTime": "",
      "description": "Use individual service account credentials for each controller.",
      "remediation": "Edit the Controller Manager pod specification file `/etc/kubernetes/manifests/kube-controller-manager.yaml` on the Control Plane node to set the below parameter.\n\n \n```\n--use-service-account-credentials=true\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-controller-manager-use-service-account-credentials-argument-is-set-to-true",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_controller_manager(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": \"--use-service-account-credentials is set to false in the controller manager\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_controller_manager(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-controller-manager\")\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tcmd[i] == \"--use-service-account-credentials=false\"\n\tpath := sprintf(\"spec.containers[0].command[%d]\", [i])\n\tresult = {\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\"path\": path, \"value\": \"--use-service-account-credentials=true\"}],\n\t}\n}\n\ninvalid_flag(cmd) = result {\n\tfull_cmd = concat(\" \", cmd)\n\tnot contains(full_cmd, \"--use-service-account-credentials\")\n\tpath := sprintf(\"spec.containers[0].command[%d]\", [count(cmd)])\n\tresult = {\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": path,\n\t\t\t\"value\": \"--use-service-account-credentials=true\",\n\t\t}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_controller_manager(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_controller_manager(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-controller-manager\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Use individual service account credentials for each controller.",
          "remediation": "Edit the Controller Manager pod specification file `/etc/kubernetes/manifests/kube-controller-manager.yaml` on the Control Plane node to set the below parameter.\n\n \n```\n--use-service-account-credentials=true\n\n```\n\n#### Impact Statement\nWhatever authorizer is configured for the cluster, it must grant sufficient permissions to the service accounts to perform their intended tasks. When using the RBAC authorizer, those roles are created and bound to the appropriate service accounts in the `kube-system` namespace automatically with default roles and rolebindings that are auto-reconciled on startup.\n\n If using other authorization methods (ABAC, Webhook, etc), the cluster deployer is responsible for granting appropriate permissions to the service accounts (the required permissions can be seen by inspecting the `controller-roles.yaml` and `controller-role-bindings.yaml` files for the RBAC roles.\n\n#### Default Value\nBy default, `--use-service-account-credentials` is set to false.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 4
    },
    {
      "guid": "",
      "name": "Ensure that the Controller Manager --bind-address argument is set to 127.0.0.1",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.3.7",
      "controlID": "CIS-1.3.7",
      "creationTime": "",
      "description": "Do not bind the Controller Manager service to non-loopback insecure addresses.",
      "remediation": "Edit the Controller Manager pod specification file `/etc/kubernetes/manifests/kube-controller-manager.yaml` on the Control Plane node and ensure the correct value for the `--bind-address` parameter",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-controller-manager-bind-address-argument-is-set-to-127.0.0.1",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n\n\ndeny[msg] {\n\tobj = input[_]\n\tis_controller_manager(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\n\tmsg := {\n\t\t\"alertMessage\": \"the Controller Manager API service is not bound to a localhost interface only\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_controller_manager(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-controller-manager\")\n}\n\nget_flag_value(cmd) = value {\n\tre := \" ?--bind-address=(.+?)(?: |$)\"\n\tmatchs := regex.find_all_string_submatch_n(re, cmd, 1)\n\tcount(matchs) == 1\n\tvalue =matchs[0][1]\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tval = get_flag_value(cmd[i])\n\tval != \"127.0.0.1\"\n\tpath = sprintf(\"spec.containers[0].command[%d]\", [i])\n\tresult = {\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\"path\": path, \"value\": \"--bind-address=127.0.0.1\"}],\n\t}\n}\n\ninvalid_flag(cmd) = result {\n\tfull_cmd = concat(\" \", cmd)\n\tnot contains(full_cmd, \"--bind-address\")\n\tpath = sprintf(\"spec.containers[0].command[%d]\", [count(cmd)])\n\tresult = {\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": [{\"path\": path, \"value\": \"--bind-address=127.0.0.1\"}],\n\t}\n}",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_controller_manager(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_controller_manager(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-controller-manager\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Do not bind the Controller Manager service to non-loopback insecure addresses.",
          "remediation": "Edit the Controller Manager pod specification file `/etc/kubernetes/manifests/kube-controller-manager.yaml` on the Control Plane node and ensure the correct value for the `--bind-address` parameter\n\n#### Impact Statement\nNone\n\n#### Default Value\nBy default, the `--bind-address` parameter is set to 0.0.0.0",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 5
    },
    {
      "guid": "",
      "name": "Ensure that the Scheduler --profiling argument is set to false",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.4.1",
      "controlID": "CIS-1.4.1",
      "creationTime": "",
      "description": "Disable profiling, if not needed.",
      "remediation": "Edit the Scheduler pod specification file `/etc/kubernetes/manifests/kube-scheduler.yaml` file on the Control Plane node and set the below parameter.\n\n \n```\n--profiling=false\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-scheduler-profiling-argument-is-set-to-false",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_scheduler(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": \"profiling is enabled for the kube-scheduler\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_scheduler(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-scheduler\")\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tcmd[i] == \"--profiling=true\"\n\tpath := sprintf(\"spec.containers[0].command[%d]\", [i])\n\tresult = {\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\"path\": path, \"value\": \"--profiling=false\"}],\n\t}\n}\n\ninvalid_flag(cmd) = result {\n\tfull_cmd = concat(\" \", cmd)\n\tnot contains(full_cmd, \"--profiling\")\n\tpath := sprintf(\"spec.containers[0].command[%d]\", [count(cmd)])\n\tresult = {\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": path,\n\t\t\t\"value\": \"--profiling=false\",\n\t\t}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_scheduler(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_scheduler(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-scheduler\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Disable profiling, if not needed.",
          "remediation": "Edit the Scheduler pod specification file `/etc/kubernetes/manifests/kube-scheduler.yaml` file on the Control Plane node and set the below parameter.\n\n \n```\n--profiling=false\n\n```\n\n#### Impact Statement\nProfiling information would not be available.\n\n#### Default Value\nBy default, profiling is enabled.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 3
    },
    {
      "guid": "",
      "name": "Ensure that the Scheduler --bind-address argument is set to 127.0.0.1",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-1.4.2",
      "controlID": "CIS-1.4.2",
      "creationTime": "",
      "description": "Do not bind the scheduler service to non-loopback insecure addresses.",
      "remediation": "Edit the Scheduler pod specification file `/etc/kubernetes/manifests/kube-scheduler.yaml` on the Control Plane node and ensure the correct value for the `--bind-address` parameter",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-scheduler-bind-address-argument-is-set-to-127.0.0.1",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_scheduler(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\n\tmsg := {\n\t\t\"alertMessage\": \"the kube scheduler is not bound to a localhost interface only\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_scheduler(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-scheduler\")\n}\n\nget_flag_value(cmd) = value {\n\tre := \" ?--bind-address=(.+?)(?: |$)\"\n\tmatchs := regex.find_all_string_submatch_n(re, cmd, 1)\n\tcount(matchs) == 1\n\tvalue = matchs[0][1]\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tval = get_flag_value(cmd[i])\n\tval != \"127.0.0.1\"\n\tpath = sprintf(\"spec.containers[0].command[%d]\", [i])\n\tresult = {\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\"path\": path, \"value\": \"--bind-address=127.0.0.1\"}],\n\t}\n}\n\ninvalid_flag(cmd) = result {\n\tfull_cmd = concat(\" \", cmd)\n\tnot contains(full_cmd, \"--bind-address\")\n\tpath = sprintf(\"spec.containers[0].command[%d]\", [count(cmd)])\n\tresult = {\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": [{\"path\": path, \"value\": \"--bind-address=127.0.0.1\"}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_scheduler(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_scheduler(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) \u003e 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-scheduler\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Do not bind the scheduler service to non-loopback insecure addresses.",
          "remediation": "Edit the Scheduler pod specification file `/etc/kubernetes/manifests/kube-scheduler.yaml` on the Control Plane node and ensure the correct value for the `--bind-address` parameter\n\n#### Impact Statement\nNone\n\n#### Default Value\nBy default, the `--bind-address` parameter is set to 0.0.0.0",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 5
    },
    {
      "guid": "",
      "name": "Ensure that the kubelet service file permissions are set to 600 or more restrictive",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-4.1.1",
      "controlID": "CIS-4.1.1",
      "creationTime": "",
      "description": "Ensure that the `kubelet` service file has permissions of `600` or more restrictive.",
      "remediation": "Run the below command (based on the file location on your system) on the each worker node. For example,\n\n \n```\nchmod 600 /etc/systemd/system/kubelet.service.d/kubeadm.conf\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-kubelet-service-file-permissions-are-set-to-600-or-more-restrictive",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_kubelet_info(obj)\n\n\tfile_obj_path := [\"data\", \"serviceFiles\"]\n\tfiles := object.get(obj, file_obj_path, false)\n\tfile := files[file_index]\n\n\t# Actual permissions test    \n\tallowed_perms := 384 # == 0o600\n\tnot cautils.unix_permissions_allow(allowed_perms, file.permissions)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tsprintf(\"%s/%d\", [concat(\"/\", file_obj_path), file_index]),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"the permissions of %s are too permissive. maximum allowed: %o. actual: %o\", [file.path, allowed_perms, file.permissions])\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chmod %o %s\", [allowed_perms, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"KubeletInfo\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the `kubelet` service file has permissions of `600` or more restrictive.",
          "remediation": "Run the below command (based on the file location on your system) on the each worker node. For example,\n\n \n```\nchmod 600 /etc/systemd/system/kubelet.service.d/kubeadm.conf\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Ensure that the kubelet service file ownership is set to root:root",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-4.1.2",
      "controlID": "CIS-4.1.2",
      "creationTime": "",
      "description": "Ensure that the `kubelet` service file ownership is set to `root:root`.",
      "remediation": "Run the below command (based on the file location on your system) on the each worker node. For example,\n\n \n```\nchown root:root /etc/systemd/system/kubelet.service.d/kubeadm.conf\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-kubelet-service-file-ownership-is-set-to-root-root",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_kubelet_info(obj)\n\n\tfile_obj_path := [\"data\", \"serviceFiles\"]\n\tfiles := object.get(obj, file_obj_path, false)\n\tfile := files[file_index]\n\n\t# Actual ownership check\n\tallowed_user := \"root\"\n\tallowed_group := \"root\"\n\tnot allowed_ownership(file.ownership, allowed_user, allowed_group)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tsprintf(\"%s/%d\", [concat(\"/\", file_obj_path), file_index]), \"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"%s is not owned by %s:%s (actual owners are %s:%s)\", [\n\t\tfile.path,\n\t\tallowed_user,\n\t\tallowed_group,\n\t\tfile.ownership.username,\n\t\tfile.ownership.groupname,\n\t])\n\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chown %s:%s %s\", [allowed_user, allowed_group, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"KubeletInfo\"\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.error # Do not fail if ownership is not found\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.username == user\n\townership.groupname == group\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the `kubelet` service file ownership is set to `root:root`.",
          "remediation": "Run the below command (based on the file location on your system) on the each worker node. For example,\n\n \n```\nchown root:root /etc/systemd/system/kubelet.service.d/kubeadm.conf\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "If proxy kubeconfig file exists ensure permissions are set to 600 or more restrictive",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-4.1.3",
      "controlID": "CIS-4.1.3",
      "creationTime": "",
      "description": "If `kube-proxy` is running, and if it is using a file-based kubeconfig file, ensure that the proxy kubeconfig file has permissions of `600` or more restrictive.",
      "remediation": "Run the below command (based on the file location on your system) on the each worker node. For example,\n\n \n```\nchmod 600 \u003cproxy kubeconfig file\u003e\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "if-proxy-kubeconfig-file-exists-ensure-permissions-are-set-to-600-or-more-restrictive",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_kubproxy_info(obj)\n\n\tfile_obj_path := [\"data\", \"kubeConfigFile\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual permissions test    \n\tallowed_perms := 384 # == 0o600\n\tnot cautils.unix_permissions_allow(allowed_perms, file.permissions)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"the permissions of %s are too permissive. maximum allowed: %o. actual: %o\", [file.path, allowed_perms, file.permissions])\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chmod %o %s\", [allowed_perms, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_kubproxy_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"KubeProxyInfo\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeProxyInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "If `kube-proxy` is running, and if it is using a file-based kubeconfig file, ensure that the proxy kubeconfig file has permissions of `600` or more restrictive.",
          "remediation": "Run the below command (based on the file location on your system) on the each worker node. For example,\n\n \n```\nchmod 600 \u003cproxy kubeconfig file\u003e\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "If proxy kubeconfig file exists ensure ownership is set to root:root",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-4.1.4",
      "controlID": "CIS-4.1.4",
      "creationTime": "",
      "description": "If `kube-proxy` is running, ensure that the file ownership of its kubeconfig file is set to `root:root`.",
      "remediation": "Run the below command (based on the file location on your system) on the each worker node. For example,\n\n \n```\nchown root:root \u003cproxy kubeconfig file\u003e\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "if-proxy-kubeconfig-file-exists-ensure-ownership-is-set-to-root-root",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_kubproxy_info(obj)\n\n\tfile_obj_path := [\"data\", \"kubeConfigFile\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual ownership check\n\tallowed_user := \"root\"\n\tallowed_group := \"root\"\n\tnot allowed_ownership(file.ownership, allowed_user, allowed_group)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"%s is not owned by %s:%s (actual owners are %s:%s)\", [\n\t\tfile.path,\n\t\tallowed_user,\n\t\tallowed_group,\n\t\tfile.ownership.username,\n\t\tfile.ownership.groupname,\n\t])\n\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chown %s:%s %s\", [allowed_user, allowed_group, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\n\nis_kubproxy_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"KubeProxyInfo\"\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.error # Do not fail if ownership is not found\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.username == user\n\townership.groupname == group\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeProxyInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "If `kube-proxy` is running, ensure that the file ownership of its kubeconfig file is set to `root:root`.",
          "remediation": "Run the below command (based on the file location on your system) on the each worker node. For example,\n\n \n```\nchown root:root \u003cproxy kubeconfig file\u003e\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Ensure that the --kubeconfig kubelet.conf file permissions are set to 600 or more restrictive",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-4.1.5",
      "controlID": "CIS-4.1.5",
      "creationTime": "",
      "description": "Ensure that the `kubelet.conf` file has permissions of `600` or more restrictive.",
      "remediation": "Run the below command (based on the file location on your system) on the each worker node. For example,\n\n \n```\nchmod 600 /etc/kubernetes/kubelet.conf\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-kubeconfig-kubelet.conf-file-permissions-are-set-to-600-or-more-restrictive",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_kubelet_info(obj)\n\n\tfile_obj_path := [\"data\", \"kubeConfigFile\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual permissions test    \n\tallowed_perms := 384 # == 0o600\n\tnot cautils.unix_permissions_allow(allowed_perms, file.permissions)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"the permissions of %s are too permissive. maximum allowed: %o. actual: %o\", [file.path, allowed_perms, file.permissions])\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chmod %o %s\", [allowed_perms, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"KubeletInfo\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the `kubelet.conf` file has permissions of `600` or more restrictive.",
          "remediation": "Run the below command (based on the file location on your system) on the each worker node. For example,\n\n \n```\nchmod 600 /etc/kubernetes/kubelet.conf\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Ensure that the --kubeconfig kubelet.conf file ownership is set to root:root",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-4.1.6",
      "controlID": "CIS-4.1.6",
      "creationTime": "",
      "description": "Ensure that the `kubelet.conf` file ownership is set to `root:root`.",
      "remediation": "Run the below command (based on the file location on your system) on the each worker node. For example,\n\n \n```\nchown root:root /etc/kubernetes/kubelet.conf\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-kubeconfig-kubelet.conf-file-ownership-is-set-to-root-root",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_kubelet_info(obj)\n\n\tfile_obj_path := [\"data\", \"kubeConfigFile\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual ownership check\n\tallowed_user := \"root\"\n\tallowed_group := \"root\"\n\tnot allowed_ownership(file.ownership, allowed_user, allowed_group)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"%s is not owned by %s:%s (actual owners are %s:%s)\", [\n\t\tfile.path,\n\t\tallowed_user,\n\t\tallowed_group,\n\t\tfile.ownership.username,\n\t\tfile.ownership.groupname,\n\t])\n\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chown %s:%s %s\", [allowed_user, allowed_group, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"KubeletInfo\"\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.error # Do not fail if ownership is not found\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.username == user\n\townership.groupname == group\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the `kubelet.conf` file ownership is set to `root:root`.",
          "remediation": "Run the below command (based on the file location on your system) on the each worker node. For example,\n\n \n```\nchown root:root /etc/kubernetes/kubelet.conf\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Ensure that the certificate authorities file permissions are set to 600 or more restrictive",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-4.1.7",
      "controlID": "CIS-4.1.7",
      "creationTime": "",
      "description": "Ensure that the certificate authorities file has permissions of `600` or more restrictive.",
      "remediation": "Run the following command to modify the file permissions of the `--client-ca-file`\n\n \n```\nchmod 600 \u003cfilename\u003e\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-certificate-authorities-file-permissions-are-set-to-600-or-more-restrictive",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_kubelet_info(obj)\n\n\tfile_obj_path := [\"data\", \"clientCAFile\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual permissions test    \n\tallowed_perms := 384 # == 0o600\n\tnot cautils.unix_permissions_allow(allowed_perms, file.permissions)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"the permissions of %s are too permissive. maximum allowed: %o. actual: %o\", [file.path, allowed_perms, file.permissions])\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chmod %o %s\", [allowed_perms, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"KubeletInfo\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the certificate authorities file has permissions of `600` or more restrictive.",
          "remediation": "Run the following command to modify the file permissions of the `--client-ca-file`\n\n \n```\nchmod 600 \u003cfilename\u003e\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 7
    },
    {
      "guid": "",
      "name": "Ensure that the client certificate authorities file ownership is set to root:root",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-4.1.8",
      "controlID": "CIS-4.1.8",
      "creationTime": "",
      "description": "Ensure that the certificate authorities file ownership is set to `root:root`.",
      "remediation": "Run the following command to modify the ownership of the `--client-ca-file`.\n\n \n```\nchown root:root \u003cfilename\u003e\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-client-certificate-authorities-file-ownership-is-set-to-root-root",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_kubelet_info(obj)\n\n\tfile_obj_path := [\"data\", \"clientCAFile\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual ownership check\n\tallowed_user := \"root\"\n\tallowed_group := \"root\"\n\tnot allowed_ownership(file.ownership, allowed_user, allowed_group)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"%s is not owned by %s:%s (actual owners are %s:%s)\", [\n\t\tfile.path,\n\t\tallowed_user,\n\t\tallowed_group,\n\t\tfile.ownership.username,\n\t\tfile.ownership.groupname,\n\t])\n\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chown %s:%s %s\", [allowed_user, allowed_group, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"KubeletInfo\"\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.error # Do not fail if ownership is not found\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.username == user\n\townership.groupname == group\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the certificate authorities file ownership is set to `root:root`.",
          "remediation": "Run the following command to modify the ownership of the `--client-ca-file`.\n\n \n```\nchown root:root \u003cfilename\u003e\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 7
    },
    {
      "guid": "",
      "name": "If the kubelet config.yaml configuration file is being used validate permissions set to 600 or more restrictive",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-4.1.9",
      "controlID": "CIS-4.1.9",
      "creationTime": "",
      "description": "Ensure that if the kubelet refers to a configuration file with the `--config` argument, that file has permissions of 600 or more restrictive.",
      "remediation": "Run the following command (using the config file location identied in the Audit step)\n\n \n```\nchmod 600 /var/lib/kubelet/config.yaml\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "if-the-kubelet-config.yaml-configuration-file-is-being-used-validate-permissions-set-to-600-or-more-restrictive",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_kubelet_info(obj)\n\n\tfile_obj_path := [\"data\", \"configFile\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual permissions test    \n\tallowed_perms := 384 # == 0o600\n\tnot cautils.unix_permissions_allow(allowed_perms, file.permissions)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"the permissions of %s are too permissive. maximum allowed: %o. actual: %o\", [file.path, allowed_perms, file.permissions])\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chmod %o %s\", [allowed_perms, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"KubeletInfo\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that if the kubelet refers to a configuration file with the `--config` argument, that file has permissions of 600 or more restrictive.",
          "remediation": "Run the following command (using the config file location identied in the Audit step)\n\n \n```\nchmod 600 /var/lib/kubelet/config.yaml\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 7
    },
    {
      "guid": "",
      "name": "If the kubelet config.yaml configuration file is being used validate file ownership is set to root:root",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-4.1.10",
      "controlID": "CIS-4.1.10",
      "creationTime": "",
      "description": "Ensure that if the kubelet refers to a configuration file with the `--config` argument, that file is owned by root:root.",
      "remediation": "Run the following command (using the config file location identied in the Audit step)\n\n \n```\nchown root:root /etc/kubernetes/kubelet.conf\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "if-the-kubelet-config.yaml-configuration-file-is-being-used-validate-file-ownership-is-set-to-root-root",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport data.cautils as cautils\nimport future.keywords.in\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_kubelet_info(obj)\n\n\tfile_obj_path := [\"data\", \"configFile\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual ownership check\n\tallowed_user := \"root\"\n\tallowed_group := \"root\"\n\tnot allowed_ownership(file.ownership, allowed_user, allowed_group)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"%s is not owned by %s:%s (actual owners are %s:%s)\", [\n\t\tfile.path,\n\t\tallowed_user,\n\t\tallowed_group,\n\t\tfile.ownership.username,\n\t\tfile.ownership.groupname,\n\t])\n\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chown %s:%s %s\", [allowed_user, allowed_group, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"KubeletInfo\"\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.error # Do not fail if ownership is not found\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.username == user\n\townership.groupname == group\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that if the kubelet refers to a configuration file with the `--config` argument, that file is owned by root:root.",
          "remediation": "Run the following command (using the config file location identied in the Audit step)\n\n \n```\nchown root:root /etc/kubernetes/kubelet.conf\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 7
    },
    {
      "guid": "",
      "name": "Ensure that the cluster-admin role is only used where required",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.1.1",
      "controlID": "CIS-5.1.1",
      "creationTime": "",
      "description": "The RBAC role `cluster-admin` provides wide-ranging powers over the environment and should be used only where and when needed.",
      "remediation": "Identify all clusterrolebindings to the cluster-admin role. Check if they are used and if they need this role or if they could use a role with fewer privileges.\n\n Where possible, first bind users to a lower privileged role and then remove the clusterrolebinding to the cluster-admin role :\n\n \n```\nkubectl delete clusterrolebinding [name]\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "cluster-admin-role",
          "attributes": {
            "armoBuiltin": true,
            "resourcesAggregator": "subject-role-rolebinding",
            "useFromKubescapeVersion": "v1.0.133"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n# returns subjects with cluster admin role\ndeny[msga] {\n\tsubjectVector := input[_]\n\n\trole := subjectVector.relatedObjects[i]\n\tendswith(role.kind, \"Role\")\n\n\trolebinding := subjectVector.relatedObjects[j]\n\tendswith(rolebinding.kind, \"Binding\")\n\n\trule := role.rules[p]\n\tsubject := rolebinding.subjects[k]\n\tis_same_subjects(subjectVector, subject)\n\n\t# check only cluster-admin role and only clusterrolebinding\n\trole.metadata.name == \"cluster-admin\"\n\trolebinding.kind == \"ClusterRoleBinding\"\n\n\trule_path := sprintf(\"relatedObjects[%d].rules[%d]\", [i, p])\n\n\tverbs := [\"*\"]\n\tverb_path := [sprintf(\"%s.verbs[%d]\", [rule_path, l]) | verb = rule.verbs[l]; verb in verbs]\n\tcount(verb_path) \u003e 0\n\n\tapi_groups := [\"*\", \"\"]\n\tapi_groups_path := [sprintf(\"%s.apiGroups[%d]\", [rule_path, a]) | apiGroup = rule.apiGroups[a]; apiGroup in api_groups]\n\tcount(api_groups_path) \u003e 0\n\n\tresources := [\"*\"]\n\tresources_path := [sprintf(\"%s.resources[%d]\", [rule_path, l]) | resource = rule.resources[l]; resource in resources]\n\tcount(resources_path) \u003e 0\n\n\tpath := array.concat(resources_path, verb_path)\n\tpath2 := array.concat(path, api_groups_path)\n\tfinalpath := array.concat(path2, [\n\t\tsprintf(\"relatedObjects[%d].subjects[%d]\", [j, k]),\n\t\tsprintf(\"relatedObjects[%d].roleRef.name\", [j]),\n\t])\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Subject: %s-%s is bound to cluster-admin role\", [subjectVector.kind, subjectVector.name]),\n\t\t\"alertScore\": 3,\n\t\t\"fixPaths\": [],\n\t\t\"failedPaths\": finalpath,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [],\n\t\t\t\"externalObjects\": subjectVector,\n\t\t},\n\t}\n}\n\n# for service accounts\nis_same_subjects(subjectVector, subject) {\n\tsubjectVector.kind == subject.kind\n\tsubjectVector.name == subject.name\n\tsubjectVector.namespace == subject.namespace\n}\n\n# for users/ groups\nis_same_subjects(subjectVector, subject) {\n\tsubjectVector.kind == subject.kind\n\tsubjectVector.name == subject.name\n\tsubjectVector.apiGroup == subject.apiGroup\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "*"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Role",
                "ClusterRole",
                "ClusterRoleBinding"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "determines which users have cluster admin permissions",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 8
    },
    {
      "guid": "",
      "name": "Minimize access to secrets",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.1.2",
      "controlID": "CIS-5.1.2",
      "creationTime": "",
      "description": "The Kubernetes API stores secrets, which may be service account tokens for the Kubernetes API or credentials used by workloads in the cluster. Access to these secrets should be restricted to the smallest possible group of users to reduce the risk of privilege escalation.",
      "remediation": "Where possible, remove `get`, `list` and `watch` access to `secret` objects in the cluster.",
      "rules": [
        {
          "guid": "",
          "name": "rule-can-list-get-secrets-v1",
          "attributes": {
            "armoBuiltin": true,
            "microsoftK8sThreatMatrix": "Discovery::Access the K8s API server",
            "resourcesAggregator": "subject-role-rolebinding",
            "useFromKubescapeVersion": "v1.0.133"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n# fails if user can list/get secrets \ndeny[msga] {\n\tsubjectVector := input[_]\n\trole := subjectVector.relatedObjects[i]\n\trolebinding := subjectVector.relatedObjects[j]\n\tendswith(role.kind, \"Role\")\n\tendswith(rolebinding.kind, \"Binding\")\n\n\trule := role.rules[p]\n\n\tsubject := rolebinding.subjects[k]\n\tis_same_subjects(subjectVector, subject)\n\nis_same_subjects(subjectVector, subject)\n\trule_path := sprintf(\"relatedObjects[%d].rules[%d]\", [i, p])\n\n\tverbs := [\"get\", \"list\", \"watch\", \"*\"]\n\tverb_path := [sprintf(\"%s.verbs[%d]\", [rule_path, l]) | verb = rule.verbs[l]; verb in verbs]\n\tcount(verb_path) \u003e 0\n\n\tapi_groups := [\"\", \"*\"]\n\tapi_groups_path := [sprintf(\"%s.apiGroups[%d]\", [rule_path, a]) | apiGroup = rule.apiGroups[a]; apiGroup in api_groups]\n\tcount(api_groups_path) \u003e 0\n\n\tresources := [\"secrets\", \"*\"]\n\tresources_path := [sprintf(\"%s.resources[%d]\", [rule_path, l]) | resource = rule.resources[l]; resource in resources]\n\tcount(resources_path) \u003e 0\n\n\tpath := array.concat(resources_path, verb_path)\n\tpath2 := array.concat(path, api_groups_path)\n\tfinalpath := array.concat(path2, [\n\t\tsprintf(\"relatedObjects[%d].subjects[%d]\", [j, k]),\n\t\tsprintf(\"relatedObjects[%d].roleRef.name\", [j]),\n\t])\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Subject: %s-%s can read secrets\", [subjectVector.kind, subjectVector.name]),\n\t\t\"alertScore\": 3,\n\t\t\"failedPaths\": finalpath,\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [],\n\t\t\t\"externalObjects\": subjectVector,\n\t\t},\n\t}\n}\n\n# for service accounts\nis_same_subjects(subjectVector, subject) {\n\tsubjectVector.kind == subject.kind\n\tsubjectVector.name == subject.name\n\tsubjectVector.namespace == subject.namespace\n}\n\n# for users/ groups\nis_same_subjects(subjectVector, subject) {\n\tsubjectVector.kind == subject.kind\n\tsubjectVector.name == subject.name\n\tsubjectVector.apiGroup == subject.apiGroup\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "*"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Role",
                "ClusterRole",
                "ClusterRoleBinding",
                "RoleBinding"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "determines which users can list/get secrets",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Minimize wildcard use in Roles and ClusterRoles",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.1.3",
      "controlID": "CIS-5.1.3",
      "creationTime": "",
      "description": "Kubernetes Roles and ClusterRoles provide access to resources based on sets of objects and actions that can be taken on those objects. It is possible to set either of these to be the wildcard \"\\*\" which matches all items.\n\n Use of wildcards is not optimal from a security perspective as it may allow for inadvertent access to be granted when new resources are added to the Kubernetes API either as CRDs or in later versions of the product.",
      "remediation": "Where possible replace any use of wildcards in clusterroles and roles with specific objects or actions.",
      "rules": [
        {
          "guid": "",
          "name": "rule-list-all-cluster-admins-v1",
          "attributes": {
            "armoBuiltin": true,
            "m$K8sThreatMatrix": "Privilege Escalation::Cluster-admin binding",
            "resourcesAggregator": "subject-role-rolebinding",
            "useFromKubescapeVersion": "v1.0.133"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n# returns subjects with cluster admin permissions\ndeny[msga] {\n\tsubjectVector := input[_]\n\trole := subjectVector.relatedObjects[i]\n\trolebinding := subjectVector.relatedObjects[j]\n\tendswith(role.kind, \"Role\")\n\tendswith(rolebinding.kind, \"Binding\")\n\n\trule := role.rules[p]\n\tsubject := rolebinding.subjects[k]\n\tis_same_subjects(subjectVector, subject)\n\nis_same_subjects(subjectVector, subject)\n\trule_path := sprintf(\"relatedObjects[%d].rules[%d]\", [i, p])\n\n\tverbs := [\"*\"]\n\tverb_path := [sprintf(\"%s.verbs[%d]\", [rule_path, l]) | verb = rule.verbs[l]; verb in verbs]\n\tcount(verb_path) \u003e 0\n\n\tapi_groups := [\"*\", \"\"]\n\tapi_groups_path := [sprintf(\"%s.apiGroups[%d]\", [rule_path, a]) | apiGroup = rule.apiGroups[a]; apiGroup in api_groups]\n\tcount(api_groups_path) \u003e 0\n\n\tresources := [\"*\"]\n\tresources_path := [sprintf(\"%s.resources[%d]\", [rule_path, l]) | resource = rule.resources[l]; resource in resources]\n\tcount(resources_path) \u003e 0\n\n\tpath := array.concat(resources_path, verb_path)\n\tpath2 := array.concat(path, api_groups_path)\n\tfinalpath := array.concat(path2, [\n\t\tsprintf(\"relatedObjects[%d].subjects[%d]\", [j, k]),\n\t\tsprintf(\"relatedObjects[%d].roleRef.name\", [j]),\n\t])\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Subject: %s-%s have high privileges, such as cluster-admin\", [subjectVector.kind, subjectVector.name]),\n\t\t\"alertScore\": 3,\n\t\t\"fixPaths\": [],\n\t\t\"failedPaths\": finalpath,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [],\n\t\t\t\"externalObjects\": subjectVector,\n\t\t},\n\t}\n}\n\n# for service accounts\nis_same_subjects(subjectVector, subject) {\n\tsubjectVector.kind == subject.kind\n\tsubjectVector.name == subject.name\n\tsubjectVector.namespace == subject.namespace\n}\n\n# for users/ groups\nis_same_subjects(subjectVector, subject) {\n\tsubjectVector.kind == subject.kind\n\tsubjectVector.name == subject.name\n\tsubjectVector.apiGroup == subject.apiGroup\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "*"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Role",
                "ClusterRole",
                "ClusterRoleBinding",
                "RoleBinding"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "determines which users have cluster admin permissions",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 7
    },
    {
      "guid": "",
      "name": "Minimize access to create pods",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.1.4",
      "controlID": "CIS-5.1.4",
      "creationTime": "",
      "description": "The ability to create pods in a namespace can provide a number of opportunities for privilege escalation, such as assigning privileged service accounts to these pods or mounting hostPaths with access to sensitive data (unless Pod Security Policies are implemented to restrict this access)\n\n As such, access to create new pods should be restricted to the smallest possible group of users.",
      "remediation": "Where possible, remove `create` access to `pod` objects in the cluster.",
      "rules": [
        {
          "guid": "",
          "name": "rule-can-create-pod",
          "attributes": {
            "armoBuiltin": true,
            "resourcesAggregator": "subject-role-rolebinding",
            "useFromKubescapeVersion": "v1.0.133"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n# fails if user has create access to pods\ndeny[msga] {\n\tsubjectVector := input[_]\n\trole := subjectVector.relatedObjects[i]\n\trolebinding := subjectVector.relatedObjects[j]\n\tendswith(role.kind, \"Role\")\n\tendswith(rolebinding.kind, \"Binding\")\n\n\trule := role.rules[p]\n\n\tsubject := rolebinding.subjects[k]\n\tis_same_subjects(subjectVector, subject)\n\nis_same_subjects(subjectVector, subject)\n\trule_path := sprintf(\"relatedObjects[%d].rules[%d]\", [i, p])\n\n\tverbs := [\"create\", \"*\"]\n\tverb_path := [sprintf(\"%s.verbs[%d]\", [rule_path, l]) | verb = rule.verbs[l]; verb in verbs]\n\tcount(verb_path) \u003e 0\n\n\tapi_groups := [\"\", \"*\"]\n\tapi_groups_path := [sprintf(\"%s.apiGroups[%d]\", [rule_path, a]) | apiGroup = rule.apiGroups[a]; apiGroup in api_groups]\n\tcount(api_groups_path) \u003e 0\n\n\tresources := [\"pods\", \"*\"]\n\tresources_path := [sprintf(\"%s.resources[%d]\", [rule_path, l]) | resource = rule.resources[l]; resource in resources]\n\tcount(resources_path) \u003e 0\n\n\tpath := array.concat(resources_path, verb_path)\n\tpath2 := array.concat(path, api_groups_path)\n\tfinalpath := array.concat(path2, [\n\t\tsprintf(\"relatedObjects[%d].subjects[%d]\", [j, k]),\n\t\tsprintf(\"relatedObjects[%d].roleRef.name\", [j]),\n\t])\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Subject: %s-%s can create pods\", [subjectVector.kind, subjectVector.name]),\n\t\t\"alertScore\": 3,\n\t\t\"failedPaths\": finalpath,\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [],\n\t\t\t\"externalObjects\": subjectVector,\n\t\t},\n\t}\n}\n\n# for service accounts\nis_same_subjects(subjectVector, subject) {\n\tsubjectVector.kind == subject.kind\n\tsubjectVector.name == subject.name\n\tsubjectVector.namespace == subject.namespace\n}\n\n# for users/ groups\nis_same_subjects(subjectVector, subject) {\n\tsubjectVector.kind == subject.kind\n\tsubjectVector.name == subject.name\n\tsubjectVector.apiGroup == subject.apiGroup\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "*"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Role",
                "ClusterRole",
                "ClusterRoleBinding",
                "RoleBinding"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "determines which users can create pods",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 5
    },
    {
      "guid": "",
      "name": "Ensure that default service accounts are not actively used",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.1.5",
      "controlID": "CIS-5.1.5",
      "creationTime": "",
      "description": "The `default` service account should not be used to ensure that rights granted to applications can be more easily audited and reviewed.",
      "remediation": "Create explicit service accounts wherever a Kubernetes workload requires specific access to the Kubernetes API server.\n\n Modify the configuration of each default service account to include this value\n\n \n```\nautomountServiceAccountToken: false\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "automount-default-service-account",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\n# Fails if user account mount tokens in pod by default\ndeny [msga]{\n    service_accounts := [service_account |  service_account= input[_]; service_account.kind == \"ServiceAccount\"]\n    service_account := service_accounts[_]\n\tservice_account.metadata.name == \"default\"\n    result := is_auto_mount(service_account)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\n    msga := {\n\t    \"alertMessage\": sprintf(\"the following service account: %v in the following namespace: %v mounts service account tokens in pods by default\", [service_account.metadata.name, service_account.metadata.namespace]),\n\t\t\"alertScore\": 9,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"fixPaths\": fixed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [service_account]\n\t\t}\n\t}\n}    \n\n\nget_failed_path(paths) = [paths[0]] {\n\tpaths[0] != \"\"\n} else = []\n\n\nget_fixed_path(paths) = [paths[1]] {\n\tpaths[1] != \"\"\n} else = []\n\n\n\n #  -- ----     For SAs     -- ----     \nis_auto_mount(service_account)  =  [failed_path, fix_path]  {\n\tservice_account.automountServiceAccountToken == true\n\tfailed_path = \"automountServiceAccountToken\"\n\tfix_path = \"\"\n}\n\nis_auto_mount(service_account)=  [failed_path, fix_path]  {\n\tnot service_account.automountServiceAccountToken == false\n\tnot service_account.automountServiceAccountToken == true\n\tfix_path = {\"path\": \"automountServiceAccountToken\", \"value\": \"false\"}\n\tfailed_path = \"\"\n}\n",
          "resourceEnumerator": "package armo_builtins\n\n# Fails if user account mount tokens in pod by default\ndeny [msga]{\n    service_accounts := [service_account |  service_account= input[_]; service_account.kind == \"ServiceAccount\"]\n    service_account := service_accounts[_]\n\tservice_account.metadata.name == \"default\"\n\n    msga := {\n\t    \"alertMessage\": sprintf(\"the following service account: %v in the following namespace: %v mounts service account tokens in pods by default\", [service_account.metadata.name, service_account.metadata.namespace]),\n\t\t\"alertScore\": 9,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"fixPaths\": [],\n\t\t\"failedPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [service_account]\n\t\t}\n\t}\n}    \n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "ServiceAccount"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "fails if default service account mounts service account token by default",
          "remediation": "Make sure that the automountServiceAccountToken field on the default service account spec is set to false",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "namespace-without-service-account",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\n\n# Fails if namespace does not have service accounts (not incluiding default)\ndeny[msga] {\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\tserviceAccounts := [serviceaccount |  serviceaccount= input[_]; is_good_sa(serviceaccount, namespace.metadata.name)]\n\tcount(serviceAccounts) \u003c 1\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not have any service accounts besides 'default'\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\t\n\t\nis_good_sa(sa, namespace) { \n\tsa.kind == \"ServiceAccount\"\n\tsa.metadata.namespace == namespace\n\tsa.metadata.name != \"default\"\n}",
          "resourceEnumerator": "package armo_builtins\n\n\n# Fails if namespace does not have service accounts (not incluiding default)\ndeny[msga] {\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\t\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not have any service accounts besides 'default'\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "*"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Namespace",
                "ServiceAccount"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "fails if namespace does not have service accounts (not incluiding default)",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        "",
        ""
      ],
      "baseScore": 5
    },
    {
      "guid": "",
      "name": "Ensure that Service Account Tokens are only mounted where necessary",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.1.6",
      "controlID": "CIS-5.1.6",
      "creationTime": "",
      "description": "Service accounts tokens should not be mounted in pods except where the workload running in the pod explicitly needs to communicate with the API server",
      "remediation": "Modify the definition of pods and service accounts which do not need to mount service account tokens to disable it.",
      "rules": [
        {
          "guid": "",
          "name": "automount-service-account",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\n# Fails if user account mount tokens in pod by default\ndeny [msga]{\n    service_accounts := [service_account |  service_account= input[_]; service_account.kind == \"ServiceAccount\"]\n    service_account := service_accounts[_]\n    result := is_auto_mount(service_account)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\n    msga := {\n\t    \"alertMessage\": sprintf(\"the following service account: %v in the following namespace: %v mounts service account tokens in pods by default\", [service_account.metadata.name, service_account.metadata.namespace]),\n\t\t\"alertScore\": 9,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"fixPaths\": fixed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [service_account]\n\t\t}\n\t}\n}    \n\n\n #  -- ----     For workloads     -- ----   \n# Fails if pod mount tokens  by default (either by its config or by its SA config)\n\n # POD  \ndeny [msga]{\n    pod := input[_]\n\tpod.kind == \"Pod\"\n\n\tbeggining_of_path := \"spec.\"\n\twl_namespace := pod.metadata.namespace\n\tresult := is_sa_auto_mounted(pod.spec, beggining_of_path, wl_namespace)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\n    msga := {\n\t    \"alertMessage\": sprintf(\"Pod: %v in the following namespace: %v mounts service account tokens by default\", [pod.metadata.name, pod.metadata.namespace]),\n\t\t\"alertScore\": 9,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"fixPaths\": fixed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}    \n\n# WORKLOADS\ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n\tbeggining_of_path := \"spec.template.spec.\"\n\n\twl_namespace := wl.metadata.namespace\n\tresult := is_sa_auto_mounted(wl.spec.template.spec, beggining_of_path, wl_namespace)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\n\tmsga := {\n\t\t\"alertMessage\":  sprintf(\"%v: %v in the following namespace: %v mounts service account tokens by default\", [wl.kind, wl.metadata.name, wl.metadata.namespace]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n# CRONJOB\ndeny[msga] {\n  \twl := input[_]\n\twl.kind == \"CronJob\"\n\tcontainer = wl.spec.jobTemplate.spec.template.spec.containers[i]\n\tbeggining_of_path := \"spec.jobTemplate.spec.template.spec.\"\n   \n\twl_namespace := wl.metadata.namespace\n\tresult := is_sa_auto_mounted(wl.spec.jobTemplate.spec.template.spec, beggining_of_path, wl_namespace)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v in the following namespace: %v mounts service account tokens by default\", [wl.kind, wl.metadata.name, wl.metadata.namespace]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n\n\n #  -- ----     For workloads     -- ----     \nis_sa_auto_mounted(spec, beggining_of_path, wl_namespace) = [failed_path, fix_path]   {\n\t# automountServiceAccountToken not in pod spec\n\tnot spec.automountServiceAccountToken == false\n\tnot spec.automountServiceAccountToken == true\n\n\t# check if SA  automount by default\n\tsa := input[_]\n\tis_same_sa(spec, sa.metadata.name)\n\tis_same_namespace(sa.metadata.namespace , wl_namespace)\n\tnot sa.automountServiceAccountToken == false\n\n\t# path is pod spec\n\tfix_path = { \"path\": sprintf(\"%vautomountServiceAccountToken\", [beggining_of_path]), \"value\": \"false\"}\n\tfailed_path = \"\"\n}\n\nget_failed_path(paths) = [paths[0]] {\n\tpaths[0] != \"\"\n} else = []\n\n\nget_fixed_path(paths) = [paths[1]] {\n\tpaths[1] != \"\"\n} else = []\n\nis_sa_auto_mounted(spec, beggining_of_path, wl_namespace) =  [failed_path, fix_path]  {\n\t# automountServiceAccountToken set to true in pod spec\n\tspec.automountServiceAccountToken == true\n\t\n\t# SA automount by default\n\tservice_accounts := [service_account | service_account = input[_]; service_account.kind == \"ServiceAccount\"]\n\tcount(service_accounts) \u003e 0\n\tsa := service_accounts[_]\n\tis_same_sa(spec, sa.metadata.name)\n\tis_same_namespace(sa.metadata.namespace , wl_namespace)\n\tnot sa.automountServiceAccountToken == false\n\n\tfailed_path = sprintf(\"%vautomountServiceAccountToken\", [beggining_of_path])\n\tfix_path = \"\"\n}\n\nis_sa_auto_mounted(spec, beggining_of_path, wl_namespace) =  [failed_path, fix_path]  {\n\t# automountServiceAccountToken set to true in pod spec\n\tspec.automountServiceAccountToken == true\n\t\n\t# No SA (yaml scan)\n\tservice_accounts := [service_account | service_account = input[_]; service_account.kind == \"ServiceAccount\"]\n\tcount(service_accounts) == 0\n\tfailed_path = sprintf(\"%vautomountServiceAccountToken\", [beggining_of_path])\n\tfix_path = \"\"\n}\n\n\n\n #  -- ----     For SAs     -- ----     \nis_auto_mount(service_account)  =  [failed_path, fix_path]  {\n\tservice_account.automountServiceAccountToken == true\n\tfailed_path = \"automountServiceAccountToken\"\n\tfix_path = \"\"\n}\n\nis_auto_mount(service_account)=  [failed_path, fix_path]  {\n\tnot service_account.automountServiceAccountToken == false\n\tnot service_account.automountServiceAccountToken == true\n\tfix_path = {\"path\": \"automountServiceAccountToken\", \"value\": \"false\"}\n\tfailed_path = \"\"\n}\n\nis_same_sa(spec, serviceAccountName) {\n\tspec.serviceAccountName == serviceAccountName\n}\n\nis_same_sa(spec, serviceAccountName) {\n\tnot spec.serviceAccountName \n\tserviceAccountName == \"default\"\n}\n\n\nis_same_namespace(metadata1, metadata2) {\n\tmetadata1.namespace == metadata2.namespace\n}\n\nis_same_namespace(metadata1, metadata2) {\n\tnot metadata1.namespace\n\tnot metadata2.namespace\n}\n\nis_same_namespace(metadata1, metadata2) {\n\tnot metadata2.namespace\n\tmetadata1.namespace == \"default\"\n}\n\nis_same_namespace(metadata1, metadata2) {\n\tnot metadata1.namespace\n\tmetadata2.namespace == \"default\"\n}",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod",
                "ServiceAccount"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Deployment",
                "ReplicaSet",
                "DaemonSet",
                "StatefulSet"
              ]
            },
            {
              "apiGroups": [
                "batch"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Job",
                "CronJob"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "fails if service account and workloads mount service account token by default",
          "remediation": "Make sure that the automountServiceAccountToken field on the service account spec if set to false",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 5
    },
    {
      "guid": "",
      "name": "Limit use of the Bind, Impersonate and Escalate permissions in the Kubernetes cluster",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.1.8",
      "controlID": "CIS-5.1.8",
      "creationTime": "",
      "description": "Cluster roles and roles with the impersonate, bind or escalate permissions should not be granted unless strictly required. Each of these permissions allow a particular subject to escalate their privileges beyond those explicitly granted by cluster administrators",
      "remediation": "Where possible, remove the impersonate, bind and escalate rights from subjects.",
      "rules": [
        {
          "guid": "",
          "name": "rule-can-bind-escalate",
          "attributes": {
            "armoBuiltin": true,
            "resourcesAggregator": "subject-role-rolebinding",
            "useFromKubescapeVersion": "v1.0.133"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n# ================= bind ===============================\n\n# fails if user has access to bind clusterroles/roles\ndeny[msga] {\n\tsubjectVector := input[_]\n\trole := subjectVector.relatedObjects[i]\n\trolebinding := subjectVector.relatedObjects[j]\n\tendswith(role.kind, \"Role\")\n\tendswith(rolebinding.kind, \"Binding\")\n\trule := role.rules[p]\n\n\tsubject := rolebinding.subjects[k]\n\tis_same_subjects(subjectVector, subject)\n\n\trule_path := sprintf(\"relatedObjects[%d].rules[%d]\", [i, p])\n\n\tverbs := [\"bind\", \"*\"]\n\tverb_path := [sprintf(\"%s.verbs[%d]\", [rule_path, l]) | verb = rule.verbs[l]; verb in verbs]\n\tcount(verb_path) \u003e 0\n\n\tapi_groups := [\"rbac.authorization.k8s.io\", \"*\"]\n\tapi_groups_path := [sprintf(\"%s.apiGroups[%d]\", [rule_path, a]) | apiGroup = rule.apiGroups[a]; apiGroup in api_groups]\n\tcount(api_groups_path) \u003e 0\n\n\tresources := [\"clusterroles\", \"roles\", \"*\"]\n\tresources_path := [sprintf(\"%s.resources[%d]\", [rule_path, l]) | resource = rule.resources[l]; resource in resources]\n\tcount(resources_path) \u003e 0\n\n\tpath := array.concat(resources_path, verb_path)\n\tpath2 := array.concat(path, api_groups_path)\n\tfinalpath := array.concat(path2, [\n\t\tsprintf(\"relatedObjects[%d].subjects[%d]\", [j, k]),\n\t\tsprintf(\"relatedObjects[%d].roleRef.name\", [j]),\n\t])\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Subject: %s-%s can bind roles/clusterroles\", [subjectVector.kind, subjectVector.name]),\n\t\t\"alertScore\": 3,\n\t\t\"failedPaths\": finalpath,\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [],\n\t\t\t\"externalObjects\": subjectVector,\n\t\t},\n\t}\n}\n\n# ================= escalate ===============================\n\n# fails if user has access to escalate roles/clusterroles\ndeny[msga] {\n\tsubjectVector := input[_]\n\trole := subjectVector.relatedObjects[i]\n\trolebinding := subjectVector.relatedObjects[j]\n\tendswith(role.kind, \"Role\")\n\tendswith(rolebinding.kind, \"Binding\")\n\n\trule := role.rules[p]\n\n\tsubject := rolebinding.subjects[k]\n\tis_same_subjects(subjectVector, subject)\n\n\tis_same_subjects(subjectVector, subject)\n\trule_path := sprintf(\"relatedObjects[%d].rules[%d]\", [i, p])\n\n\tverbs := [\"escalate\", \"*\"]\n\tverb_path := [sprintf(\"%s.verbs[%d]\", [rule_path, l]) | verb = rule.verbs[l]; verb in verbs]\n\tcount(verb_path) \u003e 0\n\n\tapi_groups := [\"rbac.authorization.k8s.io\", \"*\"]\n\tapi_groups_path := [sprintf(\"%s.apiGroups[%d]\", [rule_path, a]) | apiGroup = rule.apiGroups[a]; apiGroup in api_groups]\n\tcount(api_groups_path) \u003e 0\n\n\tresources := [\"clusterroles\", \"roles\", \"*\"]\n\tresources_path := [sprintf(\"%s.resources[%d]\", [rule_path, l]) | resource = rule.resources[l]; resource in resources]\n\tcount(resources_path) \u003e 0\n\n\tpath := array.concat(resources_path, verb_path)\n\tpath2 := array.concat(path, api_groups_path)\n\tfinalpath := array.concat(path2, [\n\t\tsprintf(\"relatedObjects[%d].subjects[%d]\", [j, k]),\n\t\tsprintf(\"relatedObjects[%d].roleRef.name\", [j]),\n\t])\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Subject: %s-%s can escalate roles/clusterroles\", [subjectVector.kind, subjectVector.name]),\n\t\t\"alertScore\": 3,\n\t\t\"failedPaths\": finalpath,\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [],\n\t\t\t\"externalObjects\": subjectVector,\n\t\t},\n\t}\n}\n\n# for service accounts\nis_same_subjects(subjectVector, subject) {\n\tsubjectVector.kind == subject.kind\n\tsubjectVector.name == subject.name\n\tsubjectVector.namespace == subject.namespace\n}\n\n# for users/ groups\nis_same_subjects(subjectVector, subject) {\n\tsubjectVector.kind == subject.kind\n\tsubjectVector.name == subject.name\n\tsubjectVector.apiGroup == subject.apiGroup\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "*"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Role",
                "ClusterRole",
                "ClusterRoleBinding",
                "RoleBinding"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "determines which users can or bind escalate roles/clusterroles",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "rule-can-impersonate-users-groups-v1",
          "attributes": {
            "armoBuiltin": true,
            "microsoftK8sThreatMatrix": "Discovery::Access the K8s API server",
            "resourcesAggregator": "subject-role-rolebinding",
            "useFromKubescapeVersion": "v1.0.133"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msga] {\n\tsubjectVector := input[_]\n\trole := subjectVector.relatedObjects[i]\n\trolebinding := subjectVector.relatedObjects[j]\n\tendswith(role.kind, \"Role\")\n\tendswith(rolebinding.kind, \"Binding\")\n\n\trule := role.rules[p]\n\n\tsubject := rolebinding.subjects[k]\n\tis_same_subjects(subjectVector, subject)\n\nis_same_subjects(subjectVector, subject)\n\trule_path := sprintf(\"relatedObjects[%d].rules[%d]\", [i, p])\n\n\tverbs := [\"impersonate\", \"*\"]\n\tverb_path := [sprintf(\"%s.verbs[%d]\", [rule_path, l]) | verb = rule.verbs[l]; verb in verbs]\n\tcount(verb_path) \u003e 0\n\n\tapi_groups := [\"\", \"*\"]\n\tapi_groups_path := [sprintf(\"%s.apiGroups[%d]\", [rule_path, a]) | apiGroup = rule.apiGroups[a]; apiGroup in api_groups]\n\tcount(api_groups_path) \u003e 0\n\n\tresources := [\"users\", \"serviceaccounts\", \"groups\", \"uids\", \"*\"]\n\tresources_path := [sprintf(\"%s.resources[%d]\", [rule_path, l]) | resource = rule.resources[l]; resource in resources]\n\tcount(resources_path) \u003e 0\n\n\tpath := array.concat(resources_path, verb_path)\n\tpath2 := array.concat(path, api_groups_path)\n\tfinalpath := array.concat(path2, [\n\t\tsprintf(\"relatedObjects[%d].subjects[%d]\", [j, k]),\n\t\tsprintf(\"relatedObjects[%d].roleRef.name\", [j]),\n\t])\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Subject: %s-%s can impersonate users\", [subjectVector.kind, subjectVector.name]),\n\t\t\"alertScore\": 3,\n\t\t\"failedPaths\": finalpath,\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [],\n\t\t\t\"externalObjects\": subjectVector,\n\t\t},\n\t}\n}\n\n# for service accounts\nis_same_subjects(subjectVector, subject) {\n\tsubjectVector.kind == subject.kind\n\tsubjectVector.name == subject.name\n\tsubjectVector.namespace == subject.namespace\n}\n\n# for users/ groups\nis_same_subjects(subjectVector, subject) {\n\tsubjectVector.kind == subject.kind\n\tsubjectVector.name == subject.name\n\tsubjectVector.apiGroup == subject.apiGroup\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "*"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Role",
                "ClusterRole",
                "ClusterRoleBinding",
                "RoleBinding"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "determines which users can impersonate users/groups",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        "",
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Ensure that the cluster has at least one active policy control mechanism in place",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.2.1",
      "controlID": "CIS-5.2.1",
      "creationTime": "",
      "description": "Every Kubernetes cluster should have at least one policy control mechanism in place to enforce the other requirements in this section. This could be the in-built Pod Security Admission controller, or a third party policy control system.",
      "remediation": "Ensure that either Pod Security Admission or an external policy control system is in place for every namespace which contains user workloads.",
      "rules": [
        {
          "guid": "",
          "name": "pod-security-admission-applied",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\nimport future.keywords.every\n\n# Fails if no 3rd party security admission exists and namespace does not have relevant labels\ndeny[msga] {\n    not has_external_policy_control(input)\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\tnot admission_policy_enabled(namespace)\n\tfix_path = {\"path\": \"metadata.labels[pod-security.kubernetes.io/enforce]\", \"value\": \"YOUR_VALUE\"}\n    \n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [fix_path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\nadmission_policy_enabled(namespace){\n\tsome label, _ in namespace.metadata.labels \n    startswith(label, \"pod-security.kubernetes.io/enforce\")\n}\n\nhas_external_policy_control(inp){\n    admissionwebhook := inp[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msga] {\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\t\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Namespace"
              ]
            },
            {
              "apiGroups": [
                "admissionregistration.k8s.io"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "ValidatingWebhookConfiguration",
                "MutatingWebhookConfiguration"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Checks that every namespace enabled pod security admission, or if there are external policies applied for namespaced resources (validating/mutating webhooks)",
          "remediation": "Ensure that either Pod Security Admission or an external policy control system is in place for every namespace which contains user workloads.\n\n#### Impact Statement\nWhere policy control systems are in place, there is a risk that workloads required for the operation of the cluster may be stopped from running. Care is required when implementing admission control policies to ensure that this does not occur.\n\n#### Default Value\nBy default, Pod Security Admission is enabled but no policies are in place.",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 4
    },
    {
      "guid": "",
      "name": "Minimize the admission of privileged containers",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.2.2",
      "controlID": "CIS-5.2.2",
      "creationTime": "",
      "description": "Do not generally permit containers to be run with the `securityContext.privileged` flag set to `true`.",
      "remediation": "Add policies to each namespace in the cluster which has user workloads to restrict the admission of privileged containers.",
      "rules": [
        {
          "guid": "",
          "name": "pod-security-admission-baseline-applied",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\nimport future.keywords.in\n\n# Fails if namespace does not have relevant labels and no 3rd party security admission exists\ndeny[msga] {\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\tnot baseline_admission_policy_enabled(namespace)\n    not has_external_policy_control(input)\n\tfix_path = {\"path\": \"metadata.labels[pod-security.kubernetes.io/enforce]\", \"value\": \"baseline\"}\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable baseline pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [fix_path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\n# Fails if at least 1 namespace does not have relevant labels and 3rd party namespaced security admission EXISTS\n# returns webhook configuration for user to review\ndeny[msga] {\n\tsome namespace in input\n\tnamespace.kind == \"Namespace\"\n\tnot baseline_admission_policy_enabled(namespace)\n\n    admissionwebhook := input[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Review webhook: %v ensure that it defines the required policy\", [admissionwebhook.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [admissionwebhook]\n\t\t}\n\t}\n}\n\n\nbaseline_admission_policy_enabled(namespace){\n\tsome key, value in namespace.metadata.labels \n    key == \"pod-security.kubernetes.io/enforce\"\n\tvalue in [\"baseline\", \"restricted\"]\n}\n\nhas_external_policy_control(inp){\n    some admissionwebhook in inp\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "resourceEnumerator": "package armo_builtins\nimport future.keywords.in\n\n# if no 3rd party security admission exists - Fails if namespace does not have relevant labels\ndeny[msga] {\n    not has_external_policy_control(input)\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable baseline pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\n# Fails if at least 1 namespace does not have relevant labels and 3rd party namespaced security admission EXISTS\n# returns webhook configuration for user to review\ndeny[msga] {\n\tsome namespace in input\n\tnamespace.kind == \"Namespace\"\n\tnot baseline_admission_policy_enabled(namespace)\n\n    admissionwebhook := input[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Review webhook: %v ensure that it defines the required policy\", [admissionwebhook.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [admissionwebhook]\n\t\t}\n\t}\n}\n\n\nbaseline_admission_policy_enabled(namespace){\n\tsome key, value in namespace.metadata.labels \n    key == \"pod-security.kubernetes.io/enforce\"\n\tvalue in [\"baseline\", \"restricted\"]\n}\n\nhas_external_policy_control(inp){\n    some admissionwebhook in inp\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Namespace"
              ]
            },
            {
              "apiGroups": [
                "admissionregistration.k8s.io"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "ValidatingWebhookConfiguration",
                "MutatingWebhookConfiguration"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Checks that every namespace enabled baseline pod security admission, or if there are external policies applied for namespaced resources (validating/mutating webhooks) - returns them to be reviewed",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 8
    },
    {
      "guid": "",
      "name": "Minimize the admission of containers wishing to share the host process ID namespace",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.2.3",
      "controlID": "CIS-5.2.3",
      "creationTime": "",
      "description": "Do not generally permit containers to be run with the `hostPID` flag set to true.",
      "remediation": "Add policies to each namespace in the cluster which has user workloads to restrict the admission of `hostPID` containers.",
      "rules": [
        {
          "guid": "",
          "name": "pod-security-admission-baseline-applied",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\nimport future.keywords.in\n\n# Fails if namespace does not have relevant labels and no 3rd party security admission exists\ndeny[msga] {\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\tnot baseline_admission_policy_enabled(namespace)\n    not has_external_policy_control(input)\n\tfix_path = {\"path\": \"metadata.labels[pod-security.kubernetes.io/enforce]\", \"value\": \"baseline\"}\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable baseline pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [fix_path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\n# Fails if at least 1 namespace does not have relevant labels and 3rd party namespaced security admission EXISTS\n# returns webhook configuration for user to review\ndeny[msga] {\n\tsome namespace in input\n\tnamespace.kind == \"Namespace\"\n\tnot baseline_admission_policy_enabled(namespace)\n\n    admissionwebhook := input[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Review webhook: %v ensure that it defines the required policy\", [admissionwebhook.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [admissionwebhook]\n\t\t}\n\t}\n}\n\n\nbaseline_admission_policy_enabled(namespace){\n\tsome key, value in namespace.metadata.labels \n    key == \"pod-security.kubernetes.io/enforce\"\n\tvalue in [\"baseline\", \"restricted\"]\n}\n\nhas_external_policy_control(inp){\n    some admissionwebhook in inp\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "resourceEnumerator": "package armo_builtins\nimport future.keywords.in\n\n# if no 3rd party security admission exists - Fails if namespace does not have relevant labels\ndeny[msga] {\n    not has_external_policy_control(input)\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable baseline pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\n# Fails if at least 1 namespace does not have relevant labels and 3rd party namespaced security admission EXISTS\n# returns webhook configuration for user to review\ndeny[msga] {\n\tsome namespace in input\n\tnamespace.kind == \"Namespace\"\n\tnot baseline_admission_policy_enabled(namespace)\n\n    admissionwebhook := input[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Review webhook: %v ensure that it defines the required policy\", [admissionwebhook.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [admissionwebhook]\n\t\t}\n\t}\n}\n\n\nbaseline_admission_policy_enabled(namespace){\n\tsome key, value in namespace.metadata.labels \n    key == \"pod-security.kubernetes.io/enforce\"\n\tvalue in [\"baseline\", \"restricted\"]\n}\n\nhas_external_policy_control(inp){\n    some admissionwebhook in inp\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Namespace"
              ]
            },
            {
              "apiGroups": [
                "admissionregistration.k8s.io"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "ValidatingWebhookConfiguration",
                "MutatingWebhookConfiguration"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Checks that every namespace enabled baseline pod security admission, or if there are external policies applied for namespaced resources (validating/mutating webhooks) - returns them to be reviewed",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 5
    },
    {
      "guid": "",
      "name": "Minimize the admission of containers wishing to share the host IPC namespace",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.2.4",
      "controlID": "CIS-5.2.4",
      "creationTime": "",
      "description": "Do not generally permit containers to be run with the `hostIPC` flag set to true.",
      "remediation": "Add policies to each namespace in the cluster which has user workloads to restrict the admission of `hostIPC` containers.",
      "rules": [
        {
          "guid": "",
          "name": "pod-security-admission-baseline-applied",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\nimport future.keywords.in\n\n# Fails if namespace does not have relevant labels and no 3rd party security admission exists\ndeny[msga] {\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\tnot baseline_admission_policy_enabled(namespace)\n    not has_external_policy_control(input)\n\tfix_path = {\"path\": \"metadata.labels[pod-security.kubernetes.io/enforce]\", \"value\": \"baseline\"}\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable baseline pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [fix_path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\n# Fails if at least 1 namespace does not have relevant labels and 3rd party namespaced security admission EXISTS\n# returns webhook configuration for user to review\ndeny[msga] {\n\tsome namespace in input\n\tnamespace.kind == \"Namespace\"\n\tnot baseline_admission_policy_enabled(namespace)\n\n    admissionwebhook := input[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Review webhook: %v ensure that it defines the required policy\", [admissionwebhook.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [admissionwebhook]\n\t\t}\n\t}\n}\n\n\nbaseline_admission_policy_enabled(namespace){\n\tsome key, value in namespace.metadata.labels \n    key == \"pod-security.kubernetes.io/enforce\"\n\tvalue in [\"baseline\", \"restricted\"]\n}\n\nhas_external_policy_control(inp){\n    some admissionwebhook in inp\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "resourceEnumerator": "package armo_builtins\nimport future.keywords.in\n\n# if no 3rd party security admission exists - Fails if namespace does not have relevant labels\ndeny[msga] {\n    not has_external_policy_control(input)\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable baseline pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\n# Fails if at least 1 namespace does not have relevant labels and 3rd party namespaced security admission EXISTS\n# returns webhook configuration for user to review\ndeny[msga] {\n\tsome namespace in input\n\tnamespace.kind == \"Namespace\"\n\tnot baseline_admission_policy_enabled(namespace)\n\n    admissionwebhook := input[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Review webhook: %v ensure that it defines the required policy\", [admissionwebhook.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [admissionwebhook]\n\t\t}\n\t}\n}\n\n\nbaseline_admission_policy_enabled(namespace){\n\tsome key, value in namespace.metadata.labels \n    key == \"pod-security.kubernetes.io/enforce\"\n\tvalue in [\"baseline\", \"restricted\"]\n}\n\nhas_external_policy_control(inp){\n    some admissionwebhook in inp\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Namespace"
              ]
            },
            {
              "apiGroups": [
                "admissionregistration.k8s.io"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "ValidatingWebhookConfiguration",
                "MutatingWebhookConfiguration"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Checks that every namespace enabled baseline pod security admission, or if there are external policies applied for namespaced resources (validating/mutating webhooks) - returns them to be reviewed",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 5
    },
    {
      "guid": "",
      "name": "Minimize the admission of containers wishing to share the host network namespace",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.2.5",
      "controlID": "CIS-5.2.5",
      "creationTime": "",
      "description": "Do not generally permit containers to be run with the `hostNetwork` flag set to true.",
      "remediation": "Add policies to each namespace in the cluster which has user workloads to restrict the admission of `hostNetwork` containers.",
      "rules": [
        {
          "guid": "",
          "name": "pod-security-admission-baseline-applied",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\nimport future.keywords.in\n\n# Fails if namespace does not have relevant labels and no 3rd party security admission exists\ndeny[msga] {\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\tnot baseline_admission_policy_enabled(namespace)\n    not has_external_policy_control(input)\n\tfix_path = {\"path\": \"metadata.labels[pod-security.kubernetes.io/enforce]\", \"value\": \"baseline\"}\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable baseline pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [fix_path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\n# Fails if at least 1 namespace does not have relevant labels and 3rd party namespaced security admission EXISTS\n# returns webhook configuration for user to review\ndeny[msga] {\n\tsome namespace in input\n\tnamespace.kind == \"Namespace\"\n\tnot baseline_admission_policy_enabled(namespace)\n\n    admissionwebhook := input[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Review webhook: %v ensure that it defines the required policy\", [admissionwebhook.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [admissionwebhook]\n\t\t}\n\t}\n}\n\n\nbaseline_admission_policy_enabled(namespace){\n\tsome key, value in namespace.metadata.labels \n    key == \"pod-security.kubernetes.io/enforce\"\n\tvalue in [\"baseline\", \"restricted\"]\n}\n\nhas_external_policy_control(inp){\n    some admissionwebhook in inp\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "resourceEnumerator": "package armo_builtins\nimport future.keywords.in\n\n# if no 3rd party security admission exists - Fails if namespace does not have relevant labels\ndeny[msga] {\n    not has_external_policy_control(input)\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable baseline pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\n# Fails if at least 1 namespace does not have relevant labels and 3rd party namespaced security admission EXISTS\n# returns webhook configuration for user to review\ndeny[msga] {\n\tsome namespace in input\n\tnamespace.kind == \"Namespace\"\n\tnot baseline_admission_policy_enabled(namespace)\n\n    admissionwebhook := input[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Review webhook: %v ensure that it defines the required policy\", [admissionwebhook.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [admissionwebhook]\n\t\t}\n\t}\n}\n\n\nbaseline_admission_policy_enabled(namespace){\n\tsome key, value in namespace.metadata.labels \n    key == \"pod-security.kubernetes.io/enforce\"\n\tvalue in [\"baseline\", \"restricted\"]\n}\n\nhas_external_policy_control(inp){\n    some admissionwebhook in inp\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Namespace"
              ]
            },
            {
              "apiGroups": [
                "admissionregistration.k8s.io"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "ValidatingWebhookConfiguration",
                "MutatingWebhookConfiguration"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Checks that every namespace enabled baseline pod security admission, or if there are external policies applied for namespaced resources (validating/mutating webhooks) - returns them to be reviewed",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 5
    },
    {
      "guid": "",
      "name": "Minimize the admission of containers with allowPrivilegeEscalation",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.2.6",
      "controlID": "CIS-5.2.6",
      "creationTime": "",
      "description": "Do not generally permit containers to be run with the `allowPrivilegeEscalation` flag set to true. Allowing this right can lead to a process running a container getting more rights than it started with.\n\n It's important to note that these rights are still constrained by the overall container sandbox, and this setting does not relate to the use of privileged containers.",
      "remediation": "Add policies to each namespace in the cluster which has user workloads to restrict the admission of conatiners with `.spec.allowPrivilegeEscalation`set to `true`.",
      "rules": [
        {
          "guid": "",
          "name": "pod-security-admission-restricted-applied",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\nimport future.keywords.every\n\n# Fails if namespace does not have relevant labels and no 3rd party security admission exists\ndeny[msga] {\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\tnot restricted_admission_policy_enabled(namespace)\n    not has_external_policy_control(input)\n\tfix_path = {\"path\": \"metadata.labels[pod-security.kubernetes.io/enforce]\", \"value\": \"restricted\"}\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable restricted pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [fix_path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\n# Fails if at least 1 namespace does not have relevant labels and 3rd party security admission EXISTS\n# returns webhook configuration for user to review\ndeny[msga] {\n\tsome namespace in input\n\tnamespace.kind == \"Namespace\"\n\tnot restricted_admission_policy_enabled(namespace)\n\n    admissionwebhook := input[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Review webhook: %v ensure that it defines the required policy\", [admissionwebhook.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [admissionwebhook]\n\t\t}\n\t}\n}\n\nrestricted_admission_policy_enabled(namespace){\n\tsome key, value in namespace.metadata.labels \n    key == \"pod-security.kubernetes.io/enforce\"\n\tvalue ==  \"restricted\"\n}\n\nhas_external_policy_control(inp){\n    some admissionwebhook in inp\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "resourceEnumerator": "package armo_builtins\nimport future.keywords.every\n\n# if no 3rd party security admission exists - Fails if namespace does not have relevant labels \ndeny[msga] {\n    not has_external_policy_control(input)\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable restricted pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\n# Fails if at least 1 namespace does not have relevant labels and 3rd party security admission EXISTS\n# returns webhook configuration for user to review\ndeny[msga] {\n\tsome namespace in input\n\tnamespace.kind == \"Namespace\"\n\tnot restricted_admission_policy_enabled(namespace)\n\n    admissionwebhook := input[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Review webhook: %v ensure that it defines the required policy\", [admissionwebhook.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [admissionwebhook]\n\t\t}\n\t}\n}\n\nrestricted_admission_policy_enabled(namespace){\n\tsome key, value in namespace.metadata.labels \n    key == \"pod-security.kubernetes.io/enforce\"\n\tvalue ==  \"restricted\"\n}\n\nhas_external_policy_control(inp){\n    some admissionwebhook in inp\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Namespace"
              ]
            },
            {
              "apiGroups": [
                "admissionregistration.k8s.io"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "ValidatingWebhookConfiguration",
                "MutatingWebhookConfiguration"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Checks that every namespace enabled restricted pod security admission, or if there are external policies applied for namespaced resources (validating/mutating webhooks) - returns them to be reviewed",
          "remediation": "Ensure that either Pod Security Admission or an external policy control system is in place for every namespace which contains user workloads.\n\n#### Impact Statement\nWhere policy control systems are in place, there is a risk that workloads required for the operation of the cluster may be stopped from running. Care is required when implementing admission control policies to ensure that this does not occur.\n\n#### Default Value\nBy default, Pod Security Admission is enabled but no policies are in place.",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Minimize the admission of root containers",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.2.7",
      "controlID": "CIS-5.2.7",
      "creationTime": "",
      "description": "Do not generally permit containers to be run as the root user.",
      "remediation": "Create a policy for each namespace in the cluster, ensuring that either `MustRunAsNonRoot` or `MustRunAs` with the range of UIDs not including 0, is set.",
      "rules": [
        {
          "guid": "",
          "name": "pod-security-admission-restricted-applied",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\nimport future.keywords.every\n\n# Fails if namespace does not have relevant labels and no 3rd party security admission exists\ndeny[msga] {\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\tnot restricted_admission_policy_enabled(namespace)\n    not has_external_policy_control(input)\n\tfix_path = {\"path\": \"metadata.labels[pod-security.kubernetes.io/enforce]\", \"value\": \"restricted\"}\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable restricted pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [fix_path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\n# Fails if at least 1 namespace does not have relevant labels and 3rd party security admission EXISTS\n# returns webhook configuration for user to review\ndeny[msga] {\n\tsome namespace in input\n\tnamespace.kind == \"Namespace\"\n\tnot restricted_admission_policy_enabled(namespace)\n\n    admissionwebhook := input[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Review webhook: %v ensure that it defines the required policy\", [admissionwebhook.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [admissionwebhook]\n\t\t}\n\t}\n}\n\nrestricted_admission_policy_enabled(namespace){\n\tsome key, value in namespace.metadata.labels \n    key == \"pod-security.kubernetes.io/enforce\"\n\tvalue ==  \"restricted\"\n}\n\nhas_external_policy_control(inp){\n    some admissionwebhook in inp\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "resourceEnumerator": "package armo_builtins\nimport future.keywords.every\n\n# if no 3rd party security admission exists - Fails if namespace does not have relevant labels \ndeny[msga] {\n    not has_external_policy_control(input)\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable restricted pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\n# Fails if at least 1 namespace does not have relevant labels and 3rd party security admission EXISTS\n# returns webhook configuration for user to review\ndeny[msga] {\n\tsome namespace in input\n\tnamespace.kind == \"Namespace\"\n\tnot restricted_admission_policy_enabled(namespace)\n\n    admissionwebhook := input[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Review webhook: %v ensure that it defines the required policy\", [admissionwebhook.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [admissionwebhook]\n\t\t}\n\t}\n}\n\nrestricted_admission_policy_enabled(namespace){\n\tsome key, value in namespace.metadata.labels \n    key == \"pod-security.kubernetes.io/enforce\"\n\tvalue ==  \"restricted\"\n}\n\nhas_external_policy_control(inp){\n    some admissionwebhook in inp\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Namespace"
              ]
            },
            {
              "apiGroups": [
                "admissionregistration.k8s.io"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "ValidatingWebhookConfiguration",
                "MutatingWebhookConfiguration"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Checks that every namespace enabled restricted pod security admission, or if there are external policies applied for namespaced resources (validating/mutating webhooks) - returns them to be reviewed",
          "remediation": "Ensure that either Pod Security Admission or an external policy control system is in place for every namespace which contains user workloads.\n\n#### Impact Statement\nWhere policy control systems are in place, there is a risk that workloads required for the operation of the cluster may be stopped from running. Care is required when implementing admission control policies to ensure that this does not occur.\n\n#### Default Value\nBy default, Pod Security Admission is enabled but no policies are in place.",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Minimize the admission of containers with the NET_RAW capability",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.2.8",
      "controlID": "CIS-5.2.8",
      "creationTime": "",
      "description": "Do not generally permit containers with the potentially dangerous NET\\_RAW capability.",
      "remediation": "Add policies to each namespace in the cluster which has user workloads to restrict the admission of containers with the `NET_RAW` capability.",
      "rules": [
        {
          "guid": "",
          "name": "pod-security-admission-baseline-applied",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\nimport future.keywords.in\n\n# Fails if namespace does not have relevant labels and no 3rd party security admission exists\ndeny[msga] {\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\tnot baseline_admission_policy_enabled(namespace)\n    not has_external_policy_control(input)\n\tfix_path = {\"path\": \"metadata.labels[pod-security.kubernetes.io/enforce]\", \"value\": \"baseline\"}\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable baseline pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [fix_path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\n# Fails if at least 1 namespace does not have relevant labels and 3rd party namespaced security admission EXISTS\n# returns webhook configuration for user to review\ndeny[msga] {\n\tsome namespace in input\n\tnamespace.kind == \"Namespace\"\n\tnot baseline_admission_policy_enabled(namespace)\n\n    admissionwebhook := input[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Review webhook: %v ensure that it defines the required policy\", [admissionwebhook.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [admissionwebhook]\n\t\t}\n\t}\n}\n\n\nbaseline_admission_policy_enabled(namespace){\n\tsome key, value in namespace.metadata.labels \n    key == \"pod-security.kubernetes.io/enforce\"\n\tvalue in [\"baseline\", \"restricted\"]\n}\n\nhas_external_policy_control(inp){\n    some admissionwebhook in inp\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "resourceEnumerator": "package armo_builtins\nimport future.keywords.in\n\n# if no 3rd party security admission exists - Fails if namespace does not have relevant labels\ndeny[msga] {\n    not has_external_policy_control(input)\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable baseline pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\n# Fails if at least 1 namespace does not have relevant labels and 3rd party namespaced security admission EXISTS\n# returns webhook configuration for user to review\ndeny[msga] {\n\tsome namespace in input\n\tnamespace.kind == \"Namespace\"\n\tnot baseline_admission_policy_enabled(namespace)\n\n    admissionwebhook := input[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Review webhook: %v ensure that it defines the required policy\", [admissionwebhook.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [admissionwebhook]\n\t\t}\n\t}\n}\n\n\nbaseline_admission_policy_enabled(namespace){\n\tsome key, value in namespace.metadata.labels \n    key == \"pod-security.kubernetes.io/enforce\"\n\tvalue in [\"baseline\", \"restricted\"]\n}\n\nhas_external_policy_control(inp){\n    some admissionwebhook in inp\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Namespace"
              ]
            },
            {
              "apiGroups": [
                "admissionregistration.k8s.io"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "ValidatingWebhookConfiguration",
                "MutatingWebhookConfiguration"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Checks that every namespace enabled baseline pod security admission, or if there are external policies applied for namespaced resources (validating/mutating webhooks) - returns them to be reviewed",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Minimize the admission of containers with added capabilities",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.2.9",
      "controlID": "CIS-5.2.9",
      "creationTime": "",
      "description": "Do not generally permit containers with capabilities assigned beyond the default set.",
      "remediation": "Ensure that `allowedCapabilities` is not present in policies for the cluster unless it is set to an empty array.",
      "rules": [
        {
          "guid": "",
          "name": "pod-security-admission-restricted-applied",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\nimport future.keywords.every\n\n# Fails if namespace does not have relevant labels and no 3rd party security admission exists\ndeny[msga] {\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\tnot restricted_admission_policy_enabled(namespace)\n    not has_external_policy_control(input)\n\tfix_path = {\"path\": \"metadata.labels[pod-security.kubernetes.io/enforce]\", \"value\": \"restricted\"}\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable restricted pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [fix_path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\n# Fails if at least 1 namespace does not have relevant labels and 3rd party security admission EXISTS\n# returns webhook configuration for user to review\ndeny[msga] {\n\tsome namespace in input\n\tnamespace.kind == \"Namespace\"\n\tnot restricted_admission_policy_enabled(namespace)\n\n    admissionwebhook := input[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Review webhook: %v ensure that it defines the required policy\", [admissionwebhook.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [admissionwebhook]\n\t\t}\n\t}\n}\n\nrestricted_admission_policy_enabled(namespace){\n\tsome key, value in namespace.metadata.labels \n    key == \"pod-security.kubernetes.io/enforce\"\n\tvalue ==  \"restricted\"\n}\n\nhas_external_policy_control(inp){\n    some admissionwebhook in inp\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "resourceEnumerator": "package armo_builtins\nimport future.keywords.every\n\n# if no 3rd party security admission exists - Fails if namespace does not have relevant labels \ndeny[msga] {\n    not has_external_policy_control(input)\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable restricted pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\n# Fails if at least 1 namespace does not have relevant labels and 3rd party security admission EXISTS\n# returns webhook configuration for user to review\ndeny[msga] {\n\tsome namespace in input\n\tnamespace.kind == \"Namespace\"\n\tnot restricted_admission_policy_enabled(namespace)\n\n    admissionwebhook := input[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Review webhook: %v ensure that it defines the required policy\", [admissionwebhook.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [admissionwebhook]\n\t\t}\n\t}\n}\n\nrestricted_admission_policy_enabled(namespace){\n\tsome key, value in namespace.metadata.labels \n    key == \"pod-security.kubernetes.io/enforce\"\n\tvalue ==  \"restricted\"\n}\n\nhas_external_policy_control(inp){\n    some admissionwebhook in inp\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Namespace"
              ]
            },
            {
              "apiGroups": [
                "admissionregistration.k8s.io"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "ValidatingWebhookConfiguration",
                "MutatingWebhookConfiguration"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Checks that every namespace enabled restricted pod security admission, or if there are external policies applied for namespaced resources (validating/mutating webhooks) - returns them to be reviewed",
          "remediation": "Ensure that either Pod Security Admission or an external policy control system is in place for every namespace which contains user workloads.\n\n#### Impact Statement\nWhere policy control systems are in place, there is a risk that workloads required for the operation of the cluster may be stopped from running. Care is required when implementing admission control policies to ensure that this does not occur.\n\n#### Default Value\nBy default, Pod Security Admission is enabled but no policies are in place.",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 5
    },
    {
      "guid": "",
      "name": "Minimize the admission of containers with capabilities assigned",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.2.10",
      "controlID": "CIS-5.2.10",
      "creationTime": "",
      "description": "Do not generally permit containers with capabilities",
      "remediation": "Review the use of capabilites in applications runnning on your cluster. Where a namespace contains applicaions which do not require any Linux capabities to operate consider adding a policy which forbids the admission of containers which do not drop all capabilities.",
      "rules": [
        {
          "guid": "",
          "name": "pod-security-admission-restricted-applied",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\nimport future.keywords.every\n\n# Fails if namespace does not have relevant labels and no 3rd party security admission exists\ndeny[msga] {\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\tnot restricted_admission_policy_enabled(namespace)\n    not has_external_policy_control(input)\n\tfix_path = {\"path\": \"metadata.labels[pod-security.kubernetes.io/enforce]\", \"value\": \"restricted\"}\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable restricted pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [fix_path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\n# Fails if at least 1 namespace does not have relevant labels and 3rd party security admission EXISTS\n# returns webhook configuration for user to review\ndeny[msga] {\n\tsome namespace in input\n\tnamespace.kind == \"Namespace\"\n\tnot restricted_admission_policy_enabled(namespace)\n\n    admissionwebhook := input[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Review webhook: %v ensure that it defines the required policy\", [admissionwebhook.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [admissionwebhook]\n\t\t}\n\t}\n}\n\nrestricted_admission_policy_enabled(namespace){\n\tsome key, value in namespace.metadata.labels \n    key == \"pod-security.kubernetes.io/enforce\"\n\tvalue ==  \"restricted\"\n}\n\nhas_external_policy_control(inp){\n    some admissionwebhook in inp\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "resourceEnumerator": "package armo_builtins\nimport future.keywords.every\n\n# if no 3rd party security admission exists - Fails if namespace does not have relevant labels \ndeny[msga] {\n    not has_external_policy_control(input)\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable restricted pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\n# Fails if at least 1 namespace does not have relevant labels and 3rd party security admission EXISTS\n# returns webhook configuration for user to review\ndeny[msga] {\n\tsome namespace in input\n\tnamespace.kind == \"Namespace\"\n\tnot restricted_admission_policy_enabled(namespace)\n\n    admissionwebhook := input[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Review webhook: %v ensure that it defines the required policy\", [admissionwebhook.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [admissionwebhook]\n\t\t}\n\t}\n}\n\nrestricted_admission_policy_enabled(namespace){\n\tsome key, value in namespace.metadata.labels \n    key == \"pod-security.kubernetes.io/enforce\"\n\tvalue ==  \"restricted\"\n}\n\nhas_external_policy_control(inp){\n    some admissionwebhook in inp\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Namespace"
              ]
            },
            {
              "apiGroups": [
                "admissionregistration.k8s.io"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "ValidatingWebhookConfiguration",
                "MutatingWebhookConfiguration"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Checks that every namespace enabled restricted pod security admission, or if there are external policies applied for namespaced resources (validating/mutating webhooks) - returns them to be reviewed",
          "remediation": "Ensure that either Pod Security Admission or an external policy control system is in place for every namespace which contains user workloads.\n\n#### Impact Statement\nWhere policy control systems are in place, there is a risk that workloads required for the operation of the cluster may be stopped from running. Care is required when implementing admission control policies to ensure that this does not occur.\n\n#### Default Value\nBy default, Pod Security Admission is enabled but no policies are in place.",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 5
    },
    {
      "guid": "",
      "name": "Minimize the admission of Windows HostProcess Containers",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.2.11",
      "controlID": "CIS-5.2.11",
      "creationTime": "",
      "description": "Do not generally permit Windows containers to be run with the `hostProcess` flag set to true.",
      "remediation": "Add policies to each namespace in the cluster which has user workloads to restrict the admission of `hostProcess` containers.",
      "rules": [
        {
          "guid": "",
          "name": "pod-security-admission-baseline-applied",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\nimport future.keywords.in\n\n# Fails if namespace does not have relevant labels and no 3rd party security admission exists\ndeny[msga] {\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\tnot baseline_admission_policy_enabled(namespace)\n    not has_external_policy_control(input)\n\tfix_path = {\"path\": \"metadata.labels[pod-security.kubernetes.io/enforce]\", \"value\": \"baseline\"}\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable baseline pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [fix_path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\n# Fails if at least 1 namespace does not have relevant labels and 3rd party namespaced security admission EXISTS\n# returns webhook configuration for user to review\ndeny[msga] {\n\tsome namespace in input\n\tnamespace.kind == \"Namespace\"\n\tnot baseline_admission_policy_enabled(namespace)\n\n    admissionwebhook := input[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Review webhook: %v ensure that it defines the required policy\", [admissionwebhook.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [admissionwebhook]\n\t\t}\n\t}\n}\n\n\nbaseline_admission_policy_enabled(namespace){\n\tsome key, value in namespace.metadata.labels \n    key == \"pod-security.kubernetes.io/enforce\"\n\tvalue in [\"baseline\", \"restricted\"]\n}\n\nhas_external_policy_control(inp){\n    some admissionwebhook in inp\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "resourceEnumerator": "package armo_builtins\nimport future.keywords.in\n\n# if no 3rd party security admission exists - Fails if namespace does not have relevant labels\ndeny[msga] {\n    not has_external_policy_control(input)\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable baseline pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\n# Fails if at least 1 namespace does not have relevant labels and 3rd party namespaced security admission EXISTS\n# returns webhook configuration for user to review\ndeny[msga] {\n\tsome namespace in input\n\tnamespace.kind == \"Namespace\"\n\tnot baseline_admission_policy_enabled(namespace)\n\n    admissionwebhook := input[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Review webhook: %v ensure that it defines the required policy\", [admissionwebhook.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [admissionwebhook]\n\t\t}\n\t}\n}\n\n\nbaseline_admission_policy_enabled(namespace){\n\tsome key, value in namespace.metadata.labels \n    key == \"pod-security.kubernetes.io/enforce\"\n\tvalue in [\"baseline\", \"restricted\"]\n}\n\nhas_external_policy_control(inp){\n    some admissionwebhook in inp\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Namespace"
              ]
            },
            {
              "apiGroups": [
                "admissionregistration.k8s.io"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "ValidatingWebhookConfiguration",
                "MutatingWebhookConfiguration"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Checks that every namespace enabled baseline pod security admission, or if there are external policies applied for namespaced resources (validating/mutating webhooks) - returns them to be reviewed",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 7
    },
    {
      "guid": "",
      "name": "Minimize the admission of HostPath volumes",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.2.12",
      "controlID": "CIS-5.2.12",
      "creationTime": "",
      "description": "Do not generally admit containers which make use of `hostPath` volumes.",
      "remediation": "Add policies to each namespace in the cluster which has user workloads to restrict the admission of containers which use `hostPath` volumes.",
      "rules": [
        {
          "guid": "",
          "name": "pod-security-admission-baseline-applied",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\nimport future.keywords.in\n\n# Fails if namespace does not have relevant labels and no 3rd party security admission exists\ndeny[msga] {\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\tnot baseline_admission_policy_enabled(namespace)\n    not has_external_policy_control(input)\n\tfix_path = {\"path\": \"metadata.labels[pod-security.kubernetes.io/enforce]\", \"value\": \"baseline\"}\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable baseline pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [fix_path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\n# Fails if at least 1 namespace does not have relevant labels and 3rd party namespaced security admission EXISTS\n# returns webhook configuration for user to review\ndeny[msga] {\n\tsome namespace in input\n\tnamespace.kind == \"Namespace\"\n\tnot baseline_admission_policy_enabled(namespace)\n\n    admissionwebhook := input[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Review webhook: %v ensure that it defines the required policy\", [admissionwebhook.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [admissionwebhook]\n\t\t}\n\t}\n}\n\n\nbaseline_admission_policy_enabled(namespace){\n\tsome key, value in namespace.metadata.labels \n    key == \"pod-security.kubernetes.io/enforce\"\n\tvalue in [\"baseline\", \"restricted\"]\n}\n\nhas_external_policy_control(inp){\n    some admissionwebhook in inp\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "resourceEnumerator": "package armo_builtins\nimport future.keywords.in\n\n# if no 3rd party security admission exists - Fails if namespace does not have relevant labels\ndeny[msga] {\n    not has_external_policy_control(input)\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable baseline pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\n# Fails if at least 1 namespace does not have relevant labels and 3rd party namespaced security admission EXISTS\n# returns webhook configuration for user to review\ndeny[msga] {\n\tsome namespace in input\n\tnamespace.kind == \"Namespace\"\n\tnot baseline_admission_policy_enabled(namespace)\n\n    admissionwebhook := input[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Review webhook: %v ensure that it defines the required policy\", [admissionwebhook.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [admissionwebhook]\n\t\t}\n\t}\n}\n\n\nbaseline_admission_policy_enabled(namespace){\n\tsome key, value in namespace.metadata.labels \n    key == \"pod-security.kubernetes.io/enforce\"\n\tvalue in [\"baseline\", \"restricted\"]\n}\n\nhas_external_policy_control(inp){\n    some admissionwebhook in inp\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Namespace"
              ]
            },
            {
              "apiGroups": [
                "admissionregistration.k8s.io"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "ValidatingWebhookConfiguration",
                "MutatingWebhookConfiguration"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Checks that every namespace enabled baseline pod security admission, or if there are external policies applied for namespaced resources (validating/mutating webhooks) - returns them to be reviewed",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Minimize the admission of containers which use HostPorts",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.2.13",
      "controlID": "CIS-5.2.13",
      "creationTime": "",
      "description": "Do not generally permit containers which require the use of HostPorts.",
      "remediation": "Add policies to each namespace in the cluster which has user workloads to restrict the admission of containers which use `hostPort` sections.",
      "rules": [
        {
          "guid": "",
          "name": "pod-security-admission-baseline-applied",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\nimport future.keywords.in\n\n# Fails if namespace does not have relevant labels and no 3rd party security admission exists\ndeny[msga] {\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\tnot baseline_admission_policy_enabled(namespace)\n    not has_external_policy_control(input)\n\tfix_path = {\"path\": \"metadata.labels[pod-security.kubernetes.io/enforce]\", \"value\": \"baseline\"}\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable baseline pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [fix_path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\n# Fails if at least 1 namespace does not have relevant labels and 3rd party namespaced security admission EXISTS\n# returns webhook configuration for user to review\ndeny[msga] {\n\tsome namespace in input\n\tnamespace.kind == \"Namespace\"\n\tnot baseline_admission_policy_enabled(namespace)\n\n    admissionwebhook := input[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Review webhook: %v ensure that it defines the required policy\", [admissionwebhook.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [admissionwebhook]\n\t\t}\n\t}\n}\n\n\nbaseline_admission_policy_enabled(namespace){\n\tsome key, value in namespace.metadata.labels \n    key == \"pod-security.kubernetes.io/enforce\"\n\tvalue in [\"baseline\", \"restricted\"]\n}\n\nhas_external_policy_control(inp){\n    some admissionwebhook in inp\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "resourceEnumerator": "package armo_builtins\nimport future.keywords.in\n\n# if no 3rd party security admission exists - Fails if namespace does not have relevant labels\ndeny[msga] {\n    not has_external_policy_control(input)\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable baseline pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\n# Fails if at least 1 namespace does not have relevant labels and 3rd party namespaced security admission EXISTS\n# returns webhook configuration for user to review\ndeny[msga] {\n\tsome namespace in input\n\tnamespace.kind == \"Namespace\"\n\tnot baseline_admission_policy_enabled(namespace)\n\n    admissionwebhook := input[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Review webhook: %v ensure that it defines the required policy\", [admissionwebhook.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [admissionwebhook]\n\t\t}\n\t}\n}\n\n\nbaseline_admission_policy_enabled(namespace){\n\tsome key, value in namespace.metadata.labels \n    key == \"pod-security.kubernetes.io/enforce\"\n\tvalue in [\"baseline\", \"restricted\"]\n}\n\nhas_external_policy_control(inp){\n    some admissionwebhook in inp\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Namespace"
              ]
            },
            {
              "apiGroups": [
                "admissionregistration.k8s.io"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "ValidatingWebhookConfiguration",
                "MutatingWebhookConfiguration"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Checks that every namespace enabled baseline pod security admission, or if there are external policies applied for namespaced resources (validating/mutating webhooks) - returns them to be reviewed",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 4
    },
    {
      "guid": "",
      "name": "Ensure that all Namespaces have Network Policies defined",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.3.2",
      "controlID": "CIS-5.3.2",
      "creationTime": "",
      "description": "Use network policies to isolate traffic in your cluster network.",
      "remediation": "Follow the documentation and create `NetworkPolicy` objects as you need them.",
      "rules": [
        {
          "guid": "",
          "name": "internal-networking",
          "attributes": {
            "armoBuiltin": true,
            "m$K8sThreatMatrix": "Lateral Movement::Container internal networking, Discovery::Network mapping"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\n# input: network policies\n# apiversion: networking.k8s.io/v1\n# fails if no network policies are defined in a certain namespace\n\ndeny[msga] {\n\tnamespaces := [namespace | namespace = input[_]; namespace.kind == \"Namespace\"]\n\tnamespace := namespaces[_]\n\tpolicy_names := [policy.metadata.namespace | policy = input[_]; policy.kind == \"NetworkPolicy\"]\n\tnot list_contains(policy_names, namespace.metadata.name)\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"no policy is defined for namespace %v\", [namespace.metadata.name]),\n\t\t\"alertScore\": 9,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\nlist_contains(list, element) {\n  some i\n  list[i] == element\n}",
          "resourceEnumerator": "package armo_builtins\n\n# input: network policies + namespaces\n# apiversion: networking.k8s.io/v1\n# returns all namespaces\n\ndeny[msga] {\n\tnamespaces := [namespace | namespace = input[_]; namespace.kind == \"Namespace\"]\n\tnamespace := namespaces[_]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"no policy is defined for namespace %v\", [namespace.metadata.name]),\n\t\t\"alertScore\": 9,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"failedPaths\": [\"\"],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Namespace"
              ]
            },
            {
              "apiGroups": [
                "networking.k8s.io"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "NetworkPolicy"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "lists namespaces in which no network policies are defined",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 4
    },
    {
      "guid": "",
      "name": "Prefer using secrets as files over secrets as environment variables",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.4.1",
      "controlID": "CIS-5.4.1",
      "creationTime": "",
      "description": "Kubernetes supports mounting secrets as data volumes or as environment variables. Minimize the use of environment variable secrets.",
      "remediation": "If possible, rewrite application code to read secrets from mounted secret files, rather than from environment variables.",
      "rules": [
        {
          "guid": "",
          "name": "rule-secrets-in-env-var",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\nimport data\n\ndeny[msga] {\n\tpod := input[_]\n\tpod.kind == \"Pod\"\n\n\tcontainer := pod.spec.containers[i]\n\tenv := container.env[j]\n\tenv.valueFrom.secretKeyRef\n\n\tpath := sprintf(\"spec.containers[%v].env[%v].name\", [format_int(i, 10), format_int(j, 10)])\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Pod: %v has secrets in environment variables\", [pod.metadata.name]),\n\t\t\"alertScore\": 9,\n\t\t\"fixPaths\": [],\n\t\t\"failedPaths\": [path],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}\n\ndeny[msga] {\n\twl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n\tcontainer := wl.spec.template.spec.containers[i]\n\tenv := container.env[j]\n\tenv.valueFrom.secretKeyRef\n\n\tpath := sprintf(\"spec.template.spec.containers[%v].env[%v].name\", [format_int(i, 10), format_int(j, 10)])\t\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v has secrets in environment variables\", [wl.kind, wl.metadata.name]),\n\t\t\"alertScore\": 9,\n\t\t\"fixPaths\": [],\n\t\t\"failedPaths\": [path],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n\tcontainer := wl.spec.jobTemplate.spec.template.spec.containers[i]\n\tenv := container.env[j]\n\tenv.valueFrom.secretKeyRef\n\t\n\tpath := sprintf(\"spec.jobTemplate.spec.template.spec.containers[%v].env[%v].name\", [format_int(i, 10), format_int(j, 10)])\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Cronjob: %v has secrets in environment variables\", [wl.metadata.name]),\n\t\t\"alertScore\": 9,\n\t\t\"fixPaths\": [],\n\t\t\"failedPaths\": [path],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Deployment",
                "ReplicaSet",
                "DaemonSet",
                "StatefulSet"
              ]
            },
            {
              "apiGroups": [
                "batch"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Job",
                "CronJob"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "fails if Pods have secrets in environment variables",
          "remediation": "If possible, rewrite application code to read secrets from mounted secret files, rather than from environment variables.",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 4
    },
    {
      "guid": "",
      "name": "Consider external secret storage",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.4.2",
      "controlID": "CIS-5.4.2",
      "creationTime": "",
      "description": "Consider the use of an external secrets storage and management system, instead of using Kubernetes Secrets directly, if you have more complex secret management needs. Ensure the solution requires authentication to access secrets, has auditing of access to and use of secrets, and encrypts secrets. Some solutions also make it easier to rotate secrets.",
      "remediation": "Refer to the secrets management options offered by your cloud provider or a third-party secrets management solution.",
      "rules": [
        {
          "guid": "",
          "name": "external-secret-storage",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.every\n\n# Encryption config is not using a recommended provider for KMS\ndeny[msg] {\n\tobj = input[_]\n\tis_control_plane_info(obj)\n\tconfig_file := obj.data.APIServerInfo.encryptionProviderConfigFile\n\tconfig_file_content = decode_config_file(base64.decode(config_file.content))\n\n\tresources := config_file_content.resources\n\tevery resource in resources{\n\t\tnot has_recommended_provider(resource)\n\t}\n\n\tfix_paths := [\n\t{\"path\": sprintf(\"resources[%d].resources[%d]\", [count(resources), 0]),\t\"value\": \"secrets\"},\n\t{\"path\": sprintf(\"resources[%d].providers[%d].kms\", [count(resources), 0]),\t\"value\": \"YOUR_EXTERNAL_KMS\"},\n\t]\n\n\t# Add name to the failed object so that\n\t# it fit the format of the alert object\n\tfailed_obj := json.patch(config_file_content, [{\n\t\t\"op\": \"add\",\n\t\t\"path\": \"name\",\n\t\t\"value\": \"encryption-provider-config\",\n\t}])\n\n\tmsg := {\n\t\t\"alertMessage\": \"Encryption provider config is not using a recommended provider for KMS\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": failed_obj},\n\t}\n}\n\nis_control_plane_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n\ndecode_config_file(content) := data {\n\tdata := yaml.unmarshal(content)\n} else := json.unmarshal(content)\n\nhas_recommended_provider(resource) {\n\trecommended_providers := {\"akeyless\", \"azurekmsprovider\", \"aws-encryption-provider\"}\n\tsome provider in resource.providers\n\trecommended_providers[provider.kms.name]\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "ControlPlaneInfo"
              ]
            }
          ],
          "ruleDependencies": null,
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Consider the use of an external secrets storage and management system, instead of using Kubernetes Secrets directly, if you have more complex secret management needs. Ensure the solution requires authentication to access secrets, has auditing of access to and use of secrets, and encrypts secrets. Some solutions also make it easier to rotate secrets.",
          "remediation": "Refer to the secrets management options offered by your cloud provider or a third-party secrets management solution.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 5
    },
    {
      "guid": "",
      "name": "Create administrative boundaries between resources using namespaces",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.7.1",
      "controlID": "CIS-5.7.1",
      "creationTime": "",
      "description": "Use namespaces to isolate your Kubernetes objects.",
      "remediation": "Follow the documentation and create namespaces for objects in your deployment as you need them.",
      "rules": [
        {
          "guid": "",
          "name": "list-all-namespaces",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\n# returns all namespace objects in cluster\ndeny[msga] {\n\tnamespace = input[_]\n\tnamespace.kind == \"Namespace\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"review the following namespace: %v\", [namespace.metadata.name]),\n\t\t\"alertScore\": 9,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Namespace"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "lists all namespaces for users to review",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 5
    },
    {
      "guid": "",
      "name": "Ensure that the seccomp profile is set to docker/default in your pod definitions",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.7.2",
      "controlID": "CIS-5.7.2",
      "creationTime": "",
      "description": "Enable `docker/default` seccomp profile in your pod definitions.",
      "remediation": "Use security context to enable the `docker/default` seccomp profile in your pod definitions. An example is as below:\n\n \n```\n  securityContext:\n    seccompProfile:\n      type: RuntimeDefault\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "set-seccomp-profile-RuntimeDefault",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\n# Fails if pod does not define seccompProfile as RuntimeDefault\ndeny[msga] {\n    wl := input[_]\n    wl.kind == \"Pod\"\n    wl_spec := wl.spec\n\tpath_to_containers := [\"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n\t\n\tpath_to_search := [\"securityContext\", \"seccompProfile\", \"type\"]\n\n\tseccompProfile_result := get_seccompProfile_definition(wl_spec, container, i, path_to_containers, path_to_search)\n\tseccompProfile_result.failed == true\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Pod: %v does not define seccompProfile as RuntimeDefault\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": seccompProfile_result.failed_path,\n\t\t\"fixPaths\": seccompProfile_result.fix_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n# Fails if workload does not define seccompProfile as RuntimeDefault\ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n    wl_spec := wl.spec.template.spec\n\tpath_to_containers := [\"spec\", \"template\", \"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n\t\n\tpath_to_search := [\"securityContext\", \"seccompProfile\", \"type\"]\n\n\tseccompProfile_result := get_seccompProfile_definition(wl_spec, container, i, path_to_containers, path_to_search)\n\tseccompProfile_result.failed == true\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Workload: %v does not define seccompProfile as RuntimeDefault\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": seccompProfile_result.failed_path,\n\t\t\"fixPaths\": seccompProfile_result.fix_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n\n# Fails if CronJob does not define seccompProfile as RuntimeDefault\ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n    wl_spec := wl.spec.jobTemplate.spec.template.spec\n\tpath_to_containers := [\"spec\", \"jobTemplate\", \"spec\", \"template\", \"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n\t\n\tpath_to_search := [\"securityContext\", \"seccompProfile\", \"type\"]\n\n\tseccompProfile_result := get_seccompProfile_definition(wl_spec, container, i, path_to_containers, path_to_search)\n\tseccompProfile_result.failed == true\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Cronjob: %v does not define seccompProfile as RuntimeDefault\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": seccompProfile_result.failed_path,\n\t\t\"fixPaths\": seccompProfile_result.fix_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n\n# container definition takes precedence\nget_seccompProfile_definition(wl, container, i, path_to_containers, path_to_search) = seccompProfile_result {\n\tcontainer.securityContext.seccompProfile.type == \"RuntimeDefault\"\n    seccompProfile_result := {\"failed\": false, \"failed_path\": [], \"fix_path\": []}\n\n} else = seccompProfile_result {\n\tcontainer.securityContext.seccompProfile.type != \"RuntimeDefault\"\n    failed_path := sprintf(\"%s[%d].%s\", [concat(\".\", path_to_containers), i, concat(\".\", path_to_search)])\n    seccompProfile_result := {\"failed\": true, \"failed_path\": [failed_path], \"fix_path\": []}\n\n} else = seccompProfile_result {\n\twl.securityContext.seccompProfile.type == \"RuntimeDefault\" \n    seccompProfile_result := {\"failed\": false,  \"failed_path\": [], \"fix_path\": []}\n\n} else = seccompProfile_result {\n\twl.securityContext.seccompProfile.type != \"RuntimeDefault\" \n\tfailed_path := sprintf(\"%s.%s\", [trim_suffix(concat(\".\", path_to_containers), \".containers\"), concat(\".\", path_to_search)])\n    seccompProfile_result := {\"failed\": true,  \"failed_path\": [failed_path], \"fix_path\": []}\n\n} else = seccompProfile_result{\n\tfix_path := [{\"path\": sprintf(\"%s[%d].%s\", [concat(\".\", path_to_containers), i, concat(\".\", path_to_search)]), \"value\":\"RuntimeDefault\"}]\n\tseccompProfile_result := {\"failed\": true, \"failed_path\": [], \"fix_path\": fix_path}\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Deployment",
                "ReplicaSet",
                "DaemonSet",
                "StatefulSet"
              ]
            },
            {
              "apiGroups": [
                "batch"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Job",
                "CronJob"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "fails if container does not define seccompProfile as RuntimeDefault",
          "remediation": "Make sure you define seccompProfile as RuntimeDefault at workload or container lever.",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 4
    },
    {
      "guid": "",
      "name": "Apply Security Context to Your Pods and Containers",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.7.3",
      "controlID": "CIS-5.7.3",
      "creationTime": "",
      "description": "Apply Security Context to Your Pods and Containers",
      "remediation": "Follow the Kubernetes documentation and apply security contexts to your pods. For a suggested list of security contexts, you may refer to the CIS Security Benchmark for Docker Containers.",
      "rules": [
        {
          "guid": "",
          "name": "rule-privilege-escalation",
          "attributes": {
            "armoBuiltin": true,
            "m$K8sThreatMatrix": "Privilege Escalation::privileged container",
            "mitre": "Privilege Escalation",
            "mitreCode": "TA0004"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n# Deny mutating action unless user is in group owning the resource\n\n\n#privileged pods\ndeny[msga] {\n\n\tpod := input[_]\n\tpod.kind == \"Pod\"\n\tcontainer := pod.spec.containers[i]\n\tbeggining_of_path := \"spec.\"\n\tpath := isPrivilegedContainer(container, i, beggining_of_path)\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"the following pods are defined as privileged: %v\", [pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"fixPaths\": [],\n\t\t\"failedPaths\": path,\n         \"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n     }\n}\n\n\n#handles majority of workload resources\ndeny[msga] {\n\twl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n\tcontainer := wl.spec.template.spec.containers[i]\n\tbeggining_of_path := \"spec.template.spec.\"\n\tpath := isPrivilegedContainer(container, i, beggining_of_path)\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v is defined as privileged:\", [wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"fixPaths\": [],\n\t\t\"failedPaths\": path,\n         \"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n     }\n}\n\n#handles cronjob\ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n\tcontainer := wl.spec.jobTemplate.spec.template.spec.containers[i]\n\tbeggining_of_path := \"spec.jobTemplate.spec.template.spec.\"\n\tpath := isPrivilegedContainer(container, i, beggining_of_path)\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"the following cronjobs are defined as privileged: %v\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"fixPaths\": [],\n\t\t\"failedPaths\": path,\n         \"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n     }\n}\n\n\n# Only SYS_ADMIN capabilite\nisPrivilegedContainer(container, i, beggining_of_path) = path {\n\tnot container.securityContext.privileged == true\n\tpath = [sprintf(\"%vcontainers[%v].securityContext.capabilities.add[%v]\", [beggining_of_path, format_int(i, 10), format_int(k, 10)]) | capabilite = container.securityContext.capabilities.add[k]; capabilite == \"SYS_ADMIN\"]\n\tcount(path) \u003e 0\n}\n\n# Only securityContext.privileged == true\nisPrivilegedContainer(container, i, beggining_of_path) = path {\n\tcontainer.securityContext.privileged == true\n\tpath1 = [sprintf(\"%vcontainers[%v].securityContext.capabilities.add[%v]\", [beggining_of_path, format_int(i, 10), format_int(k, 10)]) | capabilite = container.securityContext.capabilities.add[k]; capabilite == \"SYS_ADMIN\"]\n\tcount(path1) \u003c 1\n\tpath = [sprintf(\"%vcontainers[%v].securityContext.privileged\", [beggining_of_path, format_int(i, 10)])]\n}\n\n# SYS_ADMIN capabilite \u0026\u0026 securityContext.privileged == true\nisPrivilegedContainer(container, i, beggining_of_path) = path {\n\tpath1 = [sprintf(\"%vcontainers[%v].securityContext.capabilities.add[%v]\", [beggining_of_path, format_int(i, 10), format_int(k, 10)]) | capabilite = container.securityContext.capabilities.add[k]; capabilite == \"SYS_ADMIN\"]\n\tcount(path1) \u003e 0\n\tcontainer.securityContext.privileged == true\n\tpath = array.concat(path1, [sprintf(\"%vcontainers[%v].securityContext.privileged\", [beggining_of_path, format_int(i, 10)])])\n}",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Deployment",
                "ReplicaSet",
                "DaemonSet",
                "StatefulSet"
              ]
            },
            {
              "apiGroups": [
                "batch"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Job",
                "CronJob"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "determines if pods/deployments defined as privileged true",
          "remediation": "avoid defining pods as privilleged",
          "ruleQuery": "",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "immutable-container-filesystem",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\n\n# Fails if pods has container with mutable filesystem\ndeny[msga] {\n    pod := input[_]\n    pod.kind == \"Pod\"\n\tcontainer := pod.spec.containers[i]\n\tbeggining_of_path := \"spec.\"\n    result := is_mutable_filesystem(container, beggining_of_path, i)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"container: %v in pod: %v  has  mutable filesystem\", [container.name, pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": failed_path,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}\n\n# Fails if workload has  container with mutable filesystem \ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n    container := wl.spec.template.spec.containers[i]\n\tbeggining_of_path := \"spec.template.spec.\"\n    result := is_mutable_filesystem(container, beggining_of_path, i)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"container :%v in %v: %v has  mutable filesystem\", [container.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": failed_path,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n\n# Fails if cronjob has  container with mutable filesystem \ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n\tcontainer = wl.spec.jobTemplate.spec.template.spec.containers[i]\n\tbeggining_of_path := \"spec.jobTemplate.spec.template.spec.\"\n\tresult := is_mutable_filesystem(container, beggining_of_path, i)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"container :%v in %v: %v has mutable filesystem\", [container.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": failed_path,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n# Default of readOnlyRootFilesystem is false. This field is only in container spec and not pod spec\nis_mutable_filesystem(container, beggining_of_path, i) = [failed_path, fixPath]  {\n\tcontainer.securityContext.readOnlyRootFilesystem == false\n\tfailed_path = sprintf(\"%vcontainers[%v].securityContext.readOnlyRootFilesystem\", [beggining_of_path, format_int(i, 10)])\n\tfixPath = \"\"\n }\n\n is_mutable_filesystem(container, beggining_of_path, i)  = [failed_path, fixPath] {\n\tnot container.securityContext.readOnlyRootFilesystem == false\n    not container.securityContext.readOnlyRootFilesystem == true\n\tfixPath = {\"path\": sprintf(\"%vcontainers[%v].securityContext.readOnlyRootFilesystem\", [beggining_of_path, format_int(i, 10)]), \"value\": \"true\"}\n\tfailed_path = \"\"\n }\n\n\n get_failed_path(paths) = [paths[0]] {\n\tpaths[0] != \"\"\n} else = []\n\n\nget_fixed_path(paths) = [paths[1]] {\n\tpaths[1] != \"\"\n} else = []\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Deployment",
                "ReplicaSet",
                "DaemonSet",
                "StatefulSet"
              ]
            },
            {
              "apiGroups": [
                "batch"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Job",
                "CronJob"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "fails if container has mutable filesystem",
          "remediation": "Make sure that the securityContext.readOnlyRootFilesystem field in the container/pod spec is set to true",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "non-root-containers",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\n\n################################################################################\n# Rules\ndeny[msga] {\n    pod := input[_]\n    pod.kind == \"Pod\"\n\tcontainer := pod.spec.containers[i]\n\n\tbeggining_of_path := \"spec\"\n\talertInfo := evaluate_workload_non_root_container(container, pod, beggining_of_path)\n\tfixPath := get_fixed_path(alertInfo, i)\n    failed_path := get_failed_path(alertInfo, i) \n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"container: %v in pod: %v  may run as root\", [container.name, pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": failed_path,\n        \"fixPaths\": fixPath,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}\n\n\ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n    container := wl.spec.template.spec.containers[i]\n\n\tbeggining_of_path := \"spec.template.spec\"\n\talertInfo := evaluate_workload_non_root_container(container, wl.spec.template, beggining_of_path)\n\tfixPath := get_fixed_path(alertInfo, i)\n    failed_path := get_failed_path(alertInfo, i) \n    msga := {\n\t\t\"alertMessage\": sprintf(\"container :%v in %v: %v may run as root\", [container.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": failed_path,\n        \"fixPaths\": fixPath,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n# Fails if cronjob has a container configured to run as root\ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n\tcontainer = wl.spec.jobTemplate.spec.template.spec.containers[i]\n\n\tbeggining_of_path := \"spec.jobTemplate.spec.template.spec\"\n\talertInfo := evaluate_workload_non_root_container(container, wl.spec.jobTemplate.spec.template, beggining_of_path)\n\tfixPath := get_fixed_path(alertInfo, i)\n    failed_path := get_failed_path(alertInfo, i) \n\t\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"container :%v in %v: %v  may run as root\", [container.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": failed_path,\n        \"fixPaths\": fixPath,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\nget_failed_path(alertInfo, i) = [replace(alertInfo.failed_path,\"container_ndx\",format_int(i,10))] {\n\talertInfo.failed_path != \"\"\n} else = []\n\n\nget_fixed_path(alertInfo, i) = [{\"path\":replace(alertInfo.fixPath[0].path,\"container_ndx\",format_int(i,10)), \"value\":alertInfo.fixPath[0].value}, {\"path\":replace(alertInfo.fixPath[1].path,\"container_ndx\",format_int(i,10)), \"value\":alertInfo.fixPath[1].value}]{\n\tcount(alertInfo.fixPath) == 2\n} else = [{\"path\":replace(alertInfo.fixPath[0].path,\"container_ndx\",format_int(i,10)), \"value\":alertInfo.fixPath[0].value}] {\n\tcount(alertInfo.fixPath) == 1\n}  else = []\n\n#################################################################################\n# Workload evaluation \n\nevaluate_workload_non_root_container(container, pod, beggining_of_path) = alertInfo {\n\trunAsNonRootValue := get_run_as_non_root_value(container, pod, beggining_of_path)\n\trunAsNonRootValue.value == false\n\t\n\trunAsUserValue := get_run_as_user_value(container, pod, beggining_of_path)\n\trunAsUserValue.value == 0\n\n\talertInfo := choose_first_if_defined(runAsUserValue, runAsNonRootValue)\n} else = alertInfo {\n    allowPrivilegeEscalationValue := get_allow_privilege_escalation(container, pod, beggining_of_path)\n    allowPrivilegeEscalationValue.value == true\n\n    alertInfo := allowPrivilegeEscalationValue\n}\n\n\n#################################################################################\n# Value resolution functions\n\n\nget_run_as_non_root_value(container, pod, beggining_of_path) = runAsNonRoot {\n    failed_path := sprintf(\"%v.containers[container_ndx].securityContext.runAsNonRoot\", [beggining_of_path]) \n    runAsNonRoot := {\"value\" : container.securityContext.runAsNonRoot, \"failed_path\" : failed_path, \"fixPath\": [] ,\"defined\" : true}\n} else = runAsNonRoot {\n\tfailed_path := sprintf(\"%v.securityContext.runAsNonRoot\", [beggining_of_path]) \n    runAsNonRoot := {\"value\" : pod.spec.securityContext.runAsNonRoot,  \"failed_path\" : failed_path, \"fixPath\": [], \"defined\" : true}\n} else = {\"value\" : false,  \"failed_path\" : \"\", \"fixPath\": [{\"path\": sprintf(\"%v.containers[container_ndx].securityContext.runAsNonRoot\", [beggining_of_path]), \"value\":\"true\"}], \"defined\" : false} {\n\tis_allow_privilege_escalation_field(container, pod)\n} else = {\"value\" : false,  \"failed_path\" : \"\", \"fixPath\": [{\"path\":  sprintf(\"%v.containers[container_ndx].securityContext.runAsNonRoot\", [beggining_of_path]) , \"value\":\"true\"}, {\"path\":sprintf(\"%v.containers[container_ndx].securityContext.allowPrivilegeEscalation\", [beggining_of_path]), \"value\":\"false\"}], \"defined\" : false}\n\nget_run_as_user_value(container, pod, beggining_of_path) = runAsUser {\n\tfailed_path := sprintf(\"%v.containers[container_ndx].securityContext.runAsUser\", [beggining_of_path]) \n    runAsUser := {\"value\" : container.securityContext.runAsUser,  \"failed_path\" : failed_path,  \"fixPath\": [], \"defined\" : true}\n} else = runAsUser {\n\tfailed_path := sprintf(\"%v.securityContext.runAsUser\", [beggining_of_path]) \n    runAsUser := {\"value\" : pod.spec.securityContext.runAsUser,  \"failed_path\" : failed_path, \"fixPath\": [],\"defined\" : true}\n} else = {\"value\" : 0, \"failed_path\": \"\", \"fixPath\": [{\"path\":  sprintf(\"%v.containers[container_ndx].securityContext.runAsNonRoot\", [beggining_of_path]), \"value\":\"true\"}],\"defined\" : false}{\n\tis_allow_privilege_escalation_field(container, pod)\n} else = {\"value\" : 0, \"failed_path\": \"\", \n\t\"fixPath\": [{\"path\":  sprintf(\"%v.containers[container_ndx].securityContext.runAsNonRoot\", [beggining_of_path]), \"value\":\"true\"},{\"path\":  sprintf(\"%v.containers[container_ndx].securityContext.allowPrivilegeEscalation\", [beggining_of_path]), \"value\":\"false\"}],\n\t\"defined\" : false}\n\nget_run_as_group_value(container, pod, beggining_of_path) = runAsGroup {\n\tfailed_path := sprintf(\"%v.containers[container_ndx].securityContext.runAsGroup\", [beggining_of_path])\n    runAsGroup := {\"value\" : container.securityContext.runAsGroup,  \"failed_path\" : failed_path, \"fixPath\": [],\"defined\" : true}\n} else = runAsGroup {\n\tfailed_path := sprintf(\"%v.securityContext.runAsGroup\", [beggining_of_path])\n    runAsGroup := {\"value\" : pod.spec.securityContext.runAsGroup,  \"failed_path\" : failed_path, \"fixPath\":[], \"defined\" : true}\n} else = {\"value\" : 0, \"failed_path\": \"\", \"fixPath\": [{\"path\": sprintf(\"%v.containers[container_ndx].securityContext.runAsNonRoot\", [beggining_of_path]), \"value\":\"true\"}], \"defined\" : false}{\n\tis_allow_privilege_escalation_field(container, pod)\n} else = {\"value\" : 0, \"failed_path\": \"\", \n\t\"fixPath\": [{\"path\": sprintf(\"%v.containers[container_ndx].securityContext.runAsNonRoot\", [beggining_of_path]), \"value\":\"true\"},{\"path\": sprintf(\"%v.containers[container_ndx].securityContext.allowPrivilegeEscalation\", [beggining_of_path]), \"value\":\"false\"}],\n \t\"defined\" : false\n}\n\nget_allow_privilege_escalation(container, pod, beggining_of_path) = allowPrivilegeEscalation {\n\tfailed_path := sprintf(\"%v.containers[container_ndx].securityContext.allowPrivilegeEscalation\", [beggining_of_path])\n    allowPrivilegeEscalation := {\"value\" : container.securityContext.allowPrivilegeEscalation,  \"failed_path\" : failed_path, \"fixPath\": [],\"defined\" : true}\n} else = allowPrivilegeEscalation {\n\tfailed_path := sprintf(\"%v.securityContext.allowPrivilegeEscalation\", [beggining_of_path])\n    allowPrivilegeEscalation := {\"value\" : pod.spec.securityContext.allowPrivilegeEscalation,  \"failed_path\" : failed_path, \"fixPath\": [],\"defined\" : true}\n} else = {\"value\" : true, \"failed_path\": \"\", \"fixPath\": [{\"path\": sprintf(\"%v.containers[container_ndx].securityContext.allowPrivilegeEscalation\", [beggining_of_path]), \"value\":\"false\"}], \"defined\" : false}\n\nchoose_first_if_defined(l1, l2) = c {\n    l1.defined\n    c := l1\n} else = l2\n\n\nis_allow_privilege_escalation_field(container, pod) {\n\tcontainer.securityContext.allowPrivilegeEscalation == false\n}\n\nis_allow_privilege_escalation_field(container, pod) {\n\tpod.spec.securityContext.allowPrivilegeEscalation == false\n}\n\n\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Deployment",
                "ReplicaSet",
                "DaemonSet",
                "StatefulSet"
              ]
            },
            {
              "apiGroups": [
                "batch"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Job",
                "CronJob"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "fails if container can run as root",
          "remediation": "Make sure that the user/group in the securityContext of pod/container is set to an id less than 1000, or the runAsNonRoot flag is set to true. Also make sure that the allowPrivilegeEscalation field is set to false",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "drop-capability-netraw",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n# Fails if pod does not drop the capability NET_RAW \ndeny[msga] {\n    wl := input[_]\n    wl.kind == \"Pod\"\n    path_to_containers := [\"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n\t\n\tpath_to_search := [\"securityContext\", \"capabilities\", \"drop\"]\n    container_doesnt_drop_NET_RAW(container, path_to_search)\n\n\tfix_path := sprintf(\"%s[%d].%s\", [concat(\".\", path_to_containers), i, concat(\".\", path_to_search)]) \n\tfixPaths := [{\"path\": fix_path, \"value\": \"NET_RAW\"}]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Pod: %s does not drop the capability NET_RAW\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n# Fails if workload does not drop the capability NET_RAW\ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n\tpath_to_containers := [\"spec\", \"template\", \"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n\t\n\tpath_to_search := [\"securityContext\", \"capabilities\", \"drop\"]\n    container_doesnt_drop_NET_RAW(container, path_to_search)\n\n\tfix_path := sprintf(\"%s[%d].%s\", [concat(\".\", path_to_containers), i, concat(\".\", path_to_search)]) \n\tfixPaths := [{\"path\": fix_path, \"value\": \"NET_RAW\"}]\n\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Workload: %v does not drop the capability NET_RAW\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n\n# Fails if CronJob does not drop the capability NET_RAW\ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n\tpath_to_containers := [\"spec\", \"jobTemplate\", \"spec\", \"template\", \"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n\t\n\tpath_to_search := [\"securityContext\", \"capabilities\", \"drop\"]\n    container_doesnt_drop_NET_RAW(container, path_to_search)\n\n\tfix_path := sprintf(\"%s[%d].%s\", [concat(\".\", path_to_containers), i, concat(\".\", path_to_search)]) \n\tfixPaths := [{\"path\": fix_path, \"value\": \"NET_RAW\"}]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Cronjob: %v does not drop the capability NET_RAW\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\ncontainer_doesnt_drop_NET_RAW(container, path_to_search) {\n\tdrop_list := object.get(container, path_to_search, [])\n\tnot \"NET_RAW\" in drop_list\n}",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Deployment",
                "ReplicaSet",
                "DaemonSet",
                "StatefulSet"
              ]
            },
            {
              "apiGroups": [
                "batch"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Job",
                "CronJob"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "fails if container does not drop the capability NET_RAW",
          "remediation": "Define the drop list in security context capabilities to include NET_RAW.",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "set-seLinuxOptions",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\n\n# Fails if pod does not define seLinuxOptions \ndeny[msga] {\n    wl := input[_]\n    wl.kind == \"Pod\"\n    spec := wl.spec\n\tpath_to_search := [\"securityContext\", \"seLinuxOptions\"]\n\tno_seLinuxOptions_in_securityContext(spec, path_to_search)\n\n\tpath_to_containers := [\"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n    no_seLinuxOptions_in_securityContext(container, path_to_search)\n\n\tfix_path := sprintf(\"%s[%d].%s\", [concat(\".\", path_to_containers), i, concat(\".\", path_to_search)]) \n\tfixPaths := [{\"path\": fix_path, \"value\": \"YOUR_VALUE\"}]\n\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Pod: %v does not define any seLinuxOptions\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n# Fails if workload does not define seLinuxOptions\ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n    spec := wl.spec.template.spec\n\tpath_to_search := [\"securityContext\", \"seLinuxOptions\"]\n\tno_seLinuxOptions_in_securityContext(spec, path_to_search)\n\n\tpath_to_containers := [\"spec\", \"template\", \"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n    no_seLinuxOptions_in_securityContext(container, path_to_search)\n\n\tfix_path := sprintf(\"%s[%d].%s\", [concat(\".\", path_to_containers), i, concat(\".\", path_to_search)]) \n\tfixPaths := [{\"path\": fix_path, \"value\": \"YOUR_VALUE\"}]\n\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Workload: %v does not define any seLinuxOptions\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n\n# Fails if CronJob does not define seLinuxOptions \ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n\tspec := wl.spec.jobTemplate.spec.template.spec\n\tpath_to_search := [\"securityContext\", \"seLinuxOptions\"]\n\tno_seLinuxOptions_in_securityContext(spec, path_to_search)\n\n\tpath_to_containers := [\"spec\", \"jobTemplate\", \"spec\", \"template\", \"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n    no_seLinuxOptions_in_securityContext(container, path_to_search)\n\n\tfix_path := sprintf(\"%s[%d].%s\", [concat(\".\", path_to_containers), i, concat(\".\", path_to_search)]) \n\tfixPaths := [{\"path\": fix_path, \"value\": \"YOUR_VALUE\"}]\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Cronjob: %v does not define any seLinuxOptions\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\nno_seLinuxOptions_in_securityContext(spec, path_to_search){\n    object.get(spec, path_to_search, \"\") == \"\"\n}",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Deployment",
                "ReplicaSet",
                "DaemonSet",
                "StatefulSet"
              ]
            },
            {
              "apiGroups": [
                "batch"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Job",
                "CronJob"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "fails if workload and container do not define any seLinuxOptions",
          "remediation": "Make sure you set seLinuxOptions in the workload/container security context.",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "set-seccomp-profile",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\n# Fails if pod does not define seccompProfile\ndeny[msga] {\n    wl := input[_]\n    wl.kind == \"Pod\"\n    spec := wl.spec\n\tpath_to_search := [\"securityContext\", \"seccompProfile\"]\n\tseccompProfile_not_defined(spec, path_to_search)\n\n\tpath_to_containers := [\"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n    seccompProfile_not_defined(container, path_to_search)\n\n\tfix_path := sprintf(\"%s[%d].%s\", [concat(\".\", path_to_containers), i, concat(\".\", path_to_search)]) \n\tfixPaths := [{\"path\": fix_path, \"value\": \"YOUR_VALUE\"}]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Pod: %v does not define seccompProfile\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n# Fails if workload does not define seccompProfile\ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n    spec := wl.spec.template.spec\n\tpath_to_search := [\"securityContext\", \"seccompProfile\"]\n\tseccompProfile_not_defined(spec, path_to_search)\n\n\tpath_to_containers := [\"spec\", \"template\", \"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n    seccompProfile_not_defined(container, path_to_search)\n\n\tfix_path := sprintf(\"%s[%d].%s\", [concat(\".\", path_to_containers), i, concat(\".\", path_to_search)]) \n\tfixPaths := [{\"path\": fix_path, \"value\": \"YOUR_VALUE\"}]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Workload: %v does not define seccompProfile\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n\n# Fails if CronJob does not define seccompProfile\ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n    spec := wl.spec.jobTemplate.spec.template.spec\n\tpath_to_search := [\"securityContext\", \"seccompProfile\"]\n\tseccompProfile_not_defined(spec, path_to_search)\n\n\tpath_to_containers := [\"spec\", \"jobTemplate\", \"spec\", \"template\", \"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n    seccompProfile_not_defined(container, path_to_search)\n\n\tfix_path := sprintf(\"%s[%d].%s\", [concat(\".\", path_to_containers), i, concat(\".\", path_to_search)]) \n\tfixPaths := [{\"path\": fix_path, \"value\": \"YOUR_VALUE\"}]\n\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Cronjob: %v does not define seccompProfile\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\nseccompProfile_not_defined(spec, path_to_search){\n\tobject.get(spec, path_to_search, \"\") == \"\"\n}",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Deployment",
                "ReplicaSet",
                "DaemonSet",
                "StatefulSet"
              ]
            },
            {
              "apiGroups": [
                "batch"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Job",
                "CronJob"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "fails if container does not define seccompProfile",
          "remediation": "Make sure you define seccompProfile at workload or container lever.",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        "",
        "",
        "",
        "",
        "",
        ""
      ],
      "baseScore": 8
    },
    {
      "guid": "",
      "name": "The default namespace should not be used",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.7.4",
      "controlID": "CIS-5.7.4",
      "creationTime": "",
      "description": "Kubernetes provides a default namespace, where objects are placed if no namespace is specified for them. Placing objects in this namespace makes application of RBAC and other controls more difficult.",
      "remediation": "Ensure that namespaces are created to allow for appropriate segregation of Kubernetes resources and that all new resources are created in a specific namespace.",
      "rules": [
        {
          "guid": "",
          "name": "pods-in-default-namespace",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\", \"Job\", \"CronJob\", \"Pod\"}\n\tspec_template_spec_patterns[wl.kind]\n\tresult := is_default_namespace(wl.metadata)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v has pods running in the 'default' namespace\", [wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"failedPaths\": failed_path,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tmetadata.namespace == \"default\"\n\tfailed_path = \"metadata.namespace\"\n\tfixPath = \"\" \n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tnot metadata.namespace\n\tfailed_path = \"\"\n\tfixPath = {\"path\": \"metadata.namespace\", \"value\": \"YOUR_NAMESPACE\"} \n}\n\nget_failed_path(paths) = [paths[0]] {\n\tpaths[0] != \"\"\n} else = []\n\nget_fixed_path(paths) = [paths[1]] {\n\tpaths[1] != \"\"\n} else = []\n\n\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Deployment",
                "ReplicaSet",
                "DaemonSet",
                "StatefulSet"
              ]
            },
            {
              "apiGroups": [
                "batch"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Job",
                "CronJob"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "resources-notpods-in-default-namespace",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\ndeny[msga] {\n    resource := input[_]\n\tresource_kinds := {\"ConfigMap\",\"Endpoints\",\"Event\",\"LimitRange\",\"PersistentVolumeClaim\",\"PodTemplate\",\n\t\t\t\t\t\t\"ReplicationController\",\"ResourceQuota\",\"Secret\",\"ServiceAccount\",\"Service\",\n\t\t\t\t\t\t\"ControllerRevision\",\"HorizontalPodAutoscaler\",\"Lease\",\"EndpointSlice\",\"Event\",\n\t\t\t\t\t\t\"Ingress\",\"NetworkPolicy\",\"PodDisruptionBudget\",\"RoleBinding\",\"Role\",\"CSIStorageCapacity\"}\n\tresource_kinds[resource.kind]\n\tresult := is_default_namespace(resource.metadata)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v is in the 'default' namespace\", [resource.kind, resource.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"failedPaths\": failed_path,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [resource]\n\t\t}\n\t}\n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tmetadata.namespace == \"default\"\n\tfailed_path = \"metadata.namespace\"\n\tfixPath = \"\" \n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tnot metadata.namespace\n\tfailed_path = \"\"\n\tfixPath = {\"path\": \"metadata.namespace\", \"value\": \"YOUR_NAMESPACE\"}\n}\n\nget_failed_path(paths) = [paths[0]] {\n\tpaths[0] != \"\"\n} else = []\n\nget_fixed_path(paths) = [paths[1]] {\n\tpaths[1] != \"\"\n} else = []\n\n\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "ConfigMap",
                "Endpoints",
                "Event",
                "LimitRange",
                "PersistentVolumeClaim",
                "PodTemplate",
                "ReplicationController",
                "ResourceQuota",
                "Secret",
                "ServiceAccount",
                "Service"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "ControllerRevision"
              ]
            },
            {
              "apiGroups": [
                "autoscaling"
              ],
              "apiVersions": [
                "v2"
              ],
              "resources": [
                "HorizontalPodAutoscaler"
              ]
            },
            {
              "apiGroups": [
                "coordination.k8s.io"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Lease"
              ]
            },
            {
              "apiGroups": [
                "discovery.k8s.io"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "EndpointSlice"
              ]
            },
            {
              "apiGroups": [
                "events.k8s.io"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Event"
              ]
            },
            {
              "apiGroups": [
                "networking.k8s.io"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Ingress",
                "NetworkPolicy"
              ]
            },
            {
              "apiGroups": [
                "policy"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "PodDisruptionBudget"
              ]
            },
            {
              "apiGroups": [
                "rbac.authorization.k8s.io"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "RoleBinding",
                "Role"
              ]
            },
            {
              "apiGroups": [
                "storage.k8s.io"
              ],
              "apiVersions": [
                "v1beta1"
              ],
              "resources": [
                "CSIStorageCapacity"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        "",
        ""
      ],
      "baseScore": 4
    },
    {
      "guid": "",
      "name": "Prefer using secrets as files over secrets as environment variables",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.4.1",
      "controlID": "CIS-5.4.1",
      "creationTime": "",
      "description": "Kubernetes supports mounting secrets as data volumes or as environment variables. Minimize the use of environment variable secrets.",
      "remediation": "If possible, rewrite application code to read secrets from mounted secret files, rather than from environment variables.",
      "rules": [
        {
          "guid": "",
          "name": "rule-secrets-in-env-var",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\nimport data\n\ndeny[msga] {\n\tpod := input[_]\n\tpod.kind == \"Pod\"\n\n\tcontainer := pod.spec.containers[i]\n\tenv := container.env[j]\n\tenv.valueFrom.secretKeyRef\n\n\tpath := sprintf(\"spec.containers[%v].env[%v].name\", [format_int(i, 10), format_int(j, 10)])\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Pod: %v has secrets in environment variables\", [pod.metadata.name]),\n\t\t\"alertScore\": 9,\n\t\t\"fixPaths\": [],\n\t\t\"failedPaths\": [path],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}\n\ndeny[msga] {\n\twl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n\tcontainer := wl.spec.template.spec.containers[i]\n\tenv := container.env[j]\n\tenv.valueFrom.secretKeyRef\n\n\tpath := sprintf(\"spec.template.spec.containers[%v].env[%v].name\", [format_int(i, 10), format_int(j, 10)])\t\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v has secrets in environment variables\", [wl.kind, wl.metadata.name]),\n\t\t\"alertScore\": 9,\n\t\t\"fixPaths\": [],\n\t\t\"failedPaths\": [path],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n\tcontainer := wl.spec.jobTemplate.spec.template.spec.containers[i]\n\tenv := container.env[j]\n\tenv.valueFrom.secretKeyRef\n\t\n\tpath := sprintf(\"spec.jobTemplate.spec.template.spec.containers[%v].env[%v].name\", [format_int(i, 10), format_int(j, 10)])\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Cronjob: %v has secrets in environment variables\", [wl.metadata.name]),\n\t\t\"alertScore\": 9,\n\t\t\"fixPaths\": [],\n\t\t\"failedPaths\": [path],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Deployment",
                "ReplicaSet",
                "DaemonSet",
                "StatefulSet"
              ]
            },
            {
              "apiGroups": [
                "batch"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Job",
                "CronJob"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "fails if Pods have secrets in environment variables",
          "remediation": "If possible, rewrite application code to read secrets from mounted secret files, rather than from environment variables.",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 4
    },
    {
      "guid": "",
      "name": "Ensure that the --cert-file and --key-file arguments are set as appropriate",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-2.1",
      "controlID": "CIS-2.1",
      "creationTime": "",
      "description": "Configure TLS encryption for the etcd service.",
      "remediation": "Follow the etcd service documentation and configure TLS encryption.\n\n Then, edit the etcd pod specification file `/etc/kubernetes/manifests/etcd.yaml` on the master node and set the below parameters.\n\n \n```\n--cert-file=\u003c/path/to/ca-file\u003e\n--key-file=\u003c/path/to/key-file\u003e\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "etcd-tls-enabled",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\n# Check if tls is configured in a etcd service\ndeny[msga] {\n\tobj = input[_]\n\tis_etcd_pod(obj)\n\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\n\tmsga := {\n\t\t\"alertMessage\": \"etcd encryption is not enabled\",\n\t\t\"alertScore\": 8,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_etcd_pod(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tcount(obj.spec.containers) == 1\n\tendswith(split(obj.spec.containers[0].command[0], \" \")[0], \"etcd\")\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tfull_cmd = concat(\" \", cmd)\n\twanted = [\n\t\t[\"--cert-file\", \"\u003cpath/to/tls-certificate-file.crt\u003e\"],\n\t\t[\"--key-file\", \"\u003cpath/to/tls-key-file.key\u003e\"],\n\t]\n\n\tfix_paths = [{\n\t\t\"path\": sprintf(\"spec.containers[0].command[%d]\", [count(cmd) + i]),\n\t\t\"value\": sprintf(\"%s=%s\", wanted[i]),\n\t} |\n\t\tnot contains(full_cmd, wanted[i][0])\n\t]\n\n\tcount(fix_paths) \u003e 0\n\n\tresult = {\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": fix_paths,\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_etcd_pod(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_etcd_pod(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tcount(obj.spec.containers) == 1\n\tendswith(split(obj.spec.containers[0].command[0], \" \")[0], \"etcd\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Configure TLS encryption for the etcd service.",
          "remediation": "Follow the etcd service documentation and configure TLS encryption.\n\n Then, edit the etcd pod specification file `/etc/kubernetes/manifests/etcd.yaml` on the master node and set the below parameters.\n\n \n```\n--cert-file=\u003c/path/to/ca-file\u003e\n--key-file=\u003c/path/to/key-file\u003e\n\n```\n\n#### Impact Statement\nClient connections only over TLS would be served.\n\n#### Default Value\nBy default, TLS encryption is not set.",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 8
    },
    {
      "guid": "",
      "name": "Ensure that the --client-cert-auth argument is set to true",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-2.2",
      "controlID": "CIS-2.2",
      "creationTime": "",
      "description": "Enable client authentication on etcd service.",
      "remediation": "Edit the etcd pod specification file `/etc/kubernetes/manifests/etcd.yaml` on the master node and set the below parameter.\n\n \n```\n--client-cert-auth=\"true\"\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "etcd-client-auth-cert",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\n# Check if --client-cert-auth is set to true\ndeny[msga] {\n\tobj = input[_]\n\tis_etcd_pod(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\n\tmsga := {\n\t\t\"alertMessage\": \"Etcd server is not requiring a valid client certificate\",\n\t\t\"alertScore\": 8,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_etcd_pod(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tcount(obj.spec.containers) == 1\n\tendswith(split(obj.spec.containers[0].command[0], \" \")[0], \"etcd\")\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tfull_cmd = concat(\" \", cmd)\n\tnot contains(full_cmd, \"--client-cert-auth\")\n\tresult := {\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": sprintf(\"spec.containers[0].command[%d]\", [count(cmd)]),\n\t\t\t\"value\": \"--client-cert-auth=true\",\n\t\t}],\n\t}\n}\n\ninvalid_flag(cmd) = result {\n\tcontains(cmd[i], \"--client-cert-auth=false\")\n\tfixed = replace(cmd[i], \"--client-cert-auth=false\", \"--client-cert-auth=true\")\n\tpath := sprintf(\"spec.containers[0].command[%d]\", [i])\n\tresult = {\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\"path\": path, \"value\": fixed}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_etcd_pod(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_etcd_pod(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tcount(obj.spec.containers) == 1\n\tendswith(split(obj.spec.containers[0].command[0], \" \")[0], \"etcd\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Enable client authentication on etcd service.",
          "remediation": "Edit the etcd pod specification file `/etc/kubernetes/manifests/etcd.yaml` on the master node and set the below parameter.\n\n \n```\n--client-cert-auth=\"true\"\n\n```\n\n#### Impact Statement\nAll clients attempting to access the etcd server will require a valid client certificate.\n\n#### Default Value\nBy default, the etcd service can be queried by unauthenticated clients.",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 8
    },
    {
      "guid": "",
      "name": "Ensure that the --auto-tls argument is not set to true",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-2.3",
      "controlID": "CIS-2.3",
      "creationTime": "",
      "description": "Do not use self-signed certificates for TLS.",
      "remediation": "Edit the etcd pod specification file `/etc/kubernetes/manifests/etcd.yaml` on the master node and either remove the `--auto-tls` parameter or set it to `false`.\n\n \n```\n--auto-tls=false\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "etcd-auto-tls-disabled",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\n# Check if --auto-tls is not set to true\ndeny[msga] {\n\tobj = input[_]\n\tis_etcd_pod(obj)\n\n\tcommands := obj.spec.containers[0].command\n\tresult := invalid_flag(commands)\n\n\tmsga := {\n\t\t\"alertMessage\": \"Auto tls is enabled. Clients are able to use self-signed certificates for TLS.\",\n\t\t\"alertScore\": 6,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_etcd_pod(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tcount(obj.spec.containers) == 1\n\tendswith(split(obj.spec.containers[0].command[0], \" \")[0], \"etcd\")\n}\n\ninvalid_flag(cmd) = result {\n\tcontains(cmd[i], \"--auto-tls=true\")\n\tfixed = replace(cmd[i], \"--auto-tls=true\", \"--auto-tls=false\")\n\tpath := sprintf(\"spec.containers[0].command[%d]\", [i])\n\tresult = {\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\"path\": path, \"value\": fixed}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_etcd_pod(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_etcd_pod(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tcount(obj.spec.containers) == 1\n\tendswith(split(obj.spec.containers[0].command[0], \" \")[0], \"etcd\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Do not use self-signed certificates for TLS.",
          "remediation": "Edit the etcd pod specification file `/etc/kubernetes/manifests/etcd.yaml` on the master node and either remove the `--auto-tls` parameter or set it to `false`.\n\n \n```\n--auto-tls=false\n\n```\n\n#### Impact Statement\nClients will not be able to use self-signed certificates for TLS.\n\n#### Default Value\nBy default, `--auto-tls` is set to `false`.",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Ensure that the --peer-cert-file and --peer-key-file arguments are set as appropriate",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-2.4",
      "controlID": "CIS-2.4",
      "creationTime": "",
      "description": "etcd should be configured to make use of TLS encryption for peer connections.",
      "remediation": "Follow the etcd service documentation and configure peer TLS encryption as appropriate for your etcd cluster.\n\n Then, edit the etcd pod specification file `/etc/kubernetes/manifests/etcd.yaml` on the master node and set the below parameters.\n\n \n```\n--peer-client-file=\u003c/path/to/peer-cert-file\u003e\n--peer-key-file=\u003c/path/to/peer-key-file\u003e\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "etcd-peer-tls-enabled",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\n# Check if peer tls is enabled in etcd cluster\ndeny[msga] {\n\tobj = input[_]\n\tis_etcd_pod(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\n\tmsga := {\n\t\t\"alertMessage\": \"Etcd encryption for peer connection is not enabled.\",\n\t\t\"alertScore\": 7,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_etcd_pod(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tcount(obj.spec.containers) == 1\n\tendswith(split(obj.spec.containers[0].command[0], \" \")[0], \"etcd\")\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tfull_cmd = concat(\" \", cmd)\n\twanted = [\n\t\t[\"--peer-cert-file\", \"\u003cpath/to/tls-certificate-file.crt\u003e\"],\n\t\t[\"--peer-key-file\", \"\u003cpath/to/tls-key-file.key\u003e\"],\n\t]\n\n\tfix_paths = [{\n\t\t\"path\": sprintf(\"spec.containers[0].command[%d]\", [count(cmd) + i]),\n\t\t\"value\": sprintf(\"%s=%s\", wanted[i]),\n\t} |\n\t\tnot contains(full_cmd, wanted[i][0])\n\t]\n\n\tcount(fix_paths) \u003e 0\n\n\tresult = {\n\t\t\"failed_paths\": [\"spec.containers[0].command\"],\n\t\t\"fix_paths\": fix_paths,\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_etcd_pod(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_etcd_pod(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tcount(obj.spec.containers) == 1\n\tendswith(split(obj.spec.containers[0].command[0], \" \")[0], \"etcd\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "etcd should be configured to make use of TLS encryption for peer connections.",
          "remediation": "Follow the etcd service documentation and configure peer TLS encryption as appropriate for your etcd cluster.\n\n Then, edit the etcd pod specification file `/etc/kubernetes/manifests/etcd.yaml` on the master node and set the below parameters.\n\n \n```\n--peer-client-file=\u003c/path/to/peer-cert-file\u003e\n--peer-key-file=\u003c/path/to/peer-key-file\u003e\n\n```\n\n#### Impact Statement\netcd cluster peers would need to set up TLS for their communication.\n\n#### Default Value\n**Note:** This recommendation is applicable only for etcd clusters. If you are using only one etcd server in your environment then this recommendation is not applicable.\n\n By default, peer communication over TLS is not configured.",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 7
    },
    {
      "guid": "",
      "name": "Ensure that the --peer-client-cert-auth argument is set to true",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-2.5",
      "controlID": "CIS-2.5",
      "creationTime": "",
      "description": "etcd should be configured for peer authentication.",
      "remediation": "Edit the etcd pod specification file `/etc/kubernetes/manifests/etcd.yaml` on the master node and set the below parameter.\n\n \n```\n--peer-client-cert-auth=true\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "etcd-peer-client-auth-cert",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\n# Check if --client-cert-auth is set to true\ndeny[msga] {\n\tobj = input[_]\n\tis_etcd_pod(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\n\tmsga := {\n\t\t\"alertMessage\": \"Etcd server is not requiring a valid client certificate.\",\n\t\t\"alertScore\": 7,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_etcd_pod(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tcount(obj.spec.containers) == 1\n\tendswith(split(obj.spec.containers[0].command[0], \" \")[0], \"etcd\")\n}\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tfull_cmd = concat(\" \", cmd)\n\tnot contains(full_cmd, \"--peer-client-cert-auth\")\n\tresult := {\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": sprintf(\"spec.containers[0].command[%d]\", [count(cmd)]),\n\t\t\t\"value\": \"--peer-client-cert-auth=true\",\n\t\t}],\n\t}\n}\n\ninvalid_flag(cmd) = result {\n\tcontains(cmd[i], \"--peer-client-cert-auth=false\")\n\tfixed = replace(cmd[i], \"--peer-client-cert-auth=false\", \"--peer-client-cert-auth=true\")\n\tpath := sprintf(\"spec.containers[0].command[%d]\", [i])\n\tresult = {\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\"path\": path, \"value\": fixed}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_etcd_pod(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_etcd_pod(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tcount(obj.spec.containers) == 1\n\tendswith(split(obj.spec.containers[0].command[0], \" \")[0], \"etcd\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "etcd should be configured for peer authentication.",
          "remediation": "Edit the etcd pod specification file `/etc/kubernetes/manifests/etcd.yaml` on the master node and set the below parameter.\n\n \n```\n--peer-client-cert-auth=true\n\n```\n\n#### Impact Statement\nAll peers attempting to communicate with the etcd server will require a valid client certificate for authentication.\n\n#### Default Value\n**Note:** This recommendation is applicable only for etcd clusters. If you are using only one etcd server in your environment then this recommendation is not applicable.\n\n By default, `--peer-client-cert-auth` argument is set to `false`.",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 7
    },
    {
      "guid": "",
      "name": "Ensure that the --peer-auto-tls argument is not set to true",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-2.6",
      "controlID": "CIS-2.6",
      "creationTime": "",
      "description": "Do not use automatically generated self-signed certificates for TLS connections between peers.",
      "remediation": "Edit the etcd pod specification file `/etc/kubernetes/manifests/etcd.yaml` on the master node and either remove the `--peer-auto-tls` parameter or set it to `false`.\n\n \n```\n--peer-auto-tls=false\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "etcd-peer-auto-tls-disabled",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\n# Check if --auto-tls is not set to true\ndeny[msga] {\n\tobj = input[_]\n\tis_etcd_pod(obj)\n\tcommands := obj.spec.containers[0].command\n\tresult := invalid_flag(commands)\n\n\tmsga := {\n\t\t\"alertMessage\": \"Peer auto tls is enabled. Peer clients are able to use self-signed certificates for TLS.\",\n\t\t\"alertScore\": 6,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_etcd_pod(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tcount(obj.spec.containers) == 1\n\tendswith(split(obj.spec.containers[0].command[0], \" \")[0], \"etcd\")\n}\n\ninvalid_flag(cmd) = result {\n\tcontains(cmd[i], \"--peer-auto-tls=true\")\n\tfixed = replace(cmd[i], \"--peer-auto-tls=true\", \"--peer-auto-tls=false\")\n\tpath := sprintf(\"spec.containers[0].command[%d]\", [i])\n\tresult = {\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\"path\": path, \"value\": fixed}],\n\t}\n}\n",
          "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_etcd_pod(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_etcd_pod(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tcount(obj.spec.containers) == 1\n\tendswith(split(obj.spec.containers[0].command[0], \" \")[0], \"etcd\")\n}\n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Do not use automatically generated self-signed certificates for TLS connections between peers.",
          "remediation": "Edit the etcd pod specification file `/etc/kubernetes/manifests/etcd.yaml` on the master node and either remove the `--peer-auto-tls` parameter or set it to `false`.\n\n \n```\n--peer-auto-tls=false\n\n```\n\n#### Impact Statement\nAll peers attempting to communicate with the etcd server will require a valid client certificate for authentication.\n\n#### Default Value\n**Note:** This recommendation is applicable only for etcd clusters. If you are using only one etcd server in your environment then this recommendation is not applicable.\n\n By default, `--peer-auto-tls` argument is set to `false`.",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Prefer using secrets as files over secrets as environment variables",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.4.1",
      "controlID": "CIS-5.4.1",
      "creationTime": "",
      "description": "Kubernetes supports mounting secrets as data volumes or as environment variables. Minimize the use of environment variable secrets.",
      "remediation": "If possible, rewrite application code to read secrets from mounted secret files, rather than from environment variables.",
      "rules": [
        {
          "guid": "",
          "name": "rule-secrets-in-env-var",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\nimport data\n\ndeny[msga] {\n\tpod := input[_]\n\tpod.kind == \"Pod\"\n\n\tcontainer := pod.spec.containers[i]\n\tenv := container.env[j]\n\tenv.valueFrom.secretKeyRef\n\n\tpath := sprintf(\"spec.containers[%v].env[%v].name\", [format_int(i, 10), format_int(j, 10)])\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Pod: %v has secrets in environment variables\", [pod.metadata.name]),\n\t\t\"alertScore\": 9,\n\t\t\"fixPaths\": [],\n\t\t\"failedPaths\": [path],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}\n\ndeny[msga] {\n\twl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n\tcontainer := wl.spec.template.spec.containers[i]\n\tenv := container.env[j]\n\tenv.valueFrom.secretKeyRef\n\n\tpath := sprintf(\"spec.template.spec.containers[%v].env[%v].name\", [format_int(i, 10), format_int(j, 10)])\t\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v has secrets in environment variables\", [wl.kind, wl.metadata.name]),\n\t\t\"alertScore\": 9,\n\t\t\"fixPaths\": [],\n\t\t\"failedPaths\": [path],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n\tcontainer := wl.spec.jobTemplate.spec.template.spec.containers[i]\n\tenv := container.env[j]\n\tenv.valueFrom.secretKeyRef\n\t\n\tpath := sprintf(\"spec.jobTemplate.spec.template.spec.containers[%v].env[%v].name\", [format_int(i, 10), format_int(j, 10)])\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Cronjob: %v has secrets in environment variables\", [wl.metadata.name]),\n\t\t\"alertScore\": 9,\n\t\t\"fixPaths\": [],\n\t\t\"failedPaths\": [path],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Deployment",
                "ReplicaSet",
                "DaemonSet",
                "StatefulSet"
              ]
            },
            {
              "apiGroups": [
                "batch"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Job",
                "CronJob"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "fails if Pods have secrets in environment variables",
          "remediation": "If possible, rewrite application code to read secrets from mounted secret files, rather than from environment variables.",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 4
    },
    {
      "guid": "",
      "name": "Ensure that the --anonymous-auth argument is set to false",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-4.2.1",
      "controlID": "CIS-4.2.1",
      "creationTime": "",
      "description": "Disable anonymous requests to the Kubelet server.",
      "remediation": "If using a Kubelet config file, edit the file to set `authentication: anonymous: enabled` to `false`.\n\n If using executable arguments, edit the kubelet service file `/etc/kubernetes/kubelet.conf` on each worker node and set the below parameter in `KUBELET_SYSTEM_PODS_ARGS` variable.\n\n \n```\n--anonymous-auth=false\n\n```\n Based on your system, restart the `kubelet` service. For example:\n\n \n```\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "anonymous-requests-to-kubelet-service-updated",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\n#CIS 4.2.1 https://workbench.cisecurity.org/sections/1126668/recommendations/1838638\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\tcommand := obj.data.cmdLine\n\n\tcontains(command, \"--anonymous-auth\")\n\tcontains(command, \"--anonymous-auth=true\")\n\n\texternal_obj := json.filter(obj, [\"apiVersion\", \"data/cmdLine\", \"kind\", \"metadata\"])\n\n\tmsga := {\n\t\t\"alertMessage\": \"Anonymous requests is enabled.\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": external_obj},\n\t}\n}\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--anonymous-auth\")\n\tnot contains(command, \"--config\")\n\n\texternal_obj := json.filter(obj, [\"apiVersion\", \"data/cmdLine\", \"kind\", \"metadata\"])\n\n\tmsga := {\n\t\t\"alertMessage\": \"Anonymous requests is enabled.\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": external_obj},\n\t}\n}\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--anonymous-auth\")\n\tcontains(command, \"--config\")\n\n\tdecodedConfigContent := base64.decode(obj.data.configFile.content)\n\tyamlConfig := yaml.unmarshal(decodedConfigContent)\n\tnot yamlConfig.authentication.anonymous.enabled == false\n\n\tmsga := {\n\t\t\"alertMessage\": \"Anonymous requests is enabled.\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [\"authentication.anonymous.enabled\"],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"metadata\": obj.metadata,\n\t\t\t\"data\": {\"configFile\": {\"content\": decodedConfigContent}},\n\t\t}},\n\t}\n}\n\n## Host sensor failed to get config file content\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--anonymous-auth\")\n\tcontains(command, \"--config\")\n\n\tnot obj.data.configFile.content\n\n\tmsga := {\n\t\t\"alertMessage\": \"Failed to analyze config file\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"data\": obj.data,\n\t\t}},\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.kind == \"KubeletInfo\"\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Determines if anonymous requests to the kubelet service are allowed.",
          "remediation": "Disable anonymous requests by setting  the anonymous-auth flag to false, or using the kubelet configuration file.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 7
    },
    {
      "guid": "",
      "name": "Ensure that the --authorization-mode argument is not set to AlwaysAllow",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-4.2.2",
      "controlID": "CIS-4.2.2",
      "creationTime": "",
      "description": "Do not allow all requests. Enable explicit authorization.",
      "remediation": "If using a Kubelet config file, edit the file to set `authorization: mode` to `Webhook`.\n\n If using executable arguments, edit the kubelet service file `/etc/kubernetes/kubelet.conf` on each worker node and set the below parameter in `KUBELET_AUTHZ_ARGS` variable.\n\n \n```\n--authorization-mode=Webhook\n\n```\n Based on your system, restart the `kubelet` service. For example:\n\n \n```\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "kubelet-authorization-mode-alwaysAllow",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n#CIS 4.2.2 https://workbench.cisecurity.org/sections/1126668/recommendations/1838640\n\n# has cli\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tcontains(command, \"--authorization-mode\")\n\tcontains(command, \"--authorization-mode=AlwaysAllow\")\n\n\texternal_obj := json.filter(obj, [\"apiVersion\", \"data/cmdLine\", \"kind\", \"metadata\"])\n\n\tmsga := {\n\t\t\"alertMessage\": \"Anonymous requests are enabled\",\n\t\t\"alertScore\": 10,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": external_obj},\n\t}\n}\n\n# has config\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--authorization-mode\")\n\tcontains(command, \"--config\")\n\n\tdecodedConfigContent := base64.decode(obj.data.configFile.content)\n\tyamlConfig := yaml.unmarshal(decodedConfigContent)\n\tyamlConfig.authorization.mode == \"AlwaysAllow\"\n\n\tmsga := {\n\t\t\"alertMessage\": \"Anonymous requests are enabled\",\n\t\t\"alertScore\": 10,\n\t\t\"failedPaths\": [\"authorization.mode\"],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"metadata\": obj.metadata,\n\t\t\t\"data\": {\"configFile\": {\"content\": decodedConfigContent}},\n\t\t}},\n\t}\n}\n\n# has no config and cli\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--authorization-mode\")\n\tnot contains(command, \"--config\")\n\t\n\texternal_obj := json.filter(obj, [\"apiVersion\", \"data/cmdLine\", \"kind\", \"metadata\"])\n\tmsga := {\n\t\t\"alertMessage\": \"Anonymous requests are enabled\",\n\t\t\"alertScore\": 10,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": external_obj},\n\t}\n}\n\n## Host sensor failed to get config file content\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--authorization-mode\")\n\tcontains(command, \"--config\")\n\n\tnot obj.data.configFile.content\n\n\tmsga := {\n\t\t\"alertMessage\": \"Failed to analyze config file\",\n\t\t\"alertScore\": 6,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"data\": obj.data\n\t\t}}\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.kind == \"KubeletInfo\"\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Do not allow all requests. Enable explicit authorization.",
          "remediation": "Change authorization mode to Webhook.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Ensure that the --client-ca-file argument is set as appropriate",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-4.2.3",
      "controlID": "CIS-4.2.3",
      "creationTime": "",
      "description": "Enable Kubelet authentication using certificates.",
      "remediation": "If using a Kubelet config file, edit the file to set `authentication: x509: clientCAFile` to the location of the client CA file.\n\n If using command line arguments, edit the kubelet service file `/etc/kubernetes/kubelet.conf` on each worker node and set the below parameter in `KUBELET_AUTHZ_ARGS` variable.\n\n \n```\n--client-ca-file=\u003cpath/to/client-ca-file\u003e\n\n```\n Based on your system, restart the `kubelet` service. For example:\n\n \n```\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "enforce-kubelet-client-tls-authentication-updated",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\n#CIS 4.2.3 https://workbench.cisecurity.org/sections/1126668/recommendations/1838643\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--client-ca-file\")\n\tcontains(command, \"--config\")\n\n\tdecodedConfigContent := base64.decode(obj.data.configFile.content)\n\tyamlConfig := yaml.unmarshal(decodedConfigContent)\n\tnot yamlConfig.authentication.x509.clientCAFile\n\n\tmsga := {\n\t\t\"alertMessage\": \"kubelet client TLS authentication is not enabled\",\n\t\t\"alertScore\": 6,\n\t\t\"failedPaths\": [\"authentication.x509.clientCAFile\"],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"metadata\": obj.metadata,\n\t\t\t\"data\": {\"configFile\": {\"content\": decodedConfigContent}},\n\t\t}},\n\t}\n}\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--client-ca-file\")\n\tnot contains(command, \"--config\")\n\n\tmsga := {\n\t\t\"alertMessage\": \"kubelet client TLS authentication is not enabled\",\n\t\t\"alertScore\": 6,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"data\": {\"cmdLine\": command},\n\t\t}},\n\t}\n}\n\n## Host sensor failed to get config file content\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--client-ca-file\")\n\tcontains(command, \"--config\")\n\n\tnot obj.data.configFile.content\n\n\tmsga := {\n\t\t\"alertMessage\": \"Failed to analyze config file\",\n\t\t\"alertScore\": 6,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"data\": obj.data,\n\t\t}},\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.kind == \"KubeletInfo\"\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Determines if kubelet client tls authentication is enabled.",
          "remediation": "Start the kubelet with the --client-ca-file flag, providing a CA bundle to verify client certificates with.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Verify that the --read-only-port argument is set to 0",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-4.2.4",
      "controlID": "CIS-4.2.4",
      "creationTime": "",
      "description": "Disable the read-only port.",
      "remediation": "If using a Kubelet config file, edit the file to set `readOnlyPort` to `0`.\n\n If using command line arguments, edit the kubelet service file `/etc/kubernetes/kubelet.conf` on each worker node and set the below parameter in `KUBELET_SYSTEM_PODS_ARGS` variable.\n\n \n```\n--read-only-port=0\n\n```\n Based on your system, restart the `kubelet` service. For example:\n\n \n```\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "read-only-port-enabled-updated",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n#CIS 4.2.4 https://workbench.cisecurity.org/sections/1126668/recommendations/1838645\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tcontains(command, \"--read-only-port\")\n\tnot contains(command, \"--read-only-port=0\")\n\n\texternal_obj := json.filter(obj, [\"apiVersion\", \"data/cmdLine\", \"kind\", \"metadata\"])\n\n\tmsga := {\n\t\t\"alertMessage\": \"kubelet read-only port is not disabled\",\n\t\t\"alertScore\": 4,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": external_obj,\n\t}\n}\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(obj, \"--read-only-port\")\n\tcontains(command, \"--config\")\n\n\tdecodedConfigContent := base64.decode(obj.data.configFile.content)\n\tyamlConfig := yaml.unmarshal(decodedConfigContent)\n\n\tyamlConfig.readOnlyPort\n\tnot yamlConfig.readOnlyPort == 0\n\n\tmsga := {\n\t\t\"alertMessage\": \"kubelet read-only port is not disabled\",\n\t\t\"alertScore\": 4,\n\t\t\"failedPaths\": [\"readOnlyPort\"],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"metadata\": obj.metadata,\n\t\t\t\"data\": {\"configFile\": {\"content\": decodedConfigContent}},\n\t\t}},\n\t}\n}\n\n## Host sensor failed to get config file content\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(obj, \"--read-only-port\")\n\tcontains(command, \"--config\")\n\n\tnot obj.data.configFile.content\n\n\tmsga := {\n\t\t\"alertMessage\": \"Failed to analyze config file\",\n\t\t\"alertScore\": 4,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"data\": obj.data,\n\t\t}},\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.kind == \"KubeletInfo\"\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Determines if kubelet has read-only port enabled.",
          "remediation": "Start the kubelet with the --read-only-port flag set to 0.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 4
    },
    {
      "guid": "",
      "name": "Ensure that the --streaming-connection-idle-timeout argument is not set to 0",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-4.2.5",
      "controlID": "CIS-4.2.5",
      "creationTime": "",
      "description": "Do not disable timeouts on streaming connections.",
      "remediation": "If using a Kubelet config file, edit the file to set `streamingConnectionIdleTimeout` to a value other than 0.\n\n If using command line arguments, edit the kubelet service file `/etc/kubernetes/kubelet.conf` on each worker node and set the below parameter in `KUBELET_SYSTEM_PODS_ARGS` variable.\n\n \n```\n--streaming-connection-idle-timeout=5m\n\n```\n Based on your system, restart the `kubelet` service. For example:\n\n \n```\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "kubelet-streaming-connection-idle-timeout",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n#CIS 4.2.5 https://workbench.cisecurity.org/sections/1126668/recommendations/1838646\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\t\n\tcommand := obj.data.cmdLine\n\n\tcontains(command, \"--streaming-connection-idle-timeout\")\n\tcontains(command, \"--streaming-connection-idle-timeout=0\")\n\n\texternal_obj := json.filter(obj, [\"apiVersion\", \"data/cmdLine\", \"kind\", \"metadata\"])\n\n\tmsga := {\n\t\t\"alertMessage\": \"Timeouts on streaming connections are enabled\",\n\t\t\"alertScore\": 3,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": external_obj\n\t}\n}\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--streaming-connection-idle-timeout\")\n\tcontains(command, \"--config\")\n\n\tdecodedConfigContent := base64.decode(obj.data.configFile.content)\n\tyamlConfig := yaml.unmarshal(decodedConfigContent)\n\tyamlConfig.streamingConnectionIdleTimeout == 0\n\n\tmsga := {\n\t\t\"alertMessage\": \"Timeouts on streaming connections are enabled\",\n\t\t\"alertScore\": 3,\n\t\t\"failedPaths\": [\"streamingConnectionIdleTimeout\"],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"metadata\": obj.metadata,\n\t\t\t\"data\": {\"configFile\": {\"content\": decodedConfigContent}},\n\t\t}}\n\t}\n}\n\n## Host sensor failed to get config file content\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--streaming-connection-idle-timeout\")\n\tcontains(command, \"--config\")\n\n\tnot obj.data.configFile.content\n\n\tmsga := {\n\t\t\"alertMessage\": \"Failed to analyze config file\",\n\t\t\"alertScore\": 3,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"data\": obj.data\n\t\t}}\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.kind == \"KubeletInfo\"\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Determines if a kubelet has not disabled timeouts on streaming connections",
          "remediation": "Change value of a --streaming-connection-idle-timeout argument or if using a Kubelet config file, edit the file to set streamingConnectionIdleTimeout to a value other than 0.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 3
    },
    {
      "guid": "",
      "name": "Ensure that the --protect-kernel-defaults argument is set to true",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-4.2.6",
      "controlID": "CIS-4.2.6",
      "creationTime": "",
      "description": "Protect tuned kernel parameters from overriding kubelet default kernel parameter values.",
      "remediation": "If using a Kubelet config file, edit the file to set `protectKernelDefaults: true`.\n\n If using command line arguments, edit the kubelet service file `/etc/kubernetes/kubelet.conf` on each worker node and set the below parameter in `KUBELET_SYSTEM_PODS_ARGS` variable.\n\n \n```\n--protect-kernel-defaults=true\n\n```\n Based on your system, restart the `kubelet` service. For example:\n\n \n```\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "kubelet-protect-kernel-defaults",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n#CIS 4.2.6 https://workbench.cisecurity.org/sections/1126668/recommendations/1838648\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tcontains(command, \"--protect-kernel-defaults\")\n\tnot contains(command, \"--protect-kernel-defaults=true\")\n\n\texternal_obj := json.filter(obj, [\"apiVersion\", \"data/cmdLine\", \"kind\", \"metadata\"])\n\n\tmsga := {\n\t\t\"alertMessage\": \"Argument --protect-kernel-defaults is not set to true.\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": external_obj},\n\t}\n}\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--protect-kernel-defaults\")\n\tcontains(command, \"--config\")\n\n\tdecodedConfigContent := base64.decode(obj.data.configFile.content)\n\tyamlConfig := yaml.unmarshal(decodedConfigContent)\n\tnot yamlConfig.protectKernelDefaults == true\n\n\tmsga := {\n\t\t\"alertMessage\": \"Property protectKernelDefaults is not set to true\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [\"protectKernelDefaults\"],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"metadata\": obj.metadata,\n\t\t\t\"data\": {\"configFile\": {\"content\": decodedConfigContent}},\n\t\t}},\n\t}\n}\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--protect-kernel-defaults\")\n\tnot contains(command, \"--config\")\n\n\texternal_obj := json.filter(obj, [\"apiVersion\", \"data/cmdLine\", \"kind\", \"metadata\"])\n\n\tmsga := {\n\t\t\"alertMessage\": \"Argument --protect-kernel-defaults is not set to true.\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": external_obj},\n\t}\n}\n\n## Host sensor failed to get config file content\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--protect-kernel-defaults\")\n\tcontains(command, \"--config\")\n\n\tnot obj.data.configFile.content\n\n\tmsga := {\n\t\t\"alertMessage\": \"Failed to analyze config file\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"data\": obj.data,\n\t\t}},\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.kind == \"KubeletInfo\"\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Determines if the --protect-kernel-defaults argument is set to true.",
          "remediation": "Set --protect-kernel-defaults to true or if using a config file set the protectKernelDefaults as true",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 2
    },
    {
      "guid": "",
      "name": "Ensure that the --make-iptables-util-chains argument is set to true",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-4.2.7",
      "controlID": "CIS-4.2.7",
      "creationTime": "",
      "description": "Allow Kubelet to manage iptables.",
      "remediation": "If using a Kubelet config file, edit the file to set `makeIPTablesUtilChains: true`.\n\n If using command line arguments, edit the kubelet service file `/etc/kubernetes/kubelet.conf` on each worker node and remove the `--make-iptables-util-chains` argument from the `KUBELET_SYSTEM_PODS_ARGS` variable.\n\n Based on your system, restart the `kubelet` service. For example:\n\n \n```\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "kubelet-ip-tables",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n#CIS 4.2.7 https://workbench.cisecurity.org/sections/1126668/recommendations/1838651\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tcontains(command, \"--make-iptables-util-chains\")\n\tnot contains(command, \"--make-iptables-util-chains=true\")\n\n\texternal_obj := json.filter(obj, [\"apiVersion\", \"data/cmdLine\", \"kind\", \"metadata\"])\n\n\tmsga := {\n\t\t\"alertMessage\": \"Argument --make-iptables-util-chains is not set to true.\",\n\t\t\"alertScore\": 3,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": external_obj},\n\t}\n}\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--make-iptables-util-chains\")\n\tcontains(command, \"--config\")\n\n\tdecodedConfigContent := base64.decode(obj.data.configFile.content)\n\tyamlConfig := yaml.unmarshal(decodedConfigContent)\n\tnot yamlConfig.makeIPTablesUtilChains == true\n\n\tmsga := {\n\t\t\"alertMessage\": \"Property makeIPTablesUtilChains is not set to true\",\n\t\t\"alertScore\": 3,\n\t\t\"failedPaths\": [\"makeIPTablesUtilChains\"],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"metadata\": obj.metadata,\n\t\t\t\"data\": {\"configFile\": {\"content\": decodedConfigContent}},\n\t\t}},\n\t}\n}\n\n## Host sensor failed to get config file content\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--make-iptables-util-chains\")\n\tcontains(command, \"--config\")\n\n\tnot obj.data.configFile.content\n\n\tmsga := {\n\t\t\"alertMessage\": \"Failed to analyze config file\",\n\t\t\"alertScore\": 6,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"data\": obj.data,\n\t\t}},\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.kind == \"KubeletInfo\"\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensures that the --make-iptables-util-chains argument is set to true.",
          "remediation": "Set --make-iptables-util-chains to true or if using a config file set the makeIPTablesUtilChains as true",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 3
    },
    {
      "guid": "",
      "name": "Ensure that the --hostname-override argument is not set",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-4.2.8",
      "controlID": "CIS-4.2.8",
      "creationTime": "",
      "description": "Do not override node hostnames.",
      "remediation": "Edit the kubelet service file `/etc/systemd/system/kubelet.service.d/10-kubeadm.conf` on each worker node and remove the `--hostname-override` argument from the `KUBELET_SYSTEM_PODS_ARGS` variable.\n\n Based on your system, restart the `kubelet` service. For example:\n\n \n```\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "kubelet-hostname-override",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n#CIS 4.2.8 https://workbench.cisecurity.org/sections/1126668/recommendations/1838654\n\ndeny[msga] {\n\tkubelet_info := input[_]\n\tkubelet_info.kind == \"KubeletInfo\"\n\tkubelet_info.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tcommand := kubelet_info.data.cmdLine\n\n\tcontains(command, \"--hostname-override\")\n\n\texternal_obj := json.filter(kubelet_info, [\"apiVersion\", \"data/cmdLine\", \"kind\", \"metadata\"])\n\n\tmsga := {\n\t\t\"alertMessage\": \"Argument --hostname-override is set.\",\n\t\t\"alertScore\": 3,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": external_obj},\n\t}\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the --hostname-override argument is not set.",
          "remediation": "Unset the --hostname-override argument.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 3
    },
    {
      "guid": "",
      "name": "Ensure that the --event-qps argument is set to 0 or a level which ensures appropriate event capture",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-4.2.9",
      "controlID": "CIS-4.2.9",
      "creationTime": "",
      "description": "Security relevant information should be captured. The `--event-qps` flag on the Kubelet can be used to limit the rate at which events are gathered. Setting this too low could result in relevant events not being logged, however the unlimited setting of `0` could result in a denial of service on the kubelet.",
      "remediation": "If using a Kubelet config file, edit the file to set `eventRecordQPS:` to an appropriate level.\n\n If using command line arguments, edit the kubelet service file `/etc/systemd/system/kubelet.service.d/10-kubeadm.conf` on each worker node and set the below parameter in `KUBELET_SYSTEM_PODS_ARGS` variable.\n\n Based on your system, restart the `kubelet` service. For example:\n\n \n```\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "kubelet-event-qps",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n#CIS 4.2.9 https://workbench.cisecurity.org/sections/1126668/recommendations/1838656\n\n# if --event-qps is present rule should pass\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--event-qps\")\n\tcontains(command, \"--config\")\n\n\tdecodedConfigContent := base64.decode(obj.data.configFile.content)\n\tyamlConfig := yaml.unmarshal(decodedConfigContent)\n\tyamlConfig.eventRecordQPS == 0\n\n\tmsga := {\n\t\t\"alertMessage\": \"Value of the eventRecordQPS argument is set to 0\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [\"eventRecordQPS\"],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"metadata\": obj.metadata,\n\t\t\t\"data\": {\"configFile\": {\"content\": decodedConfigContent}},\n\t\t}},\n\t}\n}\n\n## Host sensor failed to get config file content\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--event-qps\")\n\tcontains(command, \"--config\")\n\n\tnot obj.data.configFile.content\n\n\tmsga := {\n\t\t\"alertMessage\": \"Failed to analyze config file\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"data\": obj.data,\n\t\t}},\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.kind == \"KubeletInfo\"\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the --event-qps argument is set to 0 or a level which ensures appropriate event capture.",
          "remediation": "Set --event-qps argument to appropiate level or if using a config file set the eventRecordQPS property to the value other than 0",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 2
    },
    {
      "guid": "",
      "name": "Ensure that the --tls-cert-file and --tls-private-key-file arguments are set as appropriate",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-4.2.10",
      "controlID": "CIS-4.2.10",
      "creationTime": "",
      "description": "Setup TLS connection on the Kubelets.",
      "remediation": "If using a Kubelet config file, edit the file to set tlsCertFile to the location of the certificate file to use to identify this Kubelet, and tlsPrivateKeyFile to the location of the corresponding private key file.\n\n If using command line arguments, edit the kubelet service file /etc/kubernetes/kubelet.conf on each worker node and set the below parameters in KUBELET\\_CERTIFICATE\\_ARGS variable.\n\n --tls-cert-file=\u003cpath/to/tls-certificate-file\u003e --tls-private-key-file=\u003cpath/to/tls-key-file\u003e\nBased on your system, restart the kubelet service. For example:\n\n \n```\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "validate-kubelet-tls-configuration-updated",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\n#CIS 4.2.10 https://workbench.cisecurity.org/sections/1126668/recommendations/1838657\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--config\")\n\n\tres := not_set_arguments(command)\n\tcount(res) != 0\n\n\tfailed_args := extract_failed_object(res, \"cliArg\")\n\n\texternal_obj := json.filter(obj, [\"apiVersion\", \"data/cmdLine\", \"kind\", \"metadata\"])\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v should be set\", [failed_args]),\n\t\t\"alertScore\": 2,\n\t\t\"fixPaths\": [],\n\t\t\"failedPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": external_obj},\n\t}\n}\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tcontains(command, \"--config\")\n\n\tres := not_set_arguments(command)\n\tcount(res) == 2\n\n\tdecodedConfigContent := base64.decode(obj.data.configFile.content)\n\tyamlConfig := yaml.unmarshal(decodedConfigContent)\n\n\tpropsResult := not_set_props(yamlConfig)\n\tcount(propsResult) != 0\n\n\tfailed_props := extract_failed_object(propsResult, \"configProp\")\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v must be set\", [failed_props]),\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"metadata\": obj.metadata,\n\t\t\t\"data\": {\"configFile\": {\"content\": decodedConfigContent}},\n\t\t}},\n\t}\n}\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tcontains(command, \"--config\")\n\n\t# only 1 argument is set via cli\n\tres := not_set_arguments(command)\n\tcount(res) == 1\n\n\t#get yaml config equivalent\n\tnot_set_prop := res[0].configProp\n\n\tfailed_args := extract_failed_object(res, \"cliArg\")\n\n\tdecodedConfigContent := base64.decode(obj.data.configFile.content)\n\tyamlConfig := yaml.unmarshal(decodedConfigContent)\n\n\tnot yamlConfig[not_set_prop]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v should be set\", [failed_args]),\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"metadata\": obj.metadata,\n\t\t\t\"data\": {\"configFile\": {\"content\": decodedConfigContent}},\n\t\t}},\n\t}\n}\n\nextract_failed_object(resultList, keyField) = failed_objects {\n\tfailed_objects_array = [mapped |\n\t\tsingleResult := resultList[_]\n\t\tmapped := singleResult[keyField]\n\t]\n\n\tfailed_objects = concat(\", \", failed_objects_array)\n}\n\nnot_set_arguments(cmd) = result {\n\twanted = [\n\t\t[\"--tls-cert-file\", \"tlsCertFile\"],\n\t\t[\"--tls-private-key-file\", \"tlsPrivateKeyFile\"],\n\t]\n\n\tresult = [{\n\t\t\"cliArg\": wanted[i][0],\n\t\t\"configProp\": wanted[i][1],\n\t} |\n\t\tnot contains(cmd, wanted[i][0])\n\t]\n}\n\nnot_set_props(yamlConfig) = result {\n\twanted = [\n\t\t[\"tlsCertFile\", \"--tls-cert-file\"],\n\t\t[\"tlsPrivateKeyFile\", \"--tls-private-key-file\"],\n\t]\n\n\tresult = [{\n\t\t\"cliArg\": wanted[i][1],\n\t\t\"configProp\": wanted[i][0],\n\t} |\n\t\tnot yamlConfig[wanted[i][0]]\n\t]\n}\n\nis_kubelet_info(obj) {\n\tobj.kind == \"KubeletInfo\"\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletConfiguration",
                "KubeletCommandLine"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the --tls-cert-file and --tls-private-key-file arguments are set as appropriate.",
          "remediation": "Start the kubelet with the --tls-cert-file and --tls-private-key-file flags, providing the X509 certificate and its matching private key or if using config file set tlsCertFile and tlsPrivateKeyFile properties to the locations of the corresponding files.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 7
    },
    {
      "guid": "",
      "name": "Ensure that the --rotate-certificates argument is not set to false",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-4.2.11",
      "controlID": "CIS-4.2.11",
      "creationTime": "",
      "description": "Enable kubelet client certificate rotation.",
      "remediation": "If using a Kubelet config file, edit the file to add the line `rotateCertificates: true` or remove it altogether to use the default value.\n\n If using command line arguments, edit the kubelet service file `/etc/kubernetes/kubelet.conf` on each worker node and remove `--rotate-certificates=false` argument from the `KUBELET_CERTIFICATE_ARGS` variable.\n\n Based on your system, restart the `kubelet` service. For example:\n\n \n```\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "kubelet-rotate-certificates",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n#CIS 4.2.11 https://workbench.cisecurity.org/sections/1126668/recommendations/1838658\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tcontains(command, \"--rotate-certificates\")\n\tnot contains(command, \"--rotate-certificates=true\")\n\n\texternal_obj := json.filter(obj, [\"apiVersion\", \"data/cmdLine\", \"kind\", \"metadata\"])\n\n\tmsga := {\n\t\t\"alertMessage\": \"Kubelet client certificates rotation is disabled\",\n\t\t\"alertScore\": 6,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": external_obj},\n\t}\n}\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--rotate-certificates\")\n\tcontains(command, \"--config\")\n\n\tdecodedConfigContent := base64.decode(obj.data.configFile.content)\n\tyamlConfig := yaml.unmarshal(decodedConfigContent)\n\tyamlConfig.rotateCertificates == false\n\n\tmsga := {\n\t\t\"alertMessage\": \"Kubelet client certificates rotation is disabled\",\n\t\t\"alertScore\": 6,\n\t\t\"failedPaths\": [\"rotateCertificates\"],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"metadata\": obj.metadata,\n\t\t\t\"data\": {\"configFile\": {\"content\": decodedConfigContent}},\n\t\t}},\n\t}\n}\n\n## Host sensor failed to get config file content\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--rotate-certificates\")\n\tcontains(command, \"--config\")\n\n\tnot obj.data.configFile.content\n\n\tmsga := {\n\t\t\"alertMessage\": \"Failed to analyze config file\",\n\t\t\"alertScore\": 6,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"data\": obj.data,\n\t\t}},\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.kind == \"KubeletInfo\"\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the --rotate-certificates argument is not set to false.",
          "remediation": "Verify that the --rotate-certificates argument is not present, or is set to true. If the --rotate-certificates argument is not present, verify that if there is a Kubelet config file specified by --config, that file does not contain rotateCertificates: false.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Verify that the RotateKubeletServerCertificate argument is set to true",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-4.2.12",
      "controlID": "CIS-4.2.12",
      "creationTime": "",
      "description": "Enable kubelet server certificate rotation.",
      "remediation": "Edit the kubelet service file `/etc/kubernetes/kubelet.conf` on each worker node and set the below parameter in `KUBELET_CERTIFICATE_ARGS` variable.\n\n \n```\n--feature-gates=RotateKubeletServerCertificate=true\n\n```\n Based on your system, restart the `kubelet` service. For example:\n\n \n```\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "kubelet-rotate-kubelet-server-certificate",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msga] {\n\tkubelet_info := input[_]\n\tkubelet_info.kind == \"KubeletInfo\"\n\tkubelet_info.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\n\tnot should_skip_check(kubelet_info)\n\n\tcommand := kubelet_info.data.cmdLine\n\n\tnot is_RotateKubeletServerCertificate_enabled_via_cli(command)\n\n\texternal_obj := json.filter(kubelet_info, [\"apiVersion\", \"data/cmdLine\", \"kind\", \"metadata\"])\n\n\tmsga := {\n\t\t\"alertMessage\": \"RotateKubeletServerCertificate is not set to true\",\n\t\t\"alertScore\": 6,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": external_obj},\n\t}\n}\n\n## Inner rules\nshould_skip_check(kubelet_info) {\n\tcommand := kubelet_info.data.cmdLine\n\tcontains(command, \"--rotate-server-certificates\")\n}\n\nshould_skip_check(kubelet_info) {\n\tyamlConfigContent := yaml.unmarshal(base64.decode(kubelet_info.data.configFile.content))\n\tyamlConfigContent.serverTLSBootstrap == true\n}\n\nis_RotateKubeletServerCertificate_enabled_via_cli(command) {\n\tcontains(command, \"--feature-gates=\")\n\targs := regex.split(\" +\", command)\n\tsome i\n\tregex.match(\"RotateKubeletServerCertificate=true\", args[i])\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Verify that the RotateKubeletServerCertificate argument is set to true.",
          "remediation": "Verify that the --rotate-certificates argument is not present, or is set to true. If the --rotate-certificates argument is not present, verify that if there is a Kubelet config file specified by --config, that file does not contain rotateCertificates: false.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 6
    },
    {
      "guid": "",
      "name": "Ensure that the Kubelet only makes use of Strong Cryptographic Ciphers",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-4.2.13",
      "controlID": "CIS-4.2.13",
      "creationTime": "",
      "description": "Ensure that the Kubelet is configured to only use strong cryptographic ciphers.",
      "remediation": "If using a Kubelet config file, edit the file to set `TLSCipherSuites:` to `TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_128_GCM_SHA256` or to a subset of these values.\n\n If using executable arguments, edit the kubelet service file `/etc/kubernetes/kubelet.conf` on each worker node and set the `--tls-cipher-suites` parameter as follows, or to a subset of these values.\n\n \n```\n --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_128_GCM_SHA256\n\n```\n Based on your system, restart the `kubelet` service. For example:\n\n \n```\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "kubelet-strong-cryptographics-ciphers",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n#CIS 4.2.13 https://workbench.cisecurity.org/sections/1126668/recommendations/1838663\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tcontains(command, \"--tls-cipher-suites\")\n\n\tnot has_strong_cipher_set_via_cli(command)\n\n\texternal_obj := json.filter(obj, [\"apiVersion\", \"data/cmdLine\", \"kind\", \"metadata\"])\n\n\tmsga := {\n\t\t\"alertMessage\": \"Kubelet is not configured to only use strong cryptographic ciphers\",\n\t\t\"alertScore\": 5,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": external_obj},\n\t}\n}\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--tls-cipher-suites\")\n\tcontains(command, \"--config\")\n\n\tdecodedConfigContent := base64.decode(obj.data.configFile.content)\n\tyamlConfig := yaml.unmarshal(decodedConfigContent)\n\tyamlConfig.TLSCipherSuites\n\n\tnot is_value_in_strong_cliphers_set(yamlConfig.TLSCipherSuites)\n\n\tmsga := {\n\t\t\"alertMessage\": \"Kubelet is not configured to only use strong cryptographic ciphers\",\n\t\t\"alertScore\": 5,\n\t\t\"failedPaths\": [\"TLSCipherSuites\"],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"metadata\": obj.metadata,\n\t\t\t\"data\": {\"configFile\": {\"content\": decodedConfigContent}},\n\t\t}},\n\t}\n}\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--tls-cipher-suites\")\n\tnot contains(command, \"--config\")\n\n\texternal_obj := json.filter(obj, [\"apiVersion\", \"data/cmdLine\", \"kind\", \"metadata\"])\n\n\tmsga := {\n\t\t\"alertMessage\": \"Kubelet is not configured to only use strong cryptographic ciphers\",\n\t\t\"alertScore\": 5,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": external_obj},\n\t}\n}\n\nhas_strong_cipher_set_via_cli(command) {\n\tcontains(command, \"--tls-cipher-suites=\")\n\n\tstrong_cliphers := [\n\t\t\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\",\n\t\t\"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\",\n\t\t\"TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\",\n\t\t\"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\",\n\t\t\"TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305\",\n\t\t\"TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\",\n\t\t\"TLS_RSA_WITH_AES_256_GCM_SHA384\",\n\t\t\"TLS_RSA_WITH_AES_128_GCM_SHA256\",\n\t]\n\n\tsome i\n\tcontains(command, sprintf(\"%v%v\", [\"--tls-cipher-suites=\", strong_cliphers[i]]))\n}\n\nis_value_in_strong_cliphers_set(value) {\n\tstrong_cliphers := [\n\t\t\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\",\n\t\t\"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\",\n\t\t\"TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\",\n\t\t\"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\",\n\t\t\"TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305\",\n\t\t\"TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\",\n\t\t\"TLS_RSA_WITH_AES_256_GCM_SHA384\",\n\t\t\"TLS_RSA_WITH_AES_128_GCM_SHA256\",\n\t]\n\n\tsome x\n\tstrong_cliphers[x] == value\n}\n\nis_kubelet_info(obj) {\n\tobj.kind == \"KubeletInfo\"\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Determines if the Kubelet is configured to only use strong cryptographic ciphers.",
          "remediation": "Change --tls-cipher-suites value of TLSCipherSuites property of config file to use strong cryptographics ciphers",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 5
    },
    {
      "guid": "",
      "name": "Ensure that a unique Certificate Authority is used for etcd",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-2.7",
      "controlID": "CIS-2.7",
      "creationTime": "",
      "description": "Use a different certificate authority for etcd from the one used for Kubernetes.",
      "remediation": "Follow the etcd documentation and create a dedicated certificate authority setup for the etcd service.\n\n Then, edit the etcd pod specification file `/etc/kubernetes/manifests/etcd.yaml` on the master node and set the below parameter.\n\n \n```\n--trusted-ca-file=\u003c/path/to/ca-file\u003e\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "etcd-unique-ca",
          "attributes": {
            "armoBuiltin": true
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n#CIS 2.7 https://workbench.cisecurity.org/sections/1126654/recommendations/1838578\n\ndeny[msga] {\n\tetcdPod := [pod | pod := input[_]; filter_input(pod, \"etcd\")]\n\tetcdCheckResult := get_argument_value_with_path(etcdPod[0].spec.containers[0].command, \"--trusted-ca-file\")\n\n\tapiserverPod := [pod | pod := input[_]; filter_input(pod, \"kube-apiserver\")]\n\tapiserverCheckResult := get_argument_value_with_path(apiserverPod[0].spec.containers[0].command, \"--client-ca-file\")\n\n\tetcdCheckResult.value == apiserverCheckResult.value\n\tmsga := {\n\t\t\"alertMessage\": \"Cert file is the same both for the api server and the etcd\",\n\t\t\"alertScore\": 8,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"failedPaths\": [etcdCheckResult.path, apiserverCheckResult.path],\n\t\t\"fixPaths\": [etcdCheckResult.fix_paths, apiserverCheckResult.fix_paths],\n\t\t\"alertObject\": {\"k8sApiObjects\": [etcdPod[0], apiserverPod[0]]},\n\t}\n}\n\ncommand_api_server_or_etcd(cmd) {\n\tendswith(cmd, \"kube-apiserver\")\n}\n\ncommand_api_server_or_etcd(cmd) {\n\tendswith(cmd, \"etcd\")\n}\n\nfilter_input(obj, res) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tcount(obj.spec.containers) == 1\n\tendswith(split(obj.spec.containers[0].command[0], \" \")[0], res)\n}\n\nget_argument_value(command, argument) = value {\n\targs := regex.split(\"=\", command)\n\tsome i, sprintf(\"%v\", [argument]) in args\n\tvalue := args[i + 1]\n}\n\nget_argument_value_with_path(cmd, argument) = result {\n\tcontains(cmd[i], argument)\n\targumentValue := get_argument_value(cmd[i], argument)\n\tpath := sprintf(\"spec.containers[0].command[%d]\", [i])\n\tresult = {\n\t\t\"path\": path,\n\t\t\"value\": argumentValue,\n\t\t\"fix_paths\": {\"path\": path, \"value\": \"\u003cpath/to/different-tls-certificate-file.crt\u003e\"},\n\t}\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Use a different certificate authority for etcd from the one used for Kubernetes.",
          "remediation": "Follow the etcd documentation and create a dedicated certificate authority setup for the etcd service.\n\n Then, edit the etcd pod specification file `/etc/kubernetes/manifests/etcd.yaml` on the master node and set the below parameter.\n\n \n```\n--trusted-ca-file=\u003c/path/to/ca-file\u003e\n\n```\n\n#### Impact Statement\nAdditional management of the certificates and keys for the dedicated certificate authority will be required.\n\n#### Default Value\nBy default, no etcd certificate is created and used.",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 8
    },
    {
      "guid": "",
      "name": "Ensure that the CNI in use supports Network Policies",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-5.3.1",
      "controlID": "CIS-5.3.1",
      "creationTime": "",
      "description": "There are a variety of CNI plugins available for Kubernetes. If the CNI in use does not support Network Policies it may not be possible to effectively restrict traffic in the cluster.",
      "remediation": "If the CNI plugin in use does not support network policies, consideration should be given to making use of a different plugin, or finding an alternate mechanism for restricting traffic in the Kubernetes cluster.",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-cni-in-use-supports-network-policies",
          "attributes": {
            "armoBuiltin": true,
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\n\n# Deny CNIs that don't support Network Policies.\n# Deny when CNIName in input and in CNINotSupportsNetworkPolicies list.\n# Pass when CNIName not in input, or when CNIName in input but not in CNINotSupportsNetworkPolicies\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n    is_control_plane_info(obj)\n  \n\t# list of CNIs not supporting support Network Policies\n \tCNINotSupportsNetworkPolicies := [\"Flannel\"]\n\n\t# filter CNIs not supporting Network Policies\n    CNINotSupportsNetworkPolicies[_] = obj.data.CNIName\n\n\t# filter out irrelevant host-sensor data\n    obj_filtered := json.filter(obj, [\"apiVersion\", \"kind\", \"metadata\", \"data/CNIName\"])\n    \n\talert := sprintf(\"''%s' CNI doesn't support Network Policies.\", [obj.data.CNIName])\n\n    msg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": \"\",\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\n\t}\n}\n\nis_control_plane_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "ControlPlaneInfo"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "There are a variety of CNI plugins available for Kubernetes. If the CNI in use does not support Network Policies it may not be possible to effectively restrict traffic in the cluster.",
          "remediation": "If the CNI plugin in use does not support network policies, consideration should be given to making use of a different plugin, or finding an alternate mechanism for restricting traffic in the Kubernetes cluster.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "rulesIDs": [
        ""
      ],
      "baseScore": 4
    },
    {
      "guid": "",
      "name": "Ensure that a minimal audit policy is created",
      "attributes": {
        "armoBuiltin": true
      },
      "id": "CIS-3.2.1",
      "controlID": "CIS-3.2.1",
      "creationTime": "",
      "description": "Kubernetes can audit the details of requests made to the API server. The `--audit-policy-file` flag must be set for this logging to be enabled.",
      "remediation": "Create an audit policy file for your cluster.",
      "rules": null,
      "rulesIDs": null,
      "baseScore": 5
    }
  ],
  "controlsIDs": [
    "CIS-1.1.1",
    "CIS-1.1.3",
    "CIS-1.1.4",
    "CIS-1.1.5",
    "CIS-1.1.6",
    "CIS-1.1.7",
    "CIS-1.1.8",
    "CIS-1.1.11",
    "CIS-1.1.9",
    "CIS-1.1.10",
    "CIS-1.1.13",
    "CIS-1.1.12",
    "CIS-1.1.14",
    "CIS-1.1.15",
    "CIS-1.1.16",
    "CIS-1.1.17",
    "CIS-1.1.18",
    "CIS-1.1.19",
    "CIS-1.1.2",
    "CIS-1.1.20",
    "CIS-1.1.21",
    "CIS-1.2.24",
    "CIS-1.2.22",
    "CIS-1.2.3",
    "CIS-1.2.6",
    "CIS-1.2.4",
    "CIS-1.2.25",
    "CIS-1.2.8",
    "CIS-1.2.19",
    "CIS-1.2.10",
    "CIS-1.2.23",
    "CIS-1.2.7",
    "CIS-1.2.26",
    "CIS-1.2.17",
    "CIS-1.2.20",
    "CIS-1.2.31",
    "CIS-1.2.5",
    "CIS-1.2.29",
    "CIS-1.2.30",
    "CIS-1.2.21",
    "CIS-1.2.14",
    "CIS-1.2.12",
    "CIS-1.2.2",
    "CIS-1.2.16",
    "CIS-1.2.11",
    "CIS-1.2.27",
    "CIS-1.2.15",
    "CIS-1.2.18",
    "CIS-1.2.9",
    "CIS-1.2.28",
    "CIS-1.2.1",
    "CIS-1.2.13",
    "CIS-1.3.1",
    "CIS-1.3.2",
    "CIS-1.3.6",
    "CIS-1.3.5",
    "CIS-1.3.4",
    "CIS-1.3.3",
    "CIS-1.3.7",
    "CIS-1.4.1",
    "CIS-1.4.2",
    "CIS-4.1.1",
    "CIS-4.1.2",
    "CIS-4.1.3",
    "CIS-4.1.4",
    "CIS-4.1.5",
    "CIS-4.1.6",
    "CIS-4.1.7",
    "CIS-4.1.8",
    "CIS-4.1.9",
    "CIS-4.1.10",
    "CIS-5.1.1",
    "CIS-5.1.2",
    "CIS-5.1.3",
    "CIS-5.1.4",
    "CIS-5.1.5",
    "CIS-5.1.6",
    "CIS-5.1.8",
    "CIS-5.2.1",
    "CIS-5.2.2",
    "CIS-5.2.3",
    "CIS-5.2.4",
    "CIS-5.2.5",
    "CIS-5.2.6",
    "CIS-5.2.7",
    "CIS-5.2.8",
    "CIS-5.2.9",
    "CIS-5.2.10",
    "CIS-5.2.11",
    "CIS-5.2.12",
    "CIS-5.2.13",
    "CIS-5.3.2",
    "CIS-5.4.1",
    "CIS-5.4.2",
    "CIS-5.7.1",
    "CIS-5.7.2",
    "CIS-5.7.3",
    "CIS-5.7.4",
    "CIS-5.4.1",
    "CIS-2.1",
    "CIS-2.2",
    "CIS-2.3",
    "CIS-2.4",
    "CIS-2.5",
    "CIS-2.6",
    "CIS-5.4.1",
    "CIS-4.2.1",
    "CIS-4.2.2",
    "CIS-4.2.3",
    "CIS-4.2.4",
    "CIS-4.2.5",
    "CIS-4.2.6",
    "CIS-4.2.7",
    "CIS-4.2.8",
    "CIS-4.2.9",
    "CIS-4.2.10",
    "CIS-4.2.11",
    "CIS-4.2.12",
    "CIS-4.2.13",
    "CIS-2.7",
    "CIS-5.3.1",
    "CIS-3.2.1"
  ],
  "subSections": {
    "1": {
      "guid": "",
      "name": "Control Plane Components",
      "id": "1",
      "subSections": {
        "1": {
          "guid": "",
          "name": "Control Plane Node Configuration Files",
          "id": "1.1",
          "controlsIDs": [
            "CIS-1.1.1",
            "CIS-1.1.3",
            "CIS-1.1.4",
            "CIS-1.1.5",
            "CIS-1.1.6",
            "CIS-1.1.7",
            "CIS-1.1.8",
            "CIS-1.1.9",
            "CIS-1.1.10",
            "CIS-1.1.11",
            "CIS-1.1.12",
            "CIS-1.1.13",
            "CIS-1.1.14",
            "CIS-1.1.15",
            "CIS-1.1.16",
            "CIS-1.1.17",
            "CIS-1.1.18",
            "CIS-1.1.19",
            "CIS-1.1.2",
            "CIS-1.1.20",
            "CIS-1.1.21"
          ]
        },
        "2": {
          "guid": "",
          "name": "API Server",
          "id": "1.2",
          "controlsIDs": [
            "CIS-1.2.1",
            "CIS-1.2.2",
            "CIS-1.2.3",
            "CIS-1.2.4",
            "CIS-1.2.5",
            "CIS-1.2.6",
            "CIS-1.2.7",
            "CIS-1.2.8",
            "CIS-1.2.9",
            "CIS-1.2.10",
            "CIS-1.2.11",
            "CIS-1.2.12",
            "CIS-1.2.13",
            "CIS-1.2.14",
            "CIS-1.2.15",
            "CIS-1.2.16",
            "CIS-1.2.17",
            "CIS-1.2.18",
            "CIS-1.2.19",
            "CIS-1.2.20",
            "CIS-1.2.21",
            "CIS-1.2.22",
            "CIS-1.2.23",
            "CIS-1.2.24",
            "CIS-1.2.25",
            "CIS-1.2.26",
            "CIS-1.2.27",
            "CIS-1.2.28",
            "CIS-1.2.29",
            "CIS-1.2.30",
            "CIS-1.2.31"
          ]
        },
        "3": {
          "guid": "",
          "name": "Controller Manager",
          "id": "1.3",
          "controlsIDs": [
            "CIS-1.3.1",
            "CIS-1.3.2",
            "CIS-1.3.6",
            "CIS-1.3.5",
            "CIS-1.3.4",
            "CIS-1.3.3",
            "CIS-1.3.7"
          ]
        },
        "4": {
          "guid": "",
          "name": "Scheduler",
          "id": "1.4",
          "controlsIDs": [
            "CIS-1.4.1",
            "CIS-1.4.2"
          ]
        }
      }
    },
    "2": {
      "guid": "",
      "name": "etcd",
      "id": "2",
      "controlsIDs": [
        "CIS-2.1",
        "CIS-2.2",
        "CIS-2.3",
        "CIS-2.4",
        "CIS-2.5",
        "CIS-2.6",
        "CIS-2.7"
      ]
    },
    "3": {
      "guid": "",
      "name": "Control Plane Configuration",
      "id": "3",
      "subSections": {
        "2": {
          "guid": "",
          "name": "Logging",
          "id": "3.2.1",
          "controlsIDs": [
            "CIS-3.2.1"
          ]
        }
      }
    },
    "4": {
      "guid": "",
      "name": "Worker Nodes",
      "id": "4",
      "subSections": {
        "1": {
          "guid": "",
          "name": "Worker Node Configuration Files",
          "id": "4.1",
          "controlsIDs": [
            "CIS-4.1.1",
            "CIS-4.1.2",
            "CIS-4.1.3",
            "CIS-4.1.4",
            "CIS-4.1.5",
            "CIS-4.1.6",
            "CIS-4.1.7",
            "CIS-4.1.8",
            "CIS-4.1.9",
            "CIS-4.1.10"
          ]
        },
        "2": {
          "guid": "",
          "name": "Kubelet",
          "id": "4.2",
          "controlsIDs": [
            "CIS-4.2.1",
            "CIS-4.2.2",
            "CIS-4.2.3",
            "CIS-4.2.4",
            "CIS-4.2.5",
            "CIS-4.2.6",
            "CIS-4.2.7",
            "CIS-4.2.8",
            "CIS-4.2.9",
            "CIS-4.2.10",
            "CIS-4.2.11",
            "CIS-4.2.12",
            "CIS-4.2.13"
          ]
        }
      }
    },
    "5": {
      "guid": "",
      "name": "Policies",
      "id": "5",
      "subSections": {
        "1": {
          "guid": "",
          "name": "RBAC and Service Accounts",
          "id": "5.1",
          "controlsIDs": [
            "CIS-5.1.1",
            "CIS-5.1.2",
            "CIS-5.1.3",
            "CIS-5.1.4",
            "CIS-5.1.5",
            "CIS-5.1.6",
            "CIS-5.1.8"
          ]
        },
        "2": {
          "guid": "",
          "name": "Pod Security Standards",
          "id": "5.2",
          "controlsIDs": [
            "CIS-5.2.1",
            "CIS-5.2.2",
            "CIS-5.2.3",
            "CIS-5.2.4",
            "CIS-5.2.5",
            "CIS-5.2.6",
            "CIS-5.2.7",
            "CIS-5.2.8",
            "CIS-5.2.9",
            "CIS-5.2.10",
            "CIS-5.2.11",
            "CIS-5.2.12",
            "CIS-5.2.13"
          ]
        },
        "3": {
          "guid": "",
          "name": "Network Policies and CNI",
          "id": "5.3",
          "controlsIDs": [
            "CIS-5.3.1",
            "CIS-5.3.2"
          ]
        },
        "4": {
          "guid": "",
          "name": "Secrets Management",
          "id": "5.4",
          "controlsIDs": [
            "CIS-5.4.1",
            "CIS-5.4.2"
          ]
        },
        "7": {
          "guid": "",
          "name": "General Policies",
          "id": "5.7",
          "controlsIDs": [
            "CIS-5.7.1",
            "CIS-5.7.2",
            "CIS-5.7.3",
            "CIS-5.7.4"
          ]
        }
      }
    }
  }
}